Epoch 1 - Batch (0/363) - Mini-batch Training loss: 2.8941 - Training Acc 1: 0.00
Epoch 1 - Batch (10/363) - Mini-batch Training loss: 2.8658 - Training Acc 1: 0.00
Epoch 1 - Batch (20/363) - Mini-batch Training loss: 2.8456 - Training Acc 1: 0.00
Epoch 1 - Batch (30/363) - Mini-batch Training loss: 2.8367 - Training Acc 1: 0.01
Epoch 1 - Batch (40/363) - Mini-batch Training loss: 2.8257 - Training Acc 1: 0.01
Epoch 1 - Batch (50/363) - Mini-batch Training loss: 2.7983 - Training Acc 1: 0.01
Epoch 1 - Batch (60/363) - Mini-batch Training loss: 2.7994 - Training Acc 1: 0.02
Epoch 1 - Batch (70/363) - Mini-batch Training loss: 2.7851 - Training Acc 1: 0.02
Epoch 1 - Batch (80/363) - Mini-batch Training loss: 2.7707 - Training Acc 1: 0.02
Epoch 1 - Batch (90/363) - Mini-batch Training loss: 2.7491 - Training Acc 1: 0.03
Epoch 1 - Batch (100/363) - Mini-batch Training loss: 2.7388 - Training Acc 1: 0.03
Epoch 1 - Batch (110/363) - Mini-batch Training loss: 2.7253 - Training Acc 1: 0.04
Epoch 1 - Batch (120/363) - Mini-batch Training loss: 2.7264 - Training Acc 1: 0.04
Epoch 1 - Batch (130/363) - Mini-batch Training loss: 2.7058 - Training Acc 1: 0.05
Epoch 1 - Batch (140/363) - Mini-batch Training loss: 2.7014 - Training Acc 1: 0.06
Epoch 1 - Batch (150/363) - Mini-batch Training loss: 2.6922 - Training Acc 1: 0.06
Epoch 1 - Batch (160/363) - Mini-batch Training loss: 2.6824 - Training Acc 1: 0.07
Epoch 1 - Batch (170/363) - Mini-batch Training loss: 2.6621 - Training Acc 1: 0.08
Epoch 1 - Batch (180/363) - Mini-batch Training loss: 2.6445 - Training Acc 1: 0.08
Epoch 1 - Batch (190/363) - Mini-batch Training loss: 2.6308 - Training Acc 1: 0.09
Epoch 1 - Batch (200/363) - Mini-batch Training loss: 2.6159 - Training Acc 1: 0.09
Epoch 1 - Batch (210/363) - Mini-batch Training loss: 2.6129 - Training Acc 1: 0.10
Epoch 1 - Batch (220/363) - Mini-batch Training loss: 2.6018 - Training Acc 1: 0.11
Epoch 1 - Batch (230/363) - Mini-batch Training loss: 2.5919 - Training Acc 1: 0.12
Epoch 1 - Batch (240/363) - Mini-batch Training loss: 2.5826 - Training Acc 1: 0.12
Epoch 1 - Batch (250/363) - Mini-batch Training loss: 2.5781 - Training Acc 1: 0.13
Epoch 1 - Batch (260/363) - Mini-batch Training loss: 2.5680 - Training Acc 1: 0.13
Epoch 1 - Batch (270/363) - Mini-batch Training loss: 2.5584 - Training Acc 1: 0.14
Epoch 1 - Batch (280/363) - Mini-batch Training loss: 2.5569 - Training Acc 1: 0.15
Epoch 1 - Batch (290/363) - Mini-batch Training loss: 2.5557 - Training Acc 1: 0.16
Epoch 1 - Batch (300/363) - Mini-batch Training loss: 2.5512 - Training Acc 1: 0.16
Epoch 1 - Batch (310/363) - Mini-batch Training loss: 2.5371 - Training Acc 1: 0.17
Epoch 1 - Batch (320/363) - Mini-batch Training loss: 2.5209 - Training Acc 1: 0.18
Epoch 1 - Batch (330/363) - Mini-batch Training loss: 2.5123 - Training Acc 1: 0.19
Epoch 1 - Batch (340/363) - Mini-batch Training loss: 2.5002 - Training Acc 1: 0.20
Epoch 1 - Batch (350/363) - Mini-batch Training loss: 2.4961 - Training Acc 1: 0.21
Epoch 1 - Batch (360/363) - Mini-batch Training loss: 2.4852 - Training Acc 1: 0.22
Epoch 1 - Full-batch Training loss: 2.4835 - Training Acc 1: 0.22
Validation set: Average loss: 2.1333, Accuracy: 111.0/363 (31%)

0.30578512396694213
Epoch 2 - Batch (0/363) - Mini-batch Training loss: 2.2462 - Training Acc 1: 0.00
Epoch 2 - Batch (10/363) - Mini-batch Training loss: 2.2106 - Training Acc 1: 0.01
Epoch 2 - Batch (20/363) - Mini-batch Training loss: 2.1913 - Training Acc 1: 0.02
Epoch 2 - Batch (30/363) - Mini-batch Training loss: 2.2296 - Training Acc 1: 0.02
Epoch 2 - Batch (40/363) - Mini-batch Training loss: 2.2175 - Training Acc 1: 0.03
Epoch 2 - Batch (50/363) - Mini-batch Training loss: 2.1960 - Training Acc 1: 0.04
Epoch 2 - Batch (60/363) - Mini-batch Training loss: 2.2181 - Training Acc 1: 0.05
Epoch 2 - Batch (70/363) - Mini-batch Training loss: 2.1744 - Training Acc 1: 0.06
Epoch 2 - Batch (80/363) - Mini-batch Training loss: 2.1529 - Training Acc 1: 0.07
Epoch 2 - Batch (90/363) - Mini-batch Training loss: 2.1368 - Training Acc 1: 0.08
Epoch 2 - Batch (100/363) - Mini-batch Training loss: 2.1449 - Training Acc 1: 0.09
Epoch 2 - Batch (110/363) - Mini-batch Training loss: 2.1425 - Training Acc 1: 0.10
Epoch 2 - Batch (120/363) - Mini-batch Training loss: 2.1338 - Training Acc 1: 0.11
Epoch 2 - Batch (130/363) - Mini-batch Training loss: 2.1411 - Training Acc 1: 0.12
Epoch 2 - Batch (140/363) - Mini-batch Training loss: 2.1449 - Training Acc 1: 0.12
Epoch 2 - Batch (150/363) - Mini-batch Training loss: 2.1557 - Training Acc 1: 0.13
Epoch 2 - Batch (160/363) - Mini-batch Training loss: 2.1552 - Training Acc 1: 0.14
Epoch 2 - Batch (170/363) - Mini-batch Training loss: 2.1622 - Training Acc 1: 0.15
Epoch 2 - Batch (180/363) - Mini-batch Training loss: 2.1546 - Training Acc 1: 0.16
Epoch 2 - Batch (190/363) - Mini-batch Training loss: 2.1508 - Training Acc 1: 0.17
Epoch 2 - Batch (200/363) - Mini-batch Training loss: 2.1474 - Training Acc 1: 0.18
Epoch 2 - Batch (210/363) - Mini-batch Training loss: 2.1499 - Training Acc 1: 0.19
Epoch 2 - Batch (220/363) - Mini-batch Training loss: 2.1335 - Training Acc 1: 0.20
Epoch 2 - Batch (230/363) - Mini-batch Training loss: 2.1174 - Training Acc 1: 0.22
Epoch 2 - Batch (240/363) - Mini-batch Training loss: 2.1406 - Training Acc 1: 0.22
Epoch 2 - Batch (250/363) - Mini-batch Training loss: 2.1387 - Training Acc 1: 0.23
Epoch 2 - Batch (260/363) - Mini-batch Training loss: 2.1343 - Training Acc 1: 0.24
Epoch 2 - Batch (270/363) - Mini-batch Training loss: 2.1329 - Training Acc 1: 0.25
Epoch 2 - Batch (280/363) - Mini-batch Training loss: 2.1228 - Training Acc 1: 0.26
Epoch 2 - Batch (290/363) - Mini-batch Training loss: 2.1191 - Training Acc 1: 0.27
Epoch 2 - Batch (300/363) - Mini-batch Training loss: 2.1151 - Training Acc 1: 0.28
Epoch 2 - Batch (310/363) - Mini-batch Training loss: 2.1047 - Training Acc 1: 0.29
Epoch 2 - Batch (320/363) - Mini-batch Training loss: 2.0993 - Training Acc 1: 0.30
Epoch 2 - Batch (330/363) - Mini-batch Training loss: 2.0932 - Training Acc 1: 0.31
Epoch 2 - Batch (340/363) - Mini-batch Training loss: 2.0879 - Training Acc 1: 0.32
Epoch 2 - Batch (350/363) - Mini-batch Training loss: 2.0790 - Training Acc 1: 0.34
Epoch 2 - Batch (360/363) - Mini-batch Training loss: 2.0788 - Training Acc 1: 0.35
Epoch 2 - Full-batch Training loss: 2.0813 - Training Acc 1: 0.35
Validation set: Average loss: 1.8907, Accuracy: 154.0/363 (42%)

0.42424242424242425
Epoch 3 - Batch (0/363) - Mini-batch Training loss: 1.8891 - Training Acc 1: 0.00
Epoch 3 - Batch (10/363) - Mini-batch Training loss: 1.7969 - Training Acc 1: 0.01
Epoch 3 - Batch (20/363) - Mini-batch Training loss: 2.0005 - Training Acc 1: 0.02
Epoch 3 - Batch (30/363) - Mini-batch Training loss: 1.9487 - Training Acc 1: 0.04
Epoch 3 - Batch (40/363) - Mini-batch Training loss: 1.9314 - Training Acc 1: 0.04
Epoch 3 - Batch (50/363) - Mini-batch Training loss: 1.9122 - Training Acc 1: 0.06
Epoch 3 - Batch (60/363) - Mini-batch Training loss: 1.9008 - Training Acc 1: 0.07
Epoch 3 - Batch (70/363) - Mini-batch Training loss: 1.9039 - Training Acc 1: 0.08
Epoch 3 - Batch (80/363) - Mini-batch Training loss: 1.9267 - Training Acc 1: 0.09
Epoch 3 - Batch (90/363) - Mini-batch Training loss: 1.9254 - Training Acc 1: 0.10
Epoch 3 - Batch (100/363) - Mini-batch Training loss: 1.9239 - Training Acc 1: 0.11
Epoch 3 - Batch (110/363) - Mini-batch Training loss: 1.9320 - Training Acc 1: 0.12
Epoch 3 - Batch (120/363) - Mini-batch Training loss: 1.9216 - Training Acc 1: 0.14
Epoch 3 - Batch (130/363) - Mini-batch Training loss: 1.9178 - Training Acc 1: 0.15
Epoch 3 - Batch (140/363) - Mini-batch Training loss: 1.9063 - Training Acc 1: 0.16
Epoch 3 - Batch (150/363) - Mini-batch Training loss: 1.8972 - Training Acc 1: 0.17
Epoch 3 - Batch (160/363) - Mini-batch Training loss: 1.8867 - Training Acc 1: 0.19
Epoch 3 - Batch (170/363) - Mini-batch Training loss: 1.8759 - Training Acc 1: 0.20
Epoch 3 - Batch (180/363) - Mini-batch Training loss: 1.9006 - Training Acc 1: 0.21
Epoch 3 - Batch (190/363) - Mini-batch Training loss: 1.9054 - Training Acc 1: 0.22
Epoch 3 - Batch (200/363) - Mini-batch Training loss: 1.8926 - Training Acc 1: 0.23
Epoch 3 - Batch (210/363) - Mini-batch Training loss: 1.8774 - Training Acc 1: 0.24
Epoch 3 - Batch (220/363) - Mini-batch Training loss: 1.8816 - Training Acc 1: 0.25
Epoch 3 - Batch (230/363) - Mini-batch Training loss: 1.8812 - Training Acc 1: 0.26
Epoch 3 - Batch (240/363) - Mini-batch Training loss: 1.8934 - Training Acc 1: 0.27
Epoch 3 - Batch (250/363) - Mini-batch Training loss: 1.8888 - Training Acc 1: 0.29
Epoch 3 - Batch (260/363) - Mini-batch Training loss: 1.8942 - Training Acc 1: 0.29
Epoch 3 - Batch (270/363) - Mini-batch Training loss: 1.8962 - Training Acc 1: 0.31
Epoch 3 - Batch (280/363) - Mini-batch Training loss: 1.8922 - Training Acc 1: 0.32
Epoch 3 - Batch (290/363) - Mini-batch Training loss: 1.8900 - Training Acc 1: 0.33
Epoch 3 - Batch (300/363) - Mini-batch Training loss: 1.8846 - Training Acc 1: 0.35
Epoch 3 - Batch (310/363) - Mini-batch Training loss: 1.8855 - Training Acc 1: 0.36
Epoch 3 - Batch (320/363) - Mini-batch Training loss: 1.8748 - Training Acc 1: 0.37
Epoch 3 - Batch (330/363) - Mini-batch Training loss: 1.8661 - Training Acc 1: 0.39
Epoch 3 - Batch (340/363) - Mini-batch Training loss: 1.8619 - Training Acc 1: 0.40
Epoch 3 - Batch (350/363) - Mini-batch Training loss: 1.8566 - Training Acc 1: 0.41
Epoch 3 - Batch (360/363) - Mini-batch Training loss: 1.8581 - Training Acc 1: 0.42
Epoch 3 - Full-batch Training loss: 1.8547 - Training Acc 1: 0.42
Validation set: Average loss: 1.6661, Accuracy: 160.0/363 (44%)

0.44077134986225897
Epoch 4 - Batch (0/363) - Mini-batch Training loss: 2.7875 - Training Acc 1: 0.00
Epoch 4 - Batch (10/363) - Mini-batch Training loss: 1.6118 - Training Acc 1: 0.02
Epoch 4 - Batch (20/363) - Mini-batch Training loss: 1.6352 - Training Acc 1: 0.03
Epoch 4 - Batch (30/363) - Mini-batch Training loss: 1.7361 - Training Acc 1: 0.04
Epoch 4 - Batch (40/363) - Mini-batch Training loss: 1.7848 - Training Acc 1: 0.05
Epoch 4 - Batch (50/363) - Mini-batch Training loss: 1.7763 - Training Acc 1: 0.06
Epoch 4 - Batch (60/363) - Mini-batch Training loss: 1.7709 - Training Acc 1: 0.08
Epoch 4 - Batch (70/363) - Mini-batch Training loss: 1.7846 - Training Acc 1: 0.08
Epoch 4 - Batch (80/363) - Mini-batch Training loss: 1.7656 - Training Acc 1: 0.10
Epoch 4 - Batch (90/363) - Mini-batch Training loss: 1.7565 - Training Acc 1: 0.11
Epoch 4 - Batch (100/363) - Mini-batch Training loss: 1.7554 - Training Acc 1: 0.12
Epoch 4 - Batch (110/363) - Mini-batch Training loss: 1.7515 - Training Acc 1: 0.13
Epoch 4 - Batch (120/363) - Mini-batch Training loss: 1.7644 - Training Acc 1: 0.14
Epoch 4 - Batch (130/363) - Mini-batch Training loss: 1.7336 - Training Acc 1: 0.16
Epoch 4 - Batch (140/363) - Mini-batch Training loss: 1.7322 - Training Acc 1: 0.17
Epoch 4 - Batch (150/363) - Mini-batch Training loss: 1.7271 - Training Acc 1: 0.18
Epoch 4 - Batch (160/363) - Mini-batch Training loss: 1.7130 - Training Acc 1: 0.20
Epoch 4 - Batch (170/363) - Mini-batch Training loss: 1.7092 - Training Acc 1: 0.21
Epoch 4 - Batch (180/363) - Mini-batch Training loss: 1.6861 - Training Acc 1: 0.23
Epoch 4 - Batch (190/363) - Mini-batch Training loss: 1.6848 - Training Acc 1: 0.24
Epoch 4 - Batch (200/363) - Mini-batch Training loss: 1.6934 - Training Acc 1: 0.25
Epoch 4 - Batch (210/363) - Mini-batch Training loss: 1.7085 - Training Acc 1: 0.26
Epoch 4 - Batch (220/363) - Mini-batch Training loss: 1.6887 - Training Acc 1: 0.28
Epoch 4 - Batch (230/363) - Mini-batch Training loss: 1.6907 - Training Acc 1: 0.29
Epoch 4 - Batch (240/363) - Mini-batch Training loss: 1.6925 - Training Acc 1: 0.30
Epoch 4 - Batch (250/363) - Mini-batch Training loss: 1.6890 - Training Acc 1: 0.32
Epoch 4 - Batch (260/363) - Mini-batch Training loss: 1.6807 - Training Acc 1: 0.33
Epoch 4 - Batch (270/363) - Mini-batch Training loss: 1.6706 - Training Acc 1: 0.35
Epoch 4 - Batch (280/363) - Mini-batch Training loss: 1.6669 - Training Acc 1: 0.36
Epoch 4 - Batch (290/363) - Mini-batch Training loss: 1.6577 - Training Acc 1: 0.38
Epoch 4 - Batch (300/363) - Mini-batch Training loss: 1.6550 - Training Acc 1: 0.39
Epoch 4 - Batch (310/363) - Mini-batch Training loss: 1.6481 - Training Acc 1: 0.41
Epoch 4 - Batch (320/363) - Mini-batch Training loss: 1.6480 - Training Acc 1: 0.42
Epoch 4 - Batch (330/363) - Mini-batch Training loss: 1.6486 - Training Acc 1: 0.43
Epoch 4 - Batch (340/363) - Mini-batch Training loss: 1.6512 - Training Acc 1: 0.45
Epoch 4 - Batch (350/363) - Mini-batch Training loss: 1.6588 - Training Acc 1: 0.46
Epoch 4 - Batch (360/363) - Mini-batch Training loss: 1.6576 - Training Acc 1: 0.47
Epoch 4 - Full-batch Training loss: 1.6592 - Training Acc 1: 0.47
Validation set: Average loss: 1.4655, Accuracy: 183.0/363 (50%)

0.5041322314049587
Epoch 5 - Batch (0/363) - Mini-batch Training loss: 0.7379 - Training Acc 1: 0.00
Epoch 5 - Batch (10/363) - Mini-batch Training loss: 1.4571 - Training Acc 1: 0.01
Epoch 5 - Batch (20/363) - Mini-batch Training loss: 1.5537 - Training Acc 1: 0.03
Epoch 5 - Batch (30/363) - Mini-batch Training loss: 1.5499 - Training Acc 1: 0.04
Epoch 5 - Batch (40/363) - Mini-batch Training loss: 1.5839 - Training Acc 1: 0.06
Epoch 5 - Batch (50/363) - Mini-batch Training loss: 1.5866 - Training Acc 1: 0.07
Epoch 5 - Batch (60/363) - Mini-batch Training loss: 1.5559 - Training Acc 1: 0.09
Epoch 5 - Batch (70/363) - Mini-batch Training loss: 1.5284 - Training Acc 1: 0.10
Epoch 5 - Batch (80/363) - Mini-batch Training loss: 1.5472 - Training Acc 1: 0.12
Epoch 5 - Batch (90/363) - Mini-batch Training loss: 1.5139 - Training Acc 1: 0.13
Epoch 5 - Batch (100/363) - Mini-batch Training loss: 1.5303 - Training Acc 1: 0.14
Epoch 5 - Batch (110/363) - Mini-batch Training loss: 1.5367 - Training Acc 1: 0.16
Epoch 5 - Batch (120/363) - Mini-batch Training loss: 1.5381 - Training Acc 1: 0.17
Epoch 5 - Batch (130/363) - Mini-batch Training loss: 1.5370 - Training Acc 1: 0.18
Epoch 5 - Batch (140/363) - Mini-batch Training loss: 1.5324 - Training Acc 1: 0.20
Epoch 5 - Batch (150/363) - Mini-batch Training loss: 1.5359 - Training Acc 1: 0.21
Epoch 5 - Batch (160/363) - Mini-batch Training loss: 1.5364 - Training Acc 1: 0.23
Epoch 5 - Batch (170/363) - Mini-batch Training loss: 1.5214 - Training Acc 1: 0.24
Epoch 5 - Batch (180/363) - Mini-batch Training loss: 1.5175 - Training Acc 1: 0.26
Epoch 5 - Batch (190/363) - Mini-batch Training loss: 1.5259 - Training Acc 1: 0.27
Epoch 5 - Batch (200/363) - Mini-batch Training loss: 1.5382 - Training Acc 1: 0.28
Epoch 5 - Batch (210/363) - Mini-batch Training loss: 1.5459 - Training Acc 1: 0.30
Epoch 5 - Batch (220/363) - Mini-batch Training loss: 1.5408 - Training Acc 1: 0.31
Epoch 5 - Batch (230/363) - Mini-batch Training loss: 1.5320 - Training Acc 1: 0.33
Epoch 5 - Batch (240/363) - Mini-batch Training loss: 1.5418 - Training Acc 1: 0.34
Epoch 5 - Batch (250/363) - Mini-batch Training loss: 1.5374 - Training Acc 1: 0.35
Epoch 5 - Batch (260/363) - Mini-batch Training loss: 1.5212 - Training Acc 1: 0.37
Epoch 5 - Batch (270/363) - Mini-batch Training loss: 1.5185 - Training Acc 1: 0.38
Epoch 5 - Batch (280/363) - Mini-batch Training loss: 1.5219 - Training Acc 1: 0.40
Epoch 5 - Batch (290/363) - Mini-batch Training loss: 1.5166 - Training Acc 1: 0.41
Epoch 5 - Batch (300/363) - Mini-batch Training loss: 1.5170 - Training Acc 1: 0.42
Epoch 5 - Batch (310/363) - Mini-batch Training loss: 1.5035 - Training Acc 1: 0.44
Epoch 5 - Batch (320/363) - Mini-batch Training loss: 1.4980 - Training Acc 1: 0.46
Epoch 5 - Batch (330/363) - Mini-batch Training loss: 1.4894 - Training Acc 1: 0.48
Epoch 5 - Batch (340/363) - Mini-batch Training loss: 1.4836 - Training Acc 1: 0.49
Epoch 5 - Batch (350/363) - Mini-batch Training loss: 1.4822 - Training Acc 1: 0.51
Epoch 5 - Batch (360/363) - Mini-batch Training loss: 1.4861 - Training Acc 1: 0.52
Epoch 5 - Full-batch Training loss: 1.4840 - Training Acc 1: 0.52
Validation set: Average loss: 1.3105, Accuracy: 201.0/363 (55%)

0.5537190082644629
Epoch 6 - Batch (0/363) - Mini-batch Training loss: 2.1790 - Training Acc 1: 0.00
Epoch 6 - Batch (10/363) - Mini-batch Training loss: 1.7829 - Training Acc 1: 0.01
Epoch 6 - Batch (20/363) - Mini-batch Training loss: 1.5642 - Training Acc 1: 0.03
Epoch 6 - Batch (30/363) - Mini-batch Training loss: 1.4973 - Training Acc 1: 0.04
Epoch 6 - Batch (40/363) - Mini-batch Training loss: 1.4863 - Training Acc 1: 0.06
Epoch 6 - Batch (50/363) - Mini-batch Training loss: 1.4921 - Training Acc 1: 0.07
Epoch 6 - Batch (60/363) - Mini-batch Training loss: 1.5032 - Training Acc 1: 0.09
Epoch 6 - Batch (70/363) - Mini-batch Training loss: 1.5072 - Training Acc 1: 0.10
Epoch 6 - Batch (80/363) - Mini-batch Training loss: 1.5019 - Training Acc 1: 0.12
Epoch 6 - Batch (90/363) - Mini-batch Training loss: 1.4712 - Training Acc 1: 0.13
Epoch 6 - Batch (100/363) - Mini-batch Training loss: 1.4379 - Training Acc 1: 0.15
Epoch 6 - Batch (110/363) - Mini-batch Training loss: 1.4306 - Training Acc 1: 0.16
Epoch 6 - Batch (120/363) - Mini-batch Training loss: 1.4223 - Training Acc 1: 0.18
Epoch 6 - Batch (130/363) - Mini-batch Training loss: 1.4219 - Training Acc 1: 0.19
Epoch 6 - Batch (140/363) - Mini-batch Training loss: 1.4194 - Training Acc 1: 0.21
Epoch 6 - Batch (150/363) - Mini-batch Training loss: 1.4227 - Training Acc 1: 0.22
Epoch 6 - Batch (160/363) - Mini-batch Training loss: 1.4041 - Training Acc 1: 0.24
Epoch 6 - Batch (170/363) - Mini-batch Training loss: 1.3895 - Training Acc 1: 0.26
Epoch 6 - Batch (180/363) - Mini-batch Training loss: 1.3714 - Training Acc 1: 0.27
Epoch 6 - Batch (190/363) - Mini-batch Training loss: 1.3646 - Training Acc 1: 0.29
Epoch 6 - Batch (200/363) - Mini-batch Training loss: 1.3630 - Training Acc 1: 0.30
Epoch 6 - Batch (210/363) - Mini-batch Training loss: 1.3642 - Training Acc 1: 0.32
Epoch 6 - Batch (220/363) - Mini-batch Training loss: 1.3695 - Training Acc 1: 0.33
Epoch 6 - Batch (230/363) - Mini-batch Training loss: 1.3820 - Training Acc 1: 0.35
Epoch 6 - Batch (240/363) - Mini-batch Training loss: 1.3859 - Training Acc 1: 0.36
Epoch 6 - Batch (250/363) - Mini-batch Training loss: 1.3889 - Training Acc 1: 0.38
Epoch 6 - Batch (260/363) - Mini-batch Training loss: 1.3872 - Training Acc 1: 0.39
Epoch 6 - Batch (270/363) - Mini-batch Training loss: 1.3856 - Training Acc 1: 0.41
Epoch 6 - Batch (280/363) - Mini-batch Training loss: 1.3846 - Training Acc 1: 0.43
Epoch 6 - Batch (290/363) - Mini-batch Training loss: 1.3815 - Training Acc 1: 0.44
Epoch 6 - Batch (300/363) - Mini-batch Training loss: 1.3870 - Training Acc 1: 0.45
Epoch 6 - Batch (310/363) - Mini-batch Training loss: 1.3797 - Training Acc 1: 0.47
Epoch 6 - Batch (320/363) - Mini-batch Training loss: 1.3770 - Training Acc 1: 0.49
Epoch 6 - Batch (330/363) - Mini-batch Training loss: 1.3734 - Training Acc 1: 0.50
Epoch 6 - Batch (340/363) - Mini-batch Training loss: 1.3681 - Training Acc 1: 0.52
Epoch 6 - Batch (350/363) - Mini-batch Training loss: 1.3635 - Training Acc 1: 0.54
Epoch 6 - Batch (360/363) - Mini-batch Training loss: 1.3603 - Training Acc 1: 0.55
Epoch 6 - Full-batch Training loss: 1.3570 - Training Acc 1: 0.55
Validation set: Average loss: 1.2047, Accuracy: 211.0/363 (58%)

0.581267217630854
Epoch 7 - Batch (0/363) - Mini-batch Training loss: 0.9016 - Training Acc 1: 0.00
Epoch 7 - Batch (10/363) - Mini-batch Training loss: 1.6107 - Training Acc 1: 0.02
Epoch 7 - Batch (20/363) - Mini-batch Training loss: 1.3176 - Training Acc 1: 0.04
Epoch 7 - Batch (30/363) - Mini-batch Training loss: 1.3708 - Training Acc 1: 0.05
Epoch 7 - Batch (40/363) - Mini-batch Training loss: 1.2934 - Training Acc 1: 0.07
Epoch 7 - Batch (50/363) - Mini-batch Training loss: 1.3197 - Training Acc 1: 0.08
Epoch 7 - Batch (60/363) - Mini-batch Training loss: 1.3097 - Training Acc 1: 0.10
Epoch 7 - Batch (70/363) - Mini-batch Training loss: 1.3004 - Training Acc 1: 0.11
Epoch 7 - Batch (80/363) - Mini-batch Training loss: 1.3123 - Training Acc 1: 0.13
Epoch 7 - Batch (90/363) - Mini-batch Training loss: 1.2850 - Training Acc 1: 0.14
Epoch 7 - Batch (100/363) - Mini-batch Training loss: 1.2761 - Training Acc 1: 0.16
Epoch 7 - Batch (110/363) - Mini-batch Training loss: 1.2645 - Training Acc 1: 0.18
Epoch 7 - Batch (120/363) - Mini-batch Training loss: 1.2765 - Training Acc 1: 0.19
Epoch 7 - Batch (130/363) - Mini-batch Training loss: 1.2872 - Training Acc 1: 0.21
Epoch 7 - Batch (140/363) - Mini-batch Training loss: 1.2735 - Training Acc 1: 0.23
Epoch 7 - Batch (150/363) - Mini-batch Training loss: 1.2751 - Training Acc 1: 0.24
Epoch 7 - Batch (160/363) - Mini-batch Training loss: 1.2812 - Training Acc 1: 0.25
Epoch 7 - Batch (170/363) - Mini-batch Training loss: 1.2808 - Training Acc 1: 0.27
Epoch 7 - Batch (180/363) - Mini-batch Training loss: 1.2874 - Training Acc 1: 0.29
Epoch 7 - Batch (190/363) - Mini-batch Training loss: 1.2955 - Training Acc 1: 0.31
Epoch 7 - Batch (200/363) - Mini-batch Training loss: 1.2977 - Training Acc 1: 0.32
Epoch 7 - Batch (210/363) - Mini-batch Training loss: 1.3059 - Training Acc 1: 0.34
Epoch 7 - Batch (220/363) - Mini-batch Training loss: 1.2970 - Training Acc 1: 0.36
Epoch 7 - Batch (230/363) - Mini-batch Training loss: 1.2921 - Training Acc 1: 0.38
Epoch 7 - Batch (240/363) - Mini-batch Training loss: 1.2849 - Training Acc 1: 0.40
Epoch 7 - Batch (250/363) - Mini-batch Training loss: 1.2887 - Training Acc 1: 0.41
Epoch 7 - Batch (260/363) - Mini-batch Training loss: 1.2910 - Training Acc 1: 0.43
Epoch 7 - Batch (270/363) - Mini-batch Training loss: 1.3002 - Training Acc 1: 0.44
Epoch 7 - Batch (280/363) - Mini-batch Training loss: 1.3026 - Training Acc 1: 0.46
Epoch 7 - Batch (290/363) - Mini-batch Training loss: 1.2970 - Training Acc 1: 0.48
Epoch 7 - Batch (300/363) - Mini-batch Training loss: 1.2972 - Training Acc 1: 0.49
Epoch 7 - Batch (310/363) - Mini-batch Training loss: 1.2890 - Training Acc 1: 0.51
Epoch 7 - Batch (320/363) - Mini-batch Training loss: 1.2839 - Training Acc 1: 0.53
Epoch 7 - Batch (330/363) - Mini-batch Training loss: 1.2784 - Training Acc 1: 0.55
Epoch 7 - Batch (340/363) - Mini-batch Training loss: 1.2777 - Training Acc 1: 0.57
Epoch 7 - Batch (350/363) - Mini-batch Training loss: 1.2760 - Training Acc 1: 0.58
Epoch 7 - Batch (360/363) - Mini-batch Training loss: 1.2677 - Training Acc 1: 0.60
Epoch 7 - Full-batch Training loss: 1.2736 - Training Acc 1: 0.60
Validation set: Average loss: 1.1901, Accuracy: 220.0/363 (61%)

0.6060606060606061
Epoch 8 - Batch (0/363) - Mini-batch Training loss: 1.2321 - Training Acc 1: 0.00
Epoch 8 - Batch (10/363) - Mini-batch Training loss: 1.1809 - Training Acc 1: 0.02
Epoch 8 - Batch (20/363) - Mini-batch Training loss: 1.2502 - Training Acc 1: 0.03
Epoch 8 - Batch (30/363) - Mini-batch Training loss: 1.3835 - Training Acc 1: 0.04
Epoch 8 - Batch (40/363) - Mini-batch Training loss: 1.2819 - Training Acc 1: 0.06
Epoch 8 - Batch (50/363) - Mini-batch Training loss: 1.2779 - Training Acc 1: 0.08
Epoch 8 - Batch (60/363) - Mini-batch Training loss: 1.2448 - Training Acc 1: 0.10
Epoch 8 - Batch (70/363) - Mini-batch Training loss: 1.1881 - Training Acc 1: 0.12
Epoch 8 - Batch (80/363) - Mini-batch Training loss: 1.2300 - Training Acc 1: 0.14
Epoch 8 - Batch (90/363) - Mini-batch Training loss: 1.2118 - Training Acc 1: 0.15
Epoch 8 - Batch (100/363) - Mini-batch Training loss: 1.2230 - Training Acc 1: 0.16
Epoch 8 - Batch (110/363) - Mini-batch Training loss: 1.2362 - Training Acc 1: 0.18
Epoch 8 - Batch (120/363) - Mini-batch Training loss: 1.2458 - Training Acc 1: 0.20
Epoch 8 - Batch (130/363) - Mini-batch Training loss: 1.2079 - Training Acc 1: 0.22
Epoch 8 - Batch (140/363) - Mini-batch Training loss: 1.2135 - Training Acc 1: 0.23
Epoch 8 - Batch (150/363) - Mini-batch Training loss: 1.2395 - Training Acc 1: 0.25
Epoch 8 - Batch (160/363) - Mini-batch Training loss: 1.2425 - Training Acc 1: 0.26
Epoch 8 - Batch (170/363) - Mini-batch Training loss: 1.2279 - Training Acc 1: 0.28
Epoch 8 - Batch (180/363) - Mini-batch Training loss: 1.2241 - Training Acc 1: 0.30
Epoch 8 - Batch (190/363) - Mini-batch Training loss: 1.2297 - Training Acc 1: 0.31
Epoch 8 - Batch (200/363) - Mini-batch Training loss: 1.2280 - Training Acc 1: 0.33
Epoch 8 - Batch (210/363) - Mini-batch Training loss: 1.2265 - Training Acc 1: 0.34
Epoch 8 - Batch (220/363) - Mini-batch Training loss: 1.2224 - Training Acc 1: 0.36
Epoch 8 - Batch (230/363) - Mini-batch Training loss: 1.2174 - Training Acc 1: 0.37
Epoch 8 - Batch (240/363) - Mini-batch Training loss: 1.2118 - Training Acc 1: 0.39
Epoch 8 - Batch (250/363) - Mini-batch Training loss: 1.2031 - Training Acc 1: 0.41
Epoch 8 - Batch (260/363) - Mini-batch Training loss: 1.1985 - Training Acc 1: 0.43
Epoch 8 - Batch (270/363) - Mini-batch Training loss: 1.2038 - Training Acc 1: 0.44
Epoch 8 - Batch (280/363) - Mini-batch Training loss: 1.2125 - Training Acc 1: 0.46
Epoch 8 - Batch (290/363) - Mini-batch Training loss: 1.2217 - Training Acc 1: 0.47
Epoch 8 - Batch (300/363) - Mini-batch Training loss: 1.2272 - Training Acc 1: 0.49
Epoch 8 - Batch (310/363) - Mini-batch Training loss: 1.2245 - Training Acc 1: 0.51
Epoch 8 - Batch (320/363) - Mini-batch Training loss: 1.2208 - Training Acc 1: 0.53
Epoch 8 - Batch (330/363) - Mini-batch Training loss: 1.2166 - Training Acc 1: 0.55
Epoch 8 - Batch (340/363) - Mini-batch Training loss: 1.2148 - Training Acc 1: 0.57
Epoch 8 - Batch (350/363) - Mini-batch Training loss: 1.2090 - Training Acc 1: 0.58
Epoch 8 - Batch (360/363) - Mini-batch Training loss: 1.2090 - Training Acc 1: 0.60
Epoch 8 - Full-batch Training loss: 1.2050 - Training Acc 1: 0.60
Validation set: Average loss: 1.1622, Accuracy: 229.0/363 (63%)

0.6308539944903582
Epoch 9 - Batch (0/363) - Mini-batch Training loss: 1.7646 - Training Acc 1: 0.00
Epoch 9 - Batch (10/363) - Mini-batch Training loss: 1.5820 - Training Acc 1: 0.02
Epoch 9 - Batch (20/363) - Mini-batch Training loss: 1.3041 - Training Acc 1: 0.03
Epoch 9 - Batch (30/363) - Mini-batch Training loss: 1.2343 - Training Acc 1: 0.05
Epoch 9 - Batch (40/363) - Mini-batch Training loss: 1.2773 - Training Acc 1: 0.06
Epoch 9 - Batch (50/363) - Mini-batch Training loss: 1.1957 - Training Acc 1: 0.08
Epoch 9 - Batch (60/363) - Mini-batch Training loss: 1.1492 - Training Acc 1: 0.11
Epoch 9 - Batch (70/363) - Mini-batch Training loss: 1.1332 - Training Acc 1: 0.12
Epoch 9 - Batch (80/363) - Mini-batch Training loss: 1.1502 - Training Acc 1: 0.14
Epoch 9 - Batch (90/363) - Mini-batch Training loss: 1.1801 - Training Acc 1: 0.16
Epoch 9 - Batch (100/363) - Mini-batch Training loss: 1.1836 - Training Acc 1: 0.17
Epoch 9 - Batch (110/363) - Mini-batch Training loss: 1.2068 - Training Acc 1: 0.19
Epoch 9 - Batch (120/363) - Mini-batch Training loss: 1.1862 - Training Acc 1: 0.21
Epoch 9 - Batch (130/363) - Mini-batch Training loss: 1.1773 - Training Acc 1: 0.23
Epoch 9 - Batch (140/363) - Mini-batch Training loss: 1.1723 - Training Acc 1: 0.25
Epoch 9 - Batch (150/363) - Mini-batch Training loss: 1.1564 - Training Acc 1: 0.27
Epoch 9 - Batch (160/363) - Mini-batch Training loss: 1.1722 - Training Acc 1: 0.28
Epoch 9 - Batch (170/363) - Mini-batch Training loss: 1.1422 - Training Acc 1: 0.30
Epoch 9 - Batch (180/363) - Mini-batch Training loss: 1.1387 - Training Acc 1: 0.32
Epoch 9 - Batch (190/363) - Mini-batch Training loss: 1.1415 - Training Acc 1: 0.34
Epoch 9 - Batch (200/363) - Mini-batch Training loss: 1.1384 - Training Acc 1: 0.35
Epoch 9 - Batch (210/363) - Mini-batch Training loss: 1.1365 - Training Acc 1: 0.37
Epoch 9 - Batch (220/363) - Mini-batch Training loss: 1.1378 - Training Acc 1: 0.39
Epoch 9 - Batch (230/363) - Mini-batch Training loss: 1.1307 - Training Acc 1: 0.41
Epoch 9 - Batch (240/363) - Mini-batch Training loss: 1.1288 - Training Acc 1: 0.42
Epoch 9 - Batch (250/363) - Mini-batch Training loss: 1.1275 - Training Acc 1: 0.44
Epoch 9 - Batch (260/363) - Mini-batch Training loss: 1.1242 - Training Acc 1: 0.46
Epoch 9 - Batch (270/363) - Mini-batch Training loss: 1.1335 - Training Acc 1: 0.48
Epoch 9 - Batch (280/363) - Mini-batch Training loss: 1.1447 - Training Acc 1: 0.49
Epoch 9 - Batch (290/363) - Mini-batch Training loss: 1.1415 - Training Acc 1: 0.51
Epoch 9 - Batch (300/363) - Mini-batch Training loss: 1.1369 - Training Acc 1: 0.53
Epoch 9 - Batch (310/363) - Mini-batch Training loss: 1.1415 - Training Acc 1: 0.55
Epoch 9 - Batch (320/363) - Mini-batch Training loss: 1.1382 - Training Acc 1: 0.57
Epoch 9 - Batch (330/363) - Mini-batch Training loss: 1.1348 - Training Acc 1: 0.58
Epoch 9 - Batch (340/363) - Mini-batch Training loss: 1.1302 - Training Acc 1: 0.60
Epoch 9 - Batch (350/363) - Mini-batch Training loss: 1.1345 - Training Acc 1: 0.61
Epoch 9 - Batch (360/363) - Mini-batch Training loss: 1.1332 - Training Acc 1: 0.63
Epoch 9 - Full-batch Training loss: 1.1357 - Training Acc 1: 0.63
Validation set: Average loss: 1.0974, Accuracy: 240.0/363 (66%)

0.6611570247933884
Epoch 10 - Batch (0/363) - Mini-batch Training loss: 0.5073 - Training Acc 1: 0.00
Epoch 10 - Batch (10/363) - Mini-batch Training loss: 1.1372 - Training Acc 1: 0.02
Epoch 10 - Batch (20/363) - Mini-batch Training loss: 0.9332 - Training Acc 1: 0.04
Epoch 10 - Batch (30/363) - Mini-batch Training loss: 1.0437 - Training Acc 1: 0.05
Epoch 10 - Batch (40/363) - Mini-batch Training loss: 1.0926 - Training Acc 1: 0.07
Epoch 10 - Batch (50/363) - Mini-batch Training loss: 1.0938 - Training Acc 1: 0.09
Epoch 10 - Batch (60/363) - Mini-batch Training loss: 1.1282 - Training Acc 1: 0.11
Epoch 10 - Batch (70/363) - Mini-batch Training loss: 1.1415 - Training Acc 1: 0.13
Epoch 10 - Batch (80/363) - Mini-batch Training loss: 1.1898 - Training Acc 1: 0.14
Epoch 10 - Batch (90/363) - Mini-batch Training loss: 1.1434 - Training Acc 1: 0.16
Epoch 10 - Batch (100/363) - Mini-batch Training loss: 1.1449 - Training Acc 1: 0.18
Epoch 10 - Batch (110/363) - Mini-batch Training loss: 1.1736 - Training Acc 1: 0.19
Epoch 10 - Batch (120/363) - Mini-batch Training loss: 1.1784 - Training Acc 1: 0.21
Epoch 10 - Batch (130/363) - Mini-batch Training loss: 1.1599 - Training Acc 1: 0.23
Epoch 10 - Batch (140/363) - Mini-batch Training loss: 1.1503 - Training Acc 1: 0.25
Epoch 10 - Batch (150/363) - Mini-batch Training loss: 1.1670 - Training Acc 1: 0.27
Epoch 10 - Batch (160/363) - Mini-batch Training loss: 1.1461 - Training Acc 1: 0.29
Epoch 10 - Batch (170/363) - Mini-batch Training loss: 1.1470 - Training Acc 1: 0.30
Epoch 10 - Batch (180/363) - Mini-batch Training loss: 1.1455 - Training Acc 1: 0.32
Epoch 10 - Batch (190/363) - Mini-batch Training loss: 1.1238 - Training Acc 1: 0.34
Epoch 10 - Batch (200/363) - Mini-batch Training loss: 1.1211 - Training Acc 1: 0.36
Epoch 10 - Batch (210/363) - Mini-batch Training loss: 1.1062 - Training Acc 1: 0.38
Epoch 10 - Batch (220/363) - Mini-batch Training loss: 1.0958 - Training Acc 1: 0.40
Epoch 10 - Batch (230/363) - Mini-batch Training loss: 1.1073 - Training Acc 1: 0.41
Epoch 10 - Batch (240/363) - Mini-batch Training loss: 1.1009 - Training Acc 1: 0.43
Epoch 10 - Batch (250/363) - Mini-batch Training loss: 1.1070 - Training Acc 1: 0.45
Epoch 10 - Batch (260/363) - Mini-batch Training loss: 1.1063 - Training Acc 1: 0.46
Epoch 10 - Batch (270/363) - Mini-batch Training loss: 1.0999 - Training Acc 1: 0.48
Epoch 10 - Batch (280/363) - Mini-batch Training loss: 1.0910 - Training Acc 1: 0.50
Epoch 10 - Batch (290/363) - Mini-batch Training loss: 1.0969 - Training Acc 1: 0.51
Epoch 10 - Batch (300/363) - Mini-batch Training loss: 1.1043 - Training Acc 1: 0.53
Epoch 10 - Batch (310/363) - Mini-batch Training loss: 1.0968 - Training Acc 1: 0.55
Epoch 10 - Batch (320/363) - Mini-batch Training loss: 1.0963 - Training Acc 1: 0.57
Epoch 10 - Batch (330/363) - Mini-batch Training loss: 1.0981 - Training Acc 1: 0.59
Epoch 10 - Batch (340/363) - Mini-batch Training loss: 1.0985 - Training Acc 1: 0.61
Epoch 10 - Batch (350/363) - Mini-batch Training loss: 1.0954 - Training Acc 1: 0.63
Epoch 10 - Batch (360/363) - Mini-batch Training loss: 1.0911 - Training Acc 1: 0.65
Epoch 10 - Full-batch Training loss: 1.0917 - Training Acc 1: 0.65
Validation set: Average loss: 1.1031, Accuracy: 220.0/363 (61%)

Epoch 11 - Batch (0/363) - Mini-batch Training loss: 0.8123 - Training Acc 1: 0.00
Epoch 11 - Batch (10/363) - Mini-batch Training loss: 1.1601 - Training Acc 1: 0.02
Epoch 11 - Batch (20/363) - Mini-batch Training loss: 1.1229 - Training Acc 1: 0.04
Epoch 11 - Batch (30/363) - Mini-batch Training loss: 1.1187 - Training Acc 1: 0.05
Epoch 11 - Batch (40/363) - Mini-batch Training loss: 1.1207 - Training Acc 1: 0.07
Epoch 11 - Batch (50/363) - Mini-batch Training loss: 1.0668 - Training Acc 1: 0.09
Epoch 11 - Batch (60/363) - Mini-batch Training loss: 1.0566 - Training Acc 1: 0.11
Epoch 11 - Batch (70/363) - Mini-batch Training loss: 1.0727 - Training Acc 1: 0.12
Epoch 11 - Batch (80/363) - Mini-batch Training loss: 1.1242 - Training Acc 1: 0.14
Epoch 11 - Batch (90/363) - Mini-batch Training loss: 1.1007 - Training Acc 1: 0.16
Epoch 11 - Batch (100/363) - Mini-batch Training loss: 1.1235 - Training Acc 1: 0.18
Epoch 11 - Batch (110/363) - Mini-batch Training loss: 1.1192 - Training Acc 1: 0.20
Epoch 11 - Batch (120/363) - Mini-batch Training loss: 1.1500 - Training Acc 1: 0.21
Epoch 11 - Batch (130/363) - Mini-batch Training loss: 1.1502 - Training Acc 1: 0.23
Epoch 11 - Batch (140/363) - Mini-batch Training loss: 1.1322 - Training Acc 1: 0.25
Epoch 11 - Batch (150/363) - Mini-batch Training loss: 1.1195 - Training Acc 1: 0.27
Epoch 11 - Batch (160/363) - Mini-batch Training loss: 1.1093 - Training Acc 1: 0.29
Epoch 11 - Batch (170/363) - Mini-batch Training loss: 1.1009 - Training Acc 1: 0.30
Epoch 11 - Batch (180/363) - Mini-batch Training loss: 1.0879 - Training Acc 1: 0.33
Epoch 11 - Batch (190/363) - Mini-batch Training loss: 1.0846 - Training Acc 1: 0.35
Epoch 11 - Batch (200/363) - Mini-batch Training loss: 1.0902 - Training Acc 1: 0.36
Epoch 11 - Batch (210/363) - Mini-batch Training loss: 1.0795 - Training Acc 1: 0.38
Epoch 11 - Batch (220/363) - Mini-batch Training loss: 1.0752 - Training Acc 1: 0.40
Epoch 11 - Batch (230/363) - Mini-batch Training loss: 1.0793 - Training Acc 1: 0.42
Epoch 11 - Batch (240/363) - Mini-batch Training loss: 1.0606 - Training Acc 1: 0.44
Epoch 11 - Batch (250/363) - Mini-batch Training loss: 1.0571 - Training Acc 1: 0.46
Epoch 11 - Batch (260/363) - Mini-batch Training loss: 1.0526 - Training Acc 1: 0.48
Epoch 11 - Batch (270/363) - Mini-batch Training loss: 1.0478 - Training Acc 1: 0.49
Epoch 11 - Batch (280/363) - Mini-batch Training loss: 1.0493 - Training Acc 1: 0.51
Epoch 11 - Batch (290/363) - Mini-batch Training loss: 1.0371 - Training Acc 1: 0.54
Epoch 11 - Batch (300/363) - Mini-batch Training loss: 1.0415 - Training Acc 1: 0.55
Epoch 11 - Batch (310/363) - Mini-batch Training loss: 1.0412 - Training Acc 1: 0.57
Epoch 11 - Batch (320/363) - Mini-batch Training loss: 1.0393 - Training Acc 1: 0.59
Epoch 11 - Batch (330/363) - Mini-batch Training loss: 1.0449 - Training Acc 1: 0.61
Epoch 11 - Batch (340/363) - Mini-batch Training loss: 1.0413 - Training Acc 1: 0.63
Epoch 11 - Batch (350/363) - Mini-batch Training loss: 1.0340 - Training Acc 1: 0.65
Epoch 11 - Batch (360/363) - Mini-batch Training loss: 1.0292 - Training Acc 1: 0.67
Epoch 11 - Full-batch Training loss: 1.0342 - Training Acc 1: 0.67
Validation set: Average loss: 0.9778, Accuracy: 248.0/363 (68%)

0.6831955922865014
Epoch 12 - Batch (0/363) - Mini-batch Training loss: 0.5639 - Training Acc 1: 0.00
Epoch 12 - Batch (10/363) - Mini-batch Training loss: 0.9197 - Training Acc 1: 0.02
Epoch 12 - Batch (20/363) - Mini-batch Training loss: 1.0734 - Training Acc 1: 0.04
Epoch 12 - Batch (30/363) - Mini-batch Training loss: 1.1216 - Training Acc 1: 0.05
Epoch 12 - Batch (40/363) - Mini-batch Training loss: 1.1208 - Training Acc 1: 0.07
Epoch 12 - Batch (50/363) - Mini-batch Training loss: 1.1154 - Training Acc 1: 0.09
Epoch 12 - Batch (60/363) - Mini-batch Training loss: 1.0694 - Training Acc 1: 0.11
Epoch 12 - Batch (70/363) - Mini-batch Training loss: 1.0023 - Training Acc 1: 0.13
Epoch 12 - Batch (80/363) - Mini-batch Training loss: 0.9942 - Training Acc 1: 0.15
Epoch 12 - Batch (90/363) - Mini-batch Training loss: 0.9917 - Training Acc 1: 0.17
Epoch 12 - Batch (100/363) - Mini-batch Training loss: 1.0074 - Training Acc 1: 0.18
Epoch 12 - Batch (110/363) - Mini-batch Training loss: 1.0009 - Training Acc 1: 0.20
Epoch 12 - Batch (120/363) - Mini-batch Training loss: 0.9771 - Training Acc 1: 0.22
Epoch 12 - Batch (130/363) - Mini-batch Training loss: 0.9500 - Training Acc 1: 0.25
Epoch 12 - Batch (140/363) - Mini-batch Training loss: 0.9333 - Training Acc 1: 0.27
Epoch 12 - Batch (150/363) - Mini-batch Training loss: 0.9377 - Training Acc 1: 0.29
Epoch 12 - Batch (160/363) - Mini-batch Training loss: 0.9497 - Training Acc 1: 0.30
Epoch 12 - Batch (170/363) - Mini-batch Training loss: 0.9631 - Training Acc 1: 0.32
Epoch 12 - Batch (180/363) - Mini-batch Training loss: 0.9695 - Training Acc 1: 0.34
Epoch 12 - Batch (190/363) - Mini-batch Training loss: 0.9718 - Training Acc 1: 0.36
Epoch 12 - Batch (200/363) - Mini-batch Training loss: 0.9705 - Training Acc 1: 0.38
Epoch 12 - Batch (210/363) - Mini-batch Training loss: 0.9771 - Training Acc 1: 0.40
Epoch 12 - Batch (220/363) - Mini-batch Training loss: 0.9775 - Training Acc 1: 0.42
Epoch 12 - Batch (230/363) - Mini-batch Training loss: 0.9755 - Training Acc 1: 0.44
Epoch 12 - Batch (240/363) - Mini-batch Training loss: 0.9720 - Training Acc 1: 0.46
Epoch 12 - Batch (250/363) - Mini-batch Training loss: 0.9885 - Training Acc 1: 0.47
Epoch 12 - Batch (260/363) - Mini-batch Training loss: 0.9990 - Training Acc 1: 0.49
Epoch 12 - Batch (270/363) - Mini-batch Training loss: 0.9879 - Training Acc 1: 0.51
Epoch 12 - Batch (280/363) - Mini-batch Training loss: 0.9899 - Training Acc 1: 0.53
Epoch 12 - Batch (290/363) - Mini-batch Training loss: 0.9835 - Training Acc 1: 0.55
Epoch 12 - Batch (300/363) - Mini-batch Training loss: 0.9869 - Training Acc 1: 0.57
Epoch 12 - Batch (310/363) - Mini-batch Training loss: 0.9843 - Training Acc 1: 0.58
Epoch 12 - Batch (320/363) - Mini-batch Training loss: 0.9802 - Training Acc 1: 0.61
Epoch 12 - Batch (330/363) - Mini-batch Training loss: 0.9854 - Training Acc 1: 0.63
Epoch 12 - Batch (340/363) - Mini-batch Training loss: 0.9874 - Training Acc 1: 0.64
Epoch 12 - Batch (350/363) - Mini-batch Training loss: 0.9866 - Training Acc 1: 0.66
Epoch 12 - Batch (360/363) - Mini-batch Training loss: 0.9850 - Training Acc 1: 0.68
Epoch 12 - Full-batch Training loss: 0.9847 - Training Acc 1: 0.68
Validation set: Average loss: 1.0103, Accuracy: 253.0/363 (70%)

0.696969696969697
Epoch 13 - Batch (0/363) - Mini-batch Training loss: 0.9473 - Training Acc 1: 0.00
Epoch 13 - Batch (10/363) - Mini-batch Training loss: 1.1777 - Training Acc 1: 0.02
Epoch 13 - Batch (20/363) - Mini-batch Training loss: 1.0147 - Training Acc 1: 0.04
Epoch 13 - Batch (30/363) - Mini-batch Training loss: 0.9828 - Training Acc 1: 0.06
Epoch 13 - Batch (40/363) - Mini-batch Training loss: 0.9603 - Training Acc 1: 0.08
Epoch 13 - Batch (50/363) - Mini-batch Training loss: 1.0142 - Training Acc 1: 0.10
Epoch 13 - Batch (60/363) - Mini-batch Training loss: 0.9439 - Training Acc 1: 0.12
Epoch 13 - Batch (70/363) - Mini-batch Training loss: 0.9512 - Training Acc 1: 0.14
Epoch 13 - Batch (80/363) - Mini-batch Training loss: 0.9385 - Training Acc 1: 0.16
Epoch 13 - Batch (90/363) - Mini-batch Training loss: 0.9392 - Training Acc 1: 0.18
Epoch 13 - Batch (100/363) - Mini-batch Training loss: 0.9537 - Training Acc 1: 0.19
Epoch 13 - Batch (110/363) - Mini-batch Training loss: 0.9358 - Training Acc 1: 0.21
Epoch 13 - Batch (120/363) - Mini-batch Training loss: 0.9362 - Training Acc 1: 0.23
Epoch 13 - Batch (130/363) - Mini-batch Training loss: 0.9412 - Training Acc 1: 0.25
Epoch 13 - Batch (140/363) - Mini-batch Training loss: 0.9494 - Training Acc 1: 0.27
Epoch 13 - Batch (150/363) - Mini-batch Training loss: 0.9606 - Training Acc 1: 0.29
Epoch 13 - Batch (160/363) - Mini-batch Training loss: 0.9759 - Training Acc 1: 0.31
Epoch 13 - Batch (170/363) - Mini-batch Training loss: 0.9737 - Training Acc 1: 0.33
Epoch 13 - Batch (180/363) - Mini-batch Training loss: 0.9671 - Training Acc 1: 0.35
Epoch 13 - Batch (190/363) - Mini-batch Training loss: 0.9526 - Training Acc 1: 0.37
Epoch 13 - Batch (200/363) - Mini-batch Training loss: 0.9490 - Training Acc 1: 0.39
Epoch 13 - Batch (210/363) - Mini-batch Training loss: 0.9603 - Training Acc 1: 0.41
Epoch 13 - Batch (220/363) - Mini-batch Training loss: 0.9569 - Training Acc 1: 0.43
Epoch 13 - Batch (230/363) - Mini-batch Training loss: 0.9494 - Training Acc 1: 0.45
Epoch 13 - Batch (240/363) - Mini-batch Training loss: 0.9498 - Training Acc 1: 0.47
Epoch 13 - Batch (250/363) - Mini-batch Training loss: 0.9562 - Training Acc 1: 0.49
Epoch 13 - Batch (260/363) - Mini-batch Training loss: 0.9504 - Training Acc 1: 0.51
Epoch 13 - Batch (270/363) - Mini-batch Training loss: 0.9556 - Training Acc 1: 0.52
Epoch 13 - Batch (280/363) - Mini-batch Training loss: 0.9543 - Training Acc 1: 0.54
Epoch 13 - Batch (290/363) - Mini-batch Training loss: 0.9626 - Training Acc 1: 0.56
Epoch 13 - Batch (300/363) - Mini-batch Training loss: 0.9534 - Training Acc 1: 0.58
Epoch 13 - Batch (310/363) - Mini-batch Training loss: 0.9540 - Training Acc 1: 0.60
Epoch 13 - Batch (320/363) - Mini-batch Training loss: 0.9526 - Training Acc 1: 0.62
Epoch 13 - Batch (330/363) - Mini-batch Training loss: 0.9567 - Training Acc 1: 0.63
Epoch 13 - Batch (340/363) - Mini-batch Training loss: 0.9578 - Training Acc 1: 0.65
Epoch 13 - Batch (350/363) - Mini-batch Training loss: 0.9529 - Training Acc 1: 0.67
Epoch 13 - Batch (360/363) - Mini-batch Training loss: 0.9620 - Training Acc 1: 0.69
Epoch 13 - Full-batch Training loss: 0.9635 - Training Acc 1: 0.69
Validation set: Average loss: 0.8948, Accuracy: 257.0/363 (71%)

0.7079889807162535
Epoch 14 - Batch (0/363) - Mini-batch Training loss: 1.0788 - Training Acc 1: 0.00
Epoch 14 - Batch (10/363) - Mini-batch Training loss: 1.1126 - Training Acc 1: 0.02
Epoch 14 - Batch (20/363) - Mini-batch Training loss: 0.9324 - Training Acc 1: 0.04
Epoch 14 - Batch (30/363) - Mini-batch Training loss: 0.8630 - Training Acc 1: 0.06
Epoch 14 - Batch (40/363) - Mini-batch Training loss: 0.9665 - Training Acc 1: 0.08
Epoch 14 - Batch (50/363) - Mini-batch Training loss: 0.9134 - Training Acc 1: 0.10
Epoch 14 - Batch (60/363) - Mini-batch Training loss: 0.8815 - Training Acc 1: 0.12
Epoch 14 - Batch (70/363) - Mini-batch Training loss: 0.8525 - Training Acc 1: 0.14
Epoch 14 - Batch (80/363) - Mini-batch Training loss: 0.8639 - Training Acc 1: 0.16
Epoch 14 - Batch (90/363) - Mini-batch Training loss: 0.8724 - Training Acc 1: 0.18
Epoch 14 - Batch (100/363) - Mini-batch Training loss: 0.8636 - Training Acc 1: 0.20
Epoch 14 - Batch (110/363) - Mini-batch Training loss: 0.8526 - Training Acc 1: 0.22
Epoch 14 - Batch (120/363) - Mini-batch Training loss: 0.8645 - Training Acc 1: 0.24
Epoch 14 - Batch (130/363) - Mini-batch Training loss: 0.8768 - Training Acc 1: 0.26
Epoch 14 - Batch (140/363) - Mini-batch Training loss: 0.8751 - Training Acc 1: 0.28
Epoch 14 - Batch (150/363) - Mini-batch Training loss: 0.8797 - Training Acc 1: 0.30
Epoch 14 - Batch (160/363) - Mini-batch Training loss: 0.8745 - Training Acc 1: 0.32
Epoch 14 - Batch (170/363) - Mini-batch Training loss: 0.8698 - Training Acc 1: 0.34
Epoch 14 - Batch (180/363) - Mini-batch Training loss: 0.8836 - Training Acc 1: 0.36
Epoch 14 - Batch (190/363) - Mini-batch Training loss: 0.8895 - Training Acc 1: 0.38
Epoch 14 - Batch (200/363) - Mini-batch Training loss: 0.8815 - Training Acc 1: 0.40
Epoch 14 - Batch (210/363) - Mini-batch Training loss: 0.8766 - Training Acc 1: 0.42
Epoch 14 - Batch (220/363) - Mini-batch Training loss: 0.8957 - Training Acc 1: 0.44
Epoch 14 - Batch (230/363) - Mini-batch Training loss: 0.9029 - Training Acc 1: 0.45
Epoch 14 - Batch (240/363) - Mini-batch Training loss: 0.9189 - Training Acc 1: 0.47
Epoch 14 - Batch (250/363) - Mini-batch Training loss: 0.9123 - Training Acc 1: 0.49
Epoch 14 - Batch (260/363) - Mini-batch Training loss: 0.9258 - Training Acc 1: 0.51
Epoch 14 - Batch (270/363) - Mini-batch Training loss: 0.9248 - Training Acc 1: 0.53
Epoch 14 - Batch (280/363) - Mini-batch Training loss: 0.9258 - Training Acc 1: 0.55
Epoch 14 - Batch (290/363) - Mini-batch Training loss: 0.9238 - Training Acc 1: 0.57
Epoch 14 - Batch (300/363) - Mini-batch Training loss: 0.9183 - Training Acc 1: 0.59
Epoch 14 - Batch (310/363) - Mini-batch Training loss: 0.9200 - Training Acc 1: 0.61
Epoch 14 - Batch (320/363) - Mini-batch Training loss: 0.9179 - Training Acc 1: 0.63
Epoch 14 - Batch (330/363) - Mini-batch Training loss: 0.9251 - Training Acc 1: 0.64
Epoch 14 - Batch (340/363) - Mini-batch Training loss: 0.9331 - Training Acc 1: 0.66
Epoch 14 - Batch (350/363) - Mini-batch Training loss: 0.9334 - Training Acc 1: 0.67
Epoch 14 - Batch (360/363) - Mini-batch Training loss: 0.9328 - Training Acc 1: 0.69
Epoch 14 - Full-batch Training loss: 0.9319 - Training Acc 1: 0.70
Validation set: Average loss: 0.9503, Accuracy: 257.0/363 (71%)

Epoch 15 - Batch (0/363) - Mini-batch Training loss: 2.1230 - Training Acc 1: 0.00
Epoch 15 - Batch (10/363) - Mini-batch Training loss: 1.0632 - Training Acc 1: 0.02
Epoch 15 - Batch (20/363) - Mini-batch Training loss: 0.9731 - Training Acc 1: 0.04
Epoch 15 - Batch (30/363) - Mini-batch Training loss: 0.9750 - Training Acc 1: 0.06
Epoch 15 - Batch (40/363) - Mini-batch Training loss: 0.9327 - Training Acc 1: 0.08
Epoch 15 - Batch (50/363) - Mini-batch Training loss: 0.8792 - Training Acc 1: 0.10
Epoch 15 - Batch (60/363) - Mini-batch Training loss: 0.8330 - Training Acc 1: 0.12
Epoch 15 - Batch (70/363) - Mini-batch Training loss: 0.8363 - Training Acc 1: 0.14
Epoch 15 - Batch (80/363) - Mini-batch Training loss: 0.8197 - Training Acc 1: 0.16
Epoch 15 - Batch (90/363) - Mini-batch Training loss: 0.8109 - Training Acc 1: 0.18
Epoch 15 - Batch (100/363) - Mini-batch Training loss: 0.8374 - Training Acc 1: 0.20
Epoch 15 - Batch (110/363) - Mini-batch Training loss: 0.8283 - Training Acc 1: 0.22
Epoch 15 - Batch (120/363) - Mini-batch Training loss: 0.8533 - Training Acc 1: 0.24
Epoch 15 - Batch (130/363) - Mini-batch Training loss: 0.8598 - Training Acc 1: 0.26
Epoch 15 - Batch (140/363) - Mini-batch Training loss: 0.9025 - Training Acc 1: 0.27
Epoch 15 - Batch (150/363) - Mini-batch Training loss: 0.9200 - Training Acc 1: 0.29
Epoch 15 - Batch (160/363) - Mini-batch Training loss: 0.9282 - Training Acc 1: 0.31
Epoch 15 - Batch (170/363) - Mini-batch Training loss: 0.9146 - Training Acc 1: 0.33
Epoch 15 - Batch (180/363) - Mini-batch Training loss: 0.9075 - Training Acc 1: 0.35
Epoch 15 - Batch (190/363) - Mini-batch Training loss: 0.9245 - Training Acc 1: 0.37
Epoch 15 - Batch (200/363) - Mini-batch Training loss: 0.9117 - Training Acc 1: 0.39
Epoch 15 - Batch (210/363) - Mini-batch Training loss: 0.9067 - Training Acc 1: 0.41
Epoch 15 - Batch (220/363) - Mini-batch Training loss: 0.9030 - Training Acc 1: 0.43
Epoch 15 - Batch (230/363) - Mini-batch Training loss: 0.9140 - Training Acc 1: 0.45
Epoch 15 - Batch (240/363) - Mini-batch Training loss: 0.9098 - Training Acc 1: 0.47
Epoch 15 - Batch (250/363) - Mini-batch Training loss: 0.9240 - Training Acc 1: 0.48
Epoch 15 - Batch (260/363) - Mini-batch Training loss: 0.9294 - Training Acc 1: 0.50
Epoch 15 - Batch (270/363) - Mini-batch Training loss: 0.9101 - Training Acc 1: 0.53
Epoch 15 - Batch (280/363) - Mini-batch Training loss: 0.9019 - Training Acc 1: 0.55
Epoch 15 - Batch (290/363) - Mini-batch Training loss: 0.8975 - Training Acc 1: 0.57
Epoch 15 - Batch (300/363) - Mini-batch Training loss: 0.8941 - Training Acc 1: 0.59
Epoch 15 - Batch (310/363) - Mini-batch Training loss: 0.8905 - Training Acc 1: 0.61
Epoch 15 - Batch (320/363) - Mini-batch Training loss: 0.8877 - Training Acc 1: 0.64
Epoch 15 - Batch (330/363) - Mini-batch Training loss: 0.8926 - Training Acc 1: 0.65
Epoch 15 - Batch (340/363) - Mini-batch Training loss: 0.8993 - Training Acc 1: 0.67
Epoch 15 - Batch (350/363) - Mini-batch Training loss: 0.8923 - Training Acc 1: 0.70
Epoch 15 - Batch (360/363) - Mini-batch Training loss: 0.8860 - Training Acc 1: 0.72
Epoch 15 - Full-batch Training loss: 0.8869 - Training Acc 1: 0.72
Validation set: Average loss: 0.9206, Accuracy: 262.0/363 (72%)

0.721763085399449
Epoch 16 - Batch (0/363) - Mini-batch Training loss: 1.4056 - Training Acc 1: 0.00
Epoch 16 - Batch (10/363) - Mini-batch Training loss: 0.8050 - Training Acc 1: 0.02
Epoch 16 - Batch (20/363) - Mini-batch Training loss: 0.8780 - Training Acc 1: 0.04
Epoch 16 - Batch (30/363) - Mini-batch Training loss: 0.9597 - Training Acc 1: 0.06
Epoch 16 - Batch (40/363) - Mini-batch Training loss: 0.9066 - Training Acc 1: 0.08
Epoch 16 - Batch (50/363) - Mini-batch Training loss: 0.8733 - Training Acc 1: 0.10
Epoch 16 - Batch (60/363) - Mini-batch Training loss: 0.9252 - Training Acc 1: 0.12
Epoch 16 - Batch (70/363) - Mini-batch Training loss: 0.9588 - Training Acc 1: 0.14
Epoch 16 - Batch (80/363) - Mini-batch Training loss: 0.9474 - Training Acc 1: 0.16
Epoch 16 - Batch (90/363) - Mini-batch Training loss: 0.9530 - Training Acc 1: 0.18
Epoch 16 - Batch (100/363) - Mini-batch Training loss: 0.9374 - Training Acc 1: 0.20
Epoch 16 - Batch (110/363) - Mini-batch Training loss: 0.9434 - Training Acc 1: 0.22
Epoch 16 - Batch (120/363) - Mini-batch Training loss: 0.9375 - Training Acc 1: 0.24
Epoch 16 - Batch (130/363) - Mini-batch Training loss: 0.9197 - Training Acc 1: 0.26
Epoch 16 - Batch (140/363) - Mini-batch Training loss: 0.8965 - Training Acc 1: 0.28
Epoch 16 - Batch (150/363) - Mini-batch Training loss: 0.8859 - Training Acc 1: 0.30
Epoch 16 - Batch (160/363) - Mini-batch Training loss: 0.8721 - Training Acc 1: 0.32
Epoch 16 - Batch (170/363) - Mini-batch Training loss: 0.8674 - Training Acc 1: 0.35
Epoch 16 - Batch (180/363) - Mini-batch Training loss: 0.8707 - Training Acc 1: 0.36
Epoch 16 - Batch (190/363) - Mini-batch Training loss: 0.8990 - Training Acc 1: 0.38
Epoch 16 - Batch (200/363) - Mini-batch Training loss: 0.8753 - Training Acc 1: 0.40
Epoch 16 - Batch (210/363) - Mini-batch Training loss: 0.8602 - Training Acc 1: 0.43
Epoch 16 - Batch (220/363) - Mini-batch Training loss: 0.8684 - Training Acc 1: 0.44
Epoch 16 - Batch (230/363) - Mini-batch Training loss: 0.8662 - Training Acc 1: 0.46
Epoch 16 - Batch (240/363) - Mini-batch Training loss: 0.8605 - Training Acc 1: 0.49
Epoch 16 - Batch (250/363) - Mini-batch Training loss: 0.8631 - Training Acc 1: 0.50
Epoch 16 - Batch (260/363) - Mini-batch Training loss: 0.8653 - Training Acc 1: 0.52
Epoch 16 - Batch (270/363) - Mini-batch Training loss: 0.8606 - Training Acc 1: 0.55
Epoch 16 - Batch (280/363) - Mini-batch Training loss: 0.8624 - Training Acc 1: 0.57
Epoch 16 - Batch (290/363) - Mini-batch Training loss: 0.8690 - Training Acc 1: 0.58
Epoch 16 - Batch (300/363) - Mini-batch Training loss: 0.8664 - Training Acc 1: 0.60
Epoch 16 - Batch (310/363) - Mini-batch Training loss: 0.8595 - Training Acc 1: 0.63
Epoch 16 - Batch (320/363) - Mini-batch Training loss: 0.8562 - Training Acc 1: 0.65
Epoch 16 - Batch (330/363) - Mini-batch Training loss: 0.8522 - Training Acc 1: 0.67
Epoch 16 - Batch (340/363) - Mini-batch Training loss: 0.8552 - Training Acc 1: 0.69
Epoch 16 - Batch (350/363) - Mini-batch Training loss: 0.8545 - Training Acc 1: 0.71
Epoch 16 - Batch (360/363) - Mini-batch Training loss: 0.8550 - Training Acc 1: 0.73
Epoch 16 - Full-batch Training loss: 0.8552 - Training Acc 1: 0.73
Validation set: Average loss: 0.8540, Accuracy: 271.0/363 (75%)

0.7465564738292011
Epoch 17 - Batch (0/363) - Mini-batch Training loss: 0.7569 - Training Acc 1: 0.00
Epoch 17 - Batch (10/363) - Mini-batch Training loss: 0.7838 - Training Acc 1: 0.02
Epoch 17 - Batch (20/363) - Mini-batch Training loss: 0.7193 - Training Acc 1: 0.05
Epoch 17 - Batch (30/363) - Mini-batch Training loss: 0.6974 - Training Acc 1: 0.07
Epoch 17 - Batch (40/363) - Mini-batch Training loss: 0.6983 - Training Acc 1: 0.09
Epoch 17 - Batch (50/363) - Mini-batch Training loss: 0.6774 - Training Acc 1: 0.11
Epoch 17 - Batch (60/363) - Mini-batch Training loss: 0.7458 - Training Acc 1: 0.13
Epoch 17 - Batch (70/363) - Mini-batch Training loss: 0.7613 - Training Acc 1: 0.15
Epoch 17 - Batch (80/363) - Mini-batch Training loss: 0.7550 - Training Acc 1: 0.17
Epoch 17 - Batch (90/363) - Mini-batch Training loss: 0.7999 - Training Acc 1: 0.19
Epoch 17 - Batch (100/363) - Mini-batch Training loss: 0.7968 - Training Acc 1: 0.21
Epoch 17 - Batch (110/363) - Mini-batch Training loss: 0.8162 - Training Acc 1: 0.23
Epoch 17 - Batch (120/363) - Mini-batch Training loss: 0.8271 - Training Acc 1: 0.25
Epoch 17 - Batch (130/363) - Mini-batch Training loss: 0.8286 - Training Acc 1: 0.27
Epoch 17 - Batch (140/363) - Mini-batch Training loss: 0.8433 - Training Acc 1: 0.29
Epoch 17 - Batch (150/363) - Mini-batch Training loss: 0.8530 - Training Acc 1: 0.31
Epoch 17 - Batch (160/363) - Mini-batch Training loss: 0.8460 - Training Acc 1: 0.33
Epoch 17 - Batch (170/363) - Mini-batch Training loss: 0.8388 - Training Acc 1: 0.35
Epoch 17 - Batch (180/363) - Mini-batch Training loss: 0.8304 - Training Acc 1: 0.37
Epoch 17 - Batch (190/363) - Mini-batch Training loss: 0.8511 - Training Acc 1: 0.39
Epoch 17 - Batch (200/363) - Mini-batch Training loss: 0.8677 - Training Acc 1: 0.40
Epoch 17 - Batch (210/363) - Mini-batch Training loss: 0.8521 - Training Acc 1: 0.43
Epoch 17 - Batch (220/363) - Mini-batch Training loss: 0.8546 - Training Acc 1: 0.45
Epoch 17 - Batch (230/363) - Mini-batch Training loss: 0.8499 - Training Acc 1: 0.47
Epoch 17 - Batch (240/363) - Mini-batch Training loss: 0.8511 - Training Acc 1: 0.49
Epoch 17 - Batch (250/363) - Mini-batch Training loss: 0.8472 - Training Acc 1: 0.51
Epoch 17 - Batch (260/363) - Mini-batch Training loss: 0.8589 - Training Acc 1: 0.53
Epoch 17 - Batch (270/363) - Mini-batch Training loss: 0.8656 - Training Acc 1: 0.55
Epoch 17 - Batch (280/363) - Mini-batch Training loss: 0.8639 - Training Acc 1: 0.57
Epoch 17 - Batch (290/363) - Mini-batch Training loss: 0.8593 - Training Acc 1: 0.59
Epoch 17 - Batch (300/363) - Mini-batch Training loss: 0.8446 - Training Acc 1: 0.61
Epoch 17 - Batch (310/363) - Mini-batch Training loss: 0.8355 - Training Acc 1: 0.63
Epoch 17 - Batch (320/363) - Mini-batch Training loss: 0.8315 - Training Acc 1: 0.65
Epoch 17 - Batch (330/363) - Mini-batch Training loss: 0.8338 - Training Acc 1: 0.67
Epoch 17 - Batch (340/363) - Mini-batch Training loss: 0.8342 - Training Acc 1: 0.69
Epoch 17 - Batch (350/363) - Mini-batch Training loss: 0.8339 - Training Acc 1: 0.71
Epoch 17 - Batch (360/363) - Mini-batch Training loss: 0.8286 - Training Acc 1: 0.74
Epoch 17 - Full-batch Training loss: 0.8263 - Training Acc 1: 0.74
Validation set: Average loss: 0.9419, Accuracy: 256.0/363 (71%)

Epoch 18 - Batch (0/363) - Mini-batch Training loss: 1.2481 - Training Acc 1: 0.00
Epoch 18 - Batch (10/363) - Mini-batch Training loss: 0.8213 - Training Acc 1: 0.02
Epoch 18 - Batch (20/363) - Mini-batch Training loss: 0.6424 - Training Acc 1: 0.05
Epoch 18 - Batch (30/363) - Mini-batch Training loss: 0.7194 - Training Acc 1: 0.07
Epoch 18 - Batch (40/363) - Mini-batch Training loss: 0.7564 - Training Acc 1: 0.09
Epoch 18 - Batch (50/363) - Mini-batch Training loss: 0.7094 - Training Acc 1: 0.11
Epoch 18 - Batch (60/363) - Mini-batch Training loss: 0.6957 - Training Acc 1: 0.13
Epoch 18 - Batch (70/363) - Mini-batch Training loss: 0.6839 - Training Acc 1: 0.16
Epoch 18 - Batch (80/363) - Mini-batch Training loss: 0.6988 - Training Acc 1: 0.18
Epoch 18 - Batch (90/363) - Mini-batch Training loss: 0.7230 - Training Acc 1: 0.20
Epoch 18 - Batch (100/363) - Mini-batch Training loss: 0.7092 - Training Acc 1: 0.22
Epoch 18 - Batch (110/363) - Mini-batch Training loss: 0.7278 - Training Acc 1: 0.24
Epoch 18 - Batch (120/363) - Mini-batch Training loss: 0.7310 - Training Acc 1: 0.26
Epoch 18 - Batch (130/363) - Mini-batch Training loss: 0.7310 - Training Acc 1: 0.28
Epoch 18 - Batch (140/363) - Mini-batch Training loss: 0.7560 - Training Acc 1: 0.30
Epoch 18 - Batch (150/363) - Mini-batch Training loss: 0.7681 - Training Acc 1: 0.32
Epoch 18 - Batch (160/363) - Mini-batch Training loss: 0.7652 - Training Acc 1: 0.34
Epoch 18 - Batch (170/363) - Mini-batch Training loss: 0.7744 - Training Acc 1: 0.36
Epoch 18 - Batch (180/363) - Mini-batch Training loss: 0.7821 - Training Acc 1: 0.38
Epoch 18 - Batch (190/363) - Mini-batch Training loss: 0.7779 - Training Acc 1: 0.40
Epoch 18 - Batch (200/363) - Mini-batch Training loss: 0.7802 - Training Acc 1: 0.42
Epoch 18 - Batch (210/363) - Mini-batch Training loss: 0.7880 - Training Acc 1: 0.44
Epoch 18 - Batch (220/363) - Mini-batch Training loss: 0.7778 - Training Acc 1: 0.47
Epoch 18 - Batch (230/363) - Mini-batch Training loss: 0.7806 - Training Acc 1: 0.49
Epoch 18 - Batch (240/363) - Mini-batch Training loss: 0.7771 - Training Acc 1: 0.51
Epoch 18 - Batch (250/363) - Mini-batch Training loss: 0.7795 - Training Acc 1: 0.53
Epoch 18 - Batch (260/363) - Mini-batch Training loss: 0.7791 - Training Acc 1: 0.55
Epoch 18 - Batch (270/363) - Mini-batch Training loss: 0.7843 - Training Acc 1: 0.57
Epoch 18 - Batch (280/363) - Mini-batch Training loss: 0.7840 - Training Acc 1: 0.59
Epoch 18 - Batch (290/363) - Mini-batch Training loss: 0.7893 - Training Acc 1: 0.61
Epoch 18 - Batch (300/363) - Mini-batch Training loss: 0.8005 - Training Acc 1: 0.63
Epoch 18 - Batch (310/363) - Mini-batch Training loss: 0.7998 - Training Acc 1: 0.65
Epoch 18 - Batch (320/363) - Mini-batch Training loss: 0.7955 - Training Acc 1: 0.67
Epoch 18 - Batch (330/363) - Mini-batch Training loss: 0.8111 - Training Acc 1: 0.69
Epoch 18 - Batch (340/363) - Mini-batch Training loss: 0.8157 - Training Acc 1: 0.70
Epoch 18 - Batch (350/363) - Mini-batch Training loss: 0.8181 - Training Acc 1: 0.72
Epoch 18 - Batch (360/363) - Mini-batch Training loss: 0.8131 - Training Acc 1: 0.74
Epoch 18 - Full-batch Training loss: 0.8160 - Training Acc 1: 0.75
Validation set: Average loss: 1.0984, Accuracy: 244.0/363 (67%)

Epoch 19 - Batch (0/363) - Mini-batch Training loss: 2.0224 - Training Acc 1: 0.00
Epoch 19 - Batch (10/363) - Mini-batch Training loss: 0.7092 - Training Acc 1: 0.02
Epoch 19 - Batch (20/363) - Mini-batch Training loss: 0.7746 - Training Acc 1: 0.04
Epoch 19 - Batch (30/363) - Mini-batch Training loss: 0.8671 - Training Acc 1: 0.06
Epoch 19 - Batch (40/363) - Mini-batch Training loss: 0.8614 - Training Acc 1: 0.08
Epoch 19 - Batch (50/363) - Mini-batch Training loss: 0.8854 - Training Acc 1: 0.10
Epoch 19 - Batch (60/363) - Mini-batch Training loss: 0.9112 - Training Acc 1: 0.12
Epoch 19 - Batch (70/363) - Mini-batch Training loss: 0.8846 - Training Acc 1: 0.14
Epoch 19 - Batch (80/363) - Mini-batch Training loss: 0.8630 - Training Acc 1: 0.16
Epoch 19 - Batch (90/363) - Mini-batch Training loss: 0.8659 - Training Acc 1: 0.18
Epoch 19 - Batch (100/363) - Mini-batch Training loss: 0.8474 - Training Acc 1: 0.21
Epoch 19 - Batch (110/363) - Mini-batch Training loss: 0.8286 - Training Acc 1: 0.23
Epoch 19 - Batch (120/363) - Mini-batch Training loss: 0.8268 - Training Acc 1: 0.25
Epoch 19 - Batch (130/363) - Mini-batch Training loss: 0.8214 - Training Acc 1: 0.27
Epoch 19 - Batch (140/363) - Mini-batch Training loss: 0.8459 - Training Acc 1: 0.29
Epoch 19 - Batch (150/363) - Mini-batch Training loss: 0.8441 - Training Acc 1: 0.31
Epoch 19 - Batch (160/363) - Mini-batch Training loss: 0.8276 - Training Acc 1: 0.33
Epoch 19 - Batch (170/363) - Mini-batch Training loss: 0.8240 - Training Acc 1: 0.35
Epoch 19 - Batch (180/363) - Mini-batch Training loss: 0.8106 - Training Acc 1: 0.38
Epoch 19 - Batch (190/363) - Mini-batch Training loss: 0.8042 - Training Acc 1: 0.40
Epoch 19 - Batch (200/363) - Mini-batch Training loss: 0.8132 - Training Acc 1: 0.42
Epoch 19 - Batch (210/363) - Mini-batch Training loss: 0.8066 - Training Acc 1: 0.44
Epoch 19 - Batch (220/363) - Mini-batch Training loss: 0.7902 - Training Acc 1: 0.46
Epoch 19 - Batch (230/363) - Mini-batch Training loss: 0.7946 - Training Acc 1: 0.48
Epoch 19 - Batch (240/363) - Mini-batch Training loss: 0.7969 - Training Acc 1: 0.50
Epoch 19 - Batch (250/363) - Mini-batch Training loss: 0.8063 - Training Acc 1: 0.52
Epoch 19 - Batch (260/363) - Mini-batch Training loss: 0.8024 - Training Acc 1: 0.55
Epoch 19 - Batch (270/363) - Mini-batch Training loss: 0.8036 - Training Acc 1: 0.57
Epoch 19 - Batch (280/363) - Mini-batch Training loss: 0.8109 - Training Acc 1: 0.59
Epoch 19 - Batch (290/363) - Mini-batch Training loss: 0.8130 - Training Acc 1: 0.61
Epoch 19 - Batch (300/363) - Mini-batch Training loss: 0.8065 - Training Acc 1: 0.63
Epoch 19 - Batch (310/363) - Mini-batch Training loss: 0.8259 - Training Acc 1: 0.64
Epoch 19 - Batch (320/363) - Mini-batch Training loss: 0.8258 - Training Acc 1: 0.67
Epoch 19 - Batch (330/363) - Mini-batch Training loss: 0.8215 - Training Acc 1: 0.69
Epoch 19 - Batch (340/363) - Mini-batch Training loss: 0.8193 - Training Acc 1: 0.71
Epoch 19 - Batch (350/363) - Mini-batch Training loss: 0.8136 - Training Acc 1: 0.73
Epoch 19 - Batch (360/363) - Mini-batch Training loss: 0.8140 - Training Acc 1: 0.75
Epoch 19 - Full-batch Training loss: 0.8158 - Training Acc 1: 0.75
Validation set: Average loss: 0.8773, Accuracy: 265.0/363 (73%)

Epoch 20 - Batch (0/363) - Mini-batch Training loss: 0.9171 - Training Acc 1: 0.00
Epoch 20 - Batch (10/363) - Mini-batch Training loss: 0.6677 - Training Acc 1: 0.02
Epoch 20 - Batch (20/363) - Mini-batch Training loss: 0.6466 - Training Acc 1: 0.04
Epoch 20 - Batch (30/363) - Mini-batch Training loss: 0.7683 - Training Acc 1: 0.06
Epoch 20 - Batch (40/363) - Mini-batch Training loss: 0.7282 - Training Acc 1: 0.09
Epoch 20 - Batch (50/363) - Mini-batch Training loss: 0.6851 - Training Acc 1: 0.11
Epoch 20 - Batch (60/363) - Mini-batch Training loss: 0.6375 - Training Acc 1: 0.13
Epoch 20 - Batch (70/363) - Mini-batch Training loss: 0.6786 - Training Acc 1: 0.15
Epoch 20 - Batch (80/363) - Mini-batch Training loss: 0.6603 - Training Acc 1: 0.17
Epoch 20 - Batch (90/363) - Mini-batch Training loss: 0.6604 - Training Acc 1: 0.20
Epoch 20 - Batch (100/363) - Mini-batch Training loss: 0.6646 - Training Acc 1: 0.22
Epoch 20 - Batch (110/363) - Mini-batch Training loss: 0.6702 - Training Acc 1: 0.24
Epoch 20 - Batch (120/363) - Mini-batch Training loss: 0.6896 - Training Acc 1: 0.26
Epoch 20 - Batch (130/363) - Mini-batch Training loss: 0.6742 - Training Acc 1: 0.28
Epoch 20 - Batch (140/363) - Mini-batch Training loss: 0.6548 - Training Acc 1: 0.31
Epoch 20 - Batch (150/363) - Mini-batch Training loss: 0.6479 - Training Acc 1: 0.33
Epoch 20 - Batch (160/363) - Mini-batch Training loss: 0.6631 - Training Acc 1: 0.35
Epoch 20 - Batch (170/363) - Mini-batch Training loss: 0.6741 - Training Acc 1: 0.38
Epoch 20 - Batch (180/363) - Mini-batch Training loss: 0.6890 - Training Acc 1: 0.40
Epoch 20 - Batch (190/363) - Mini-batch Training loss: 0.6914 - Training Acc 1: 0.42
Epoch 20 - Batch (200/363) - Mini-batch Training loss: 0.7039 - Training Acc 1: 0.44
Epoch 20 - Batch (210/363) - Mini-batch Training loss: 0.7016 - Training Acc 1: 0.46
Epoch 20 - Batch (220/363) - Mini-batch Training loss: 0.7017 - Training Acc 1: 0.48
Epoch 20 - Batch (230/363) - Mini-batch Training loss: 0.7168 - Training Acc 1: 0.50
Epoch 20 - Batch (240/363) - Mini-batch Training loss: 0.7098 - Training Acc 1: 0.52
Epoch 20 - Batch (250/363) - Mini-batch Training loss: 0.7290 - Training Acc 1: 0.54
Epoch 20 - Batch (260/363) - Mini-batch Training loss: 0.7423 - Training Acc 1: 0.56
Epoch 20 - Batch (270/363) - Mini-batch Training loss: 0.7649 - Training Acc 1: 0.57
Epoch 20 - Batch (280/363) - Mini-batch Training loss: 0.7635 - Training Acc 1: 0.59
Epoch 20 - Batch (290/363) - Mini-batch Training loss: 0.7826 - Training Acc 1: 0.61
Epoch 20 - Batch (300/363) - Mini-batch Training loss: 0.7823 - Training Acc 1: 0.63
Epoch 20 - Batch (310/363) - Mini-batch Training loss: 0.7808 - Training Acc 1: 0.65
Epoch 20 - Batch (320/363) - Mini-batch Training loss: 0.7816 - Training Acc 1: 0.67
Epoch 20 - Batch (330/363) - Mini-batch Training loss: 0.7780 - Training Acc 1: 0.69
Epoch 20 - Batch (340/363) - Mini-batch Training loss: 0.7786 - Training Acc 1: 0.71
Epoch 20 - Batch (350/363) - Mini-batch Training loss: 0.7789 - Training Acc 1: 0.73
Epoch 20 - Batch (360/363) - Mini-batch Training loss: 0.7749 - Training Acc 1: 0.75
Epoch 20 - Full-batch Training loss: 0.7751 - Training Acc 1: 0.75
Validation set: Average loss: 0.8128, Accuracy: 275.0/363 (76%)

0.7575757575757576
Epoch 21 - Batch (0/363) - Mini-batch Training loss: 0.5715 - Training Acc 1: 0.00
Epoch 21 - Batch (10/363) - Mini-batch Training loss: 0.5972 - Training Acc 1: 0.02
Epoch 21 - Batch (20/363) - Mini-batch Training loss: 0.6944 - Training Acc 1: 0.04
Epoch 21 - Batch (30/363) - Mini-batch Training loss: 0.5820 - Training Acc 1: 0.07
Epoch 21 - Batch (40/363) - Mini-batch Training loss: 0.6423 - Training Acc 1: 0.09
Epoch 21 - Batch (50/363) - Mini-batch Training loss: 0.7572 - Training Acc 1: 0.10
Epoch 21 - Batch (60/363) - Mini-batch Training loss: 0.7559 - Training Acc 1: 0.13
Epoch 21 - Batch (70/363) - Mini-batch Training loss: 0.7299 - Training Acc 1: 0.15
Epoch 21 - Batch (80/363) - Mini-batch Training loss: 0.7517 - Training Acc 1: 0.17
Epoch 21 - Batch (90/363) - Mini-batch Training loss: 0.7770 - Training Acc 1: 0.19
Epoch 21 - Batch (100/363) - Mini-batch Training loss: 0.7690 - Training Acc 1: 0.21
Epoch 21 - Batch (110/363) - Mini-batch Training loss: 0.7554 - Training Acc 1: 0.23
Epoch 21 - Batch (120/363) - Mini-batch Training loss: 0.7339 - Training Acc 1: 0.25
Epoch 21 - Batch (130/363) - Mini-batch Training loss: 0.7531 - Training Acc 1: 0.27
Epoch 21 - Batch (140/363) - Mini-batch Training loss: 0.7444 - Training Acc 1: 0.29
Epoch 21 - Batch (150/363) - Mini-batch Training loss: 0.7327 - Training Acc 1: 0.31
Epoch 21 - Batch (160/363) - Mini-batch Training loss: 0.7281 - Training Acc 1: 0.33
Epoch 21 - Batch (170/363) - Mini-batch Training loss: 0.7235 - Training Acc 1: 0.35
Epoch 21 - Batch (180/363) - Mini-batch Training loss: 0.7210 - Training Acc 1: 0.38
Epoch 21 - Batch (190/363) - Mini-batch Training loss: 0.7266 - Training Acc 1: 0.39
Epoch 21 - Batch (200/363) - Mini-batch Training loss: 0.7382 - Training Acc 1: 0.42
Epoch 21 - Batch (210/363) - Mini-batch Training loss: 0.7405 - Training Acc 1: 0.44
Epoch 21 - Batch (220/363) - Mini-batch Training loss: 0.7330 - Training Acc 1: 0.46
Epoch 21 - Batch (230/363) - Mini-batch Training loss: 0.7459 - Training Acc 1: 0.48
Epoch 21 - Batch (240/363) - Mini-batch Training loss: 0.7392 - Training Acc 1: 0.51
Epoch 21 - Batch (250/363) - Mini-batch Training loss: 0.7385 - Training Acc 1: 0.53
Epoch 21 - Batch (260/363) - Mini-batch Training loss: 0.7453 - Training Acc 1: 0.55
Epoch 21 - Batch (270/363) - Mini-batch Training loss: 0.7384 - Training Acc 1: 0.57
Epoch 21 - Batch (280/363) - Mini-batch Training loss: 0.7396 - Training Acc 1: 0.59
Epoch 21 - Batch (290/363) - Mini-batch Training loss: 0.7345 - Training Acc 1: 0.61
Epoch 21 - Batch (300/363) - Mini-batch Training loss: 0.7365 - Training Acc 1: 0.63
Epoch 21 - Batch (310/363) - Mini-batch Training loss: 0.7312 - Training Acc 1: 0.65
Epoch 21 - Batch (320/363) - Mini-batch Training loss: 0.7217 - Training Acc 1: 0.68
Epoch 21 - Batch (330/363) - Mini-batch Training loss: 0.7312 - Training Acc 1: 0.69
Epoch 21 - Batch (340/363) - Mini-batch Training loss: 0.7351 - Training Acc 1: 0.71
Epoch 21 - Batch (350/363) - Mini-batch Training loss: 0.7301 - Training Acc 1: 0.74
Epoch 21 - Batch (360/363) - Mini-batch Training loss: 0.7280 - Training Acc 1: 0.76
Epoch 21 - Full-batch Training loss: 0.7256 - Training Acc 1: 0.76
Validation set: Average loss: 0.8117, Accuracy: 276.0/363 (76%)

0.7603305785123967
Epoch 22 - Batch (0/363) - Mini-batch Training loss: 1.1631 - Training Acc 1: 0.00
Epoch 22 - Batch (10/363) - Mini-batch Training loss: 0.8086 - Training Acc 1: 0.02
Epoch 22 - Batch (20/363) - Mini-batch Training loss: 0.8028 - Training Acc 1: 0.04
Epoch 22 - Batch (30/363) - Mini-batch Training loss: 0.7788 - Training Acc 1: 0.06
Epoch 22 - Batch (40/363) - Mini-batch Training loss: 0.7974 - Training Acc 1: 0.08
Epoch 22 - Batch (50/363) - Mini-batch Training loss: 0.7830 - Training Acc 1: 0.10
Epoch 22 - Batch (60/363) - Mini-batch Training loss: 0.7529 - Training Acc 1: 0.13
Epoch 22 - Batch (70/363) - Mini-batch Training loss: 0.7411 - Training Acc 1: 0.15
Epoch 22 - Batch (80/363) - Mini-batch Training loss: 0.7225 - Training Acc 1: 0.17
Epoch 22 - Batch (90/363) - Mini-batch Training loss: 0.6926 - Training Acc 1: 0.19
Epoch 22 - Batch (100/363) - Mini-batch Training loss: 0.6799 - Training Acc 1: 0.21
Epoch 22 - Batch (110/363) - Mini-batch Training loss: 0.6662 - Training Acc 1: 0.24
Epoch 22 - Batch (120/363) - Mini-batch Training loss: 0.6822 - Training Acc 1: 0.26
Epoch 22 - Batch (130/363) - Mini-batch Training loss: 0.6697 - Training Acc 1: 0.28
Epoch 22 - Batch (140/363) - Mini-batch Training loss: 0.6669 - Training Acc 1: 0.30
Epoch 22 - Batch (150/363) - Mini-batch Training loss: 0.6630 - Training Acc 1: 0.32
Epoch 22 - Batch (160/363) - Mini-batch Training loss: 0.6646 - Training Acc 1: 0.35
Epoch 22 - Batch (170/363) - Mini-batch Training loss: 0.6762 - Training Acc 1: 0.37
Epoch 22 - Batch (180/363) - Mini-batch Training loss: 0.6744 - Training Acc 1: 0.39
Epoch 22 - Batch (190/363) - Mini-batch Training loss: 0.6748 - Training Acc 1: 0.41
Epoch 22 - Batch (200/363) - Mini-batch Training loss: 0.6832 - Training Acc 1: 0.43
Epoch 22 - Batch (210/363) - Mini-batch Training loss: 0.6769 - Training Acc 1: 0.45
Epoch 22 - Batch (220/363) - Mini-batch Training loss: 0.6795 - Training Acc 1: 0.48
Epoch 22 - Batch (230/363) - Mini-batch Training loss: 0.6926 - Training Acc 1: 0.49
Epoch 22 - Batch (240/363) - Mini-batch Training loss: 0.6994 - Training Acc 1: 0.52
Epoch 22 - Batch (250/363) - Mini-batch Training loss: 0.7095 - Training Acc 1: 0.53
Epoch 22 - Batch (260/363) - Mini-batch Training loss: 0.7089 - Training Acc 1: 0.55
Epoch 22 - Batch (270/363) - Mini-batch Training loss: 0.7097 - Training Acc 1: 0.58
Epoch 22 - Batch (280/363) - Mini-batch Training loss: 0.7163 - Training Acc 1: 0.59
Epoch 22 - Batch (290/363) - Mini-batch Training loss: 0.7152 - Training Acc 1: 0.62
Epoch 22 - Batch (300/363) - Mini-batch Training loss: 0.7217 - Training Acc 1: 0.64
Epoch 22 - Batch (310/363) - Mini-batch Training loss: 0.7229 - Training Acc 1: 0.66
Epoch 22 - Batch (320/363) - Mini-batch Training loss: 0.7270 - Training Acc 1: 0.68
Epoch 22 - Batch (330/363) - Mini-batch Training loss: 0.7294 - Training Acc 1: 0.70
Epoch 22 - Batch (340/363) - Mini-batch Training loss: 0.7227 - Training Acc 1: 0.72
Epoch 22 - Batch (350/363) - Mini-batch Training loss: 0.7304 - Training Acc 1: 0.74
Epoch 22 - Batch (360/363) - Mini-batch Training loss: 0.7309 - Training Acc 1: 0.76
Epoch 22 - Full-batch Training loss: 0.7341 - Training Acc 1: 0.76
Validation set: Average loss: 0.8070, Accuracy: 271.0/363 (75%)

Epoch 23 - Batch (0/363) - Mini-batch Training loss: 0.1641 - Training Acc 1: 0.00
Epoch 23 - Batch (10/363) - Mini-batch Training loss: 0.4963 - Training Acc 1: 0.03
Epoch 23 - Batch (20/363) - Mini-batch Training loss: 0.4928 - Training Acc 1: 0.05
Epoch 23 - Batch (30/363) - Mini-batch Training loss: 0.4818 - Training Acc 1: 0.07
Epoch 23 - Batch (40/363) - Mini-batch Training loss: 0.5276 - Training Acc 1: 0.10
Epoch 23 - Batch (50/363) - Mini-batch Training loss: 0.5016 - Training Acc 1: 0.12
Epoch 23 - Batch (60/363) - Mini-batch Training loss: 0.5375 - Training Acc 1: 0.14
Epoch 23 - Batch (70/363) - Mini-batch Training loss: 0.5836 - Training Acc 1: 0.16
Epoch 23 - Batch (80/363) - Mini-batch Training loss: 0.5841 - Training Acc 1: 0.18
Epoch 23 - Batch (90/363) - Mini-batch Training loss: 0.6407 - Training Acc 1: 0.20
Epoch 23 - Batch (100/363) - Mini-batch Training loss: 0.6442 - Training Acc 1: 0.22
Epoch 23 - Batch (110/363) - Mini-batch Training loss: 0.6842 - Training Acc 1: 0.24
Epoch 23 - Batch (120/363) - Mini-batch Training loss: 0.6715 - Training Acc 1: 0.27
Epoch 23 - Batch (130/363) - Mini-batch Training loss: 0.6601 - Training Acc 1: 0.29
Epoch 23 - Batch (140/363) - Mini-batch Training loss: 0.6751 - Training Acc 1: 0.31
Epoch 23 - Batch (150/363) - Mini-batch Training loss: 0.6738 - Training Acc 1: 0.33
Epoch 23 - Batch (160/363) - Mini-batch Training loss: 0.6724 - Training Acc 1: 0.36
Epoch 23 - Batch (170/363) - Mini-batch Training loss: 0.6607 - Training Acc 1: 0.38
Epoch 23 - Batch (180/363) - Mini-batch Training loss: 0.6716 - Training Acc 1: 0.40
Epoch 23 - Batch (190/363) - Mini-batch Training loss: 0.6624 - Training Acc 1: 0.43
Epoch 23 - Batch (200/363) - Mini-batch Training loss: 0.6497 - Training Acc 1: 0.45
Epoch 23 - Batch (210/363) - Mini-batch Training loss: 0.6579 - Training Acc 1: 0.47
Epoch 23 - Batch (220/363) - Mini-batch Training loss: 0.6638 - Training Acc 1: 0.49
Epoch 23 - Batch (230/363) - Mini-batch Training loss: 0.6635 - Training Acc 1: 0.51
Epoch 23 - Batch (240/363) - Mini-batch Training loss: 0.6659 - Training Acc 1: 0.53
Epoch 23 - Batch (250/363) - Mini-batch Training loss: 0.6785 - Training Acc 1: 0.55
Epoch 23 - Batch (260/363) - Mini-batch Training loss: 0.6752 - Training Acc 1: 0.58
Epoch 23 - Batch (270/363) - Mini-batch Training loss: 0.6820 - Training Acc 1: 0.60
Epoch 23 - Batch (280/363) - Mini-batch Training loss: 0.6753 - Training Acc 1: 0.62
Epoch 23 - Batch (290/363) - Mini-batch Training loss: 0.6827 - Training Acc 1: 0.64
Epoch 23 - Batch (300/363) - Mini-batch Training loss: 0.6896 - Training Acc 1: 0.66
Epoch 23 - Batch (310/363) - Mini-batch Training loss: 0.6878 - Training Acc 1: 0.68
Epoch 23 - Batch (320/363) - Mini-batch Training loss: 0.6818 - Training Acc 1: 0.70
Epoch 23 - Batch (330/363) - Mini-batch Training loss: 0.6787 - Training Acc 1: 0.73
Epoch 23 - Batch (340/363) - Mini-batch Training loss: 0.6832 - Training Acc 1: 0.75
Epoch 23 - Batch (350/363) - Mini-batch Training loss: 0.6752 - Training Acc 1: 0.77
Epoch 23 - Batch (360/363) - Mini-batch Training loss: 0.6885 - Training Acc 1: 0.79
Epoch 23 - Full-batch Training loss: 0.6881 - Training Acc 1: 0.79
Validation set: Average loss: 0.7812, Accuracy: 283.0/363 (78%)

0.7796143250688705
Epoch 24 - Batch (0/363) - Mini-batch Training loss: 0.0447 - Training Acc 1: 0.00
Epoch 24 - Batch (10/363) - Mini-batch Training loss: 0.7250 - Training Acc 1: 0.03
Epoch 24 - Batch (20/363) - Mini-batch Training loss: 0.7966 - Training Acc 1: 0.05
Epoch 24 - Batch (30/363) - Mini-batch Training loss: 0.7968 - Training Acc 1: 0.07
Epoch 24 - Batch (40/363) - Mini-batch Training loss: 0.7306 - Training Acc 1: 0.09
Epoch 24 - Batch (50/363) - Mini-batch Training loss: 0.7548 - Training Acc 1: 0.11
Epoch 24 - Batch (60/363) - Mini-batch Training loss: 0.7215 - Training Acc 1: 0.13
Epoch 24 - Batch (70/363) - Mini-batch Training loss: 0.7376 - Training Acc 1: 0.15
Epoch 24 - Batch (80/363) - Mini-batch Training loss: 0.7181 - Training Acc 1: 0.18
Epoch 24 - Batch (90/363) - Mini-batch Training loss: 0.6995 - Training Acc 1: 0.20
Epoch 24 - Batch (100/363) - Mini-batch Training loss: 0.7029 - Training Acc 1: 0.22
Epoch 24 - Batch (110/363) - Mini-batch Training loss: 0.7129 - Training Acc 1: 0.24
Epoch 24 - Batch (120/363) - Mini-batch Training loss: 0.7069 - Training Acc 1: 0.26
Epoch 24 - Batch (130/363) - Mini-batch Training loss: 0.7166 - Training Acc 1: 0.28
Epoch 24 - Batch (140/363) - Mini-batch Training loss: 0.7072 - Training Acc 1: 0.30
Epoch 24 - Batch (150/363) - Mini-batch Training loss: 0.6913 - Training Acc 1: 0.33
Epoch 24 - Batch (160/363) - Mini-batch Training loss: 0.6725 - Training Acc 1: 0.35
Epoch 24 - Batch (170/363) - Mini-batch Training loss: 0.6666 - Training Acc 1: 0.38
Epoch 24 - Batch (180/363) - Mini-batch Training loss: 0.6577 - Training Acc 1: 0.40
Epoch 24 - Batch (190/363) - Mini-batch Training loss: 0.6494 - Training Acc 1: 0.42
Epoch 24 - Batch (200/363) - Mini-batch Training loss: 0.6323 - Training Acc 1: 0.45
Epoch 24 - Batch (210/363) - Mini-batch Training loss: 0.6252 - Training Acc 1: 0.47
Epoch 24 - Batch (220/363) - Mini-batch Training loss: 0.6331 - Training Acc 1: 0.49
Epoch 24 - Batch (230/363) - Mini-batch Training loss: 0.6374 - Training Acc 1: 0.52
Epoch 24 - Batch (240/363) - Mini-batch Training loss: 0.6517 - Training Acc 1: 0.53
Epoch 24 - Batch (250/363) - Mini-batch Training loss: 0.6487 - Training Acc 1: 0.56
Epoch 24 - Batch (260/363) - Mini-batch Training loss: 0.6386 - Training Acc 1: 0.58
Epoch 24 - Batch (270/363) - Mini-batch Training loss: 0.6373 - Training Acc 1: 0.60
Epoch 24 - Batch (280/363) - Mini-batch Training loss: 0.6446 - Training Acc 1: 0.63
Epoch 24 - Batch (290/363) - Mini-batch Training loss: 0.6426 - Training Acc 1: 0.65
Epoch 24 - Batch (300/363) - Mini-batch Training loss: 0.6502 - Training Acc 1: 0.66
Epoch 24 - Batch (310/363) - Mini-batch Training loss: 0.6542 - Training Acc 1: 0.68
Epoch 24 - Batch (320/363) - Mini-batch Training loss: 0.6580 - Training Acc 1: 0.71
Epoch 24 - Batch (330/363) - Mini-batch Training loss: 0.6627 - Training Acc 1: 0.73
Epoch 24 - Batch (340/363) - Mini-batch Training loss: 0.6734 - Training Acc 1: 0.74
Epoch 24 - Batch (350/363) - Mini-batch Training loss: 0.6762 - Training Acc 1: 0.76
Epoch 24 - Batch (360/363) - Mini-batch Training loss: 0.6763 - Training Acc 1: 0.78
Epoch 24 - Full-batch Training loss: 0.6853 - Training Acc 1: 0.79
Validation set: Average loss: 0.7755, Accuracy: 278.0/363 (77%)

Epoch 25 - Batch (0/363) - Mini-batch Training loss: 0.4665 - Training Acc 1: 0.00
Epoch 25 - Batch (10/363) - Mini-batch Training loss: 0.7948 - Training Acc 1: 0.02
Epoch 25 - Batch (20/363) - Mini-batch Training loss: 0.7623 - Training Acc 1: 0.04
Epoch 25 - Batch (30/363) - Mini-batch Training loss: 0.7154 - Training Acc 1: 0.07
Epoch 25 - Batch (40/363) - Mini-batch Training loss: 0.6546 - Training Acc 1: 0.09
Epoch 25 - Batch (50/363) - Mini-batch Training loss: 0.6308 - Training Acc 1: 0.11
Epoch 25 - Batch (60/363) - Mini-batch Training loss: 0.5969 - Training Acc 1: 0.14
Epoch 25 - Batch (70/363) - Mini-batch Training loss: 0.6155 - Training Acc 1: 0.16
Epoch 25 - Batch (80/363) - Mini-batch Training loss: 0.6123 - Training Acc 1: 0.18
Epoch 25 - Batch (90/363) - Mini-batch Training loss: 0.6096 - Training Acc 1: 0.20
Epoch 25 - Batch (100/363) - Mini-batch Training loss: 0.6263 - Training Acc 1: 0.22
Epoch 25 - Batch (110/363) - Mini-batch Training loss: 0.6054 - Training Acc 1: 0.25
Epoch 25 - Batch (120/363) - Mini-batch Training loss: 0.6060 - Training Acc 1: 0.27
Epoch 25 - Batch (130/363) - Mini-batch Training loss: 0.6260 - Training Acc 1: 0.29
Epoch 25 - Batch (140/363) - Mini-batch Training loss: 0.6321 - Training Acc 1: 0.31
Epoch 25 - Batch (150/363) - Mini-batch Training loss: 0.6292 - Training Acc 1: 0.33
Epoch 25 - Batch (160/363) - Mini-batch Training loss: 0.6222 - Training Acc 1: 0.36
Epoch 25 - Batch (170/363) - Mini-batch Training loss: 0.6184 - Training Acc 1: 0.38
Epoch 25 - Batch (180/363) - Mini-batch Training loss: 0.6123 - Training Acc 1: 0.40
Epoch 25 - Batch (190/363) - Mini-batch Training loss: 0.6100 - Training Acc 1: 0.43
Epoch 25 - Batch (200/363) - Mini-batch Training loss: 0.6204 - Training Acc 1: 0.45
Epoch 25 - Batch (210/363) - Mini-batch Training loss: 0.6299 - Training Acc 1: 0.47
Epoch 25 - Batch (220/363) - Mini-batch Training loss: 0.6434 - Training Acc 1: 0.49
Epoch 25 - Batch (230/363) - Mini-batch Training loss: 0.6516 - Training Acc 1: 0.51
Epoch 25 - Batch (240/363) - Mini-batch Training loss: 0.6445 - Training Acc 1: 0.53
Epoch 25 - Batch (250/363) - Mini-batch Training loss: 0.6426 - Training Acc 1: 0.56
Epoch 25 - Batch (260/363) - Mini-batch Training loss: 0.6420 - Training Acc 1: 0.58
Epoch 25 - Batch (270/363) - Mini-batch Training loss: 0.6439 - Training Acc 1: 0.60
Epoch 25 - Batch (280/363) - Mini-batch Training loss: 0.6454 - Training Acc 1: 0.62
Epoch 25 - Batch (290/363) - Mini-batch Training loss: 0.6495 - Training Acc 1: 0.64
Epoch 25 - Batch (300/363) - Mini-batch Training loss: 0.6498 - Training Acc 1: 0.66
Epoch 25 - Batch (310/363) - Mini-batch Training loss: 0.6596 - Training Acc 1: 0.68
Epoch 25 - Batch (320/363) - Mini-batch Training loss: 0.6638 - Training Acc 1: 0.70
Epoch 25 - Batch (330/363) - Mini-batch Training loss: 0.6640 - Training Acc 1: 0.72
Epoch 25 - Batch (340/363) - Mini-batch Training loss: 0.6692 - Training Acc 1: 0.74
Epoch 25 - Batch (350/363) - Mini-batch Training loss: 0.6628 - Training Acc 1: 0.76
Epoch 25 - Batch (360/363) - Mini-batch Training loss: 0.6570 - Training Acc 1: 0.79
Epoch 25 - Full-batch Training loss: 0.6545 - Training Acc 1: 0.79
Validation set: Average loss: 0.7506, Accuracy: 276.0/363 (76%)

Epoch 26 - Batch (0/363) - Mini-batch Training loss: 0.2939 - Training Acc 1: 0.00
Epoch 26 - Batch (10/363) - Mini-batch Training loss: 0.5436 - Training Acc 1: 0.02
Epoch 26 - Batch (20/363) - Mini-batch Training loss: 0.7124 - Training Acc 1: 0.04
Epoch 26 - Batch (30/363) - Mini-batch Training loss: 0.6704 - Training Acc 1: 0.07
Epoch 26 - Batch (40/363) - Mini-batch Training loss: 0.7052 - Training Acc 1: 0.09
Epoch 26 - Batch (50/363) - Mini-batch Training loss: 0.7200 - Training Acc 1: 0.11
Epoch 26 - Batch (60/363) - Mini-batch Training loss: 0.7511 - Training Acc 1: 0.12
Epoch 26 - Batch (70/363) - Mini-batch Training loss: 0.7764 - Training Acc 1: 0.14
Epoch 26 - Batch (80/363) - Mini-batch Training loss: 0.8027 - Training Acc 1: 0.16
Epoch 26 - Batch (90/363) - Mini-batch Training loss: 0.7705 - Training Acc 1: 0.19
Epoch 26 - Batch (100/363) - Mini-batch Training loss: 0.7785 - Training Acc 1: 0.21
Epoch 26 - Batch (110/363) - Mini-batch Training loss: 0.7714 - Training Acc 1: 0.23
Epoch 26 - Batch (120/363) - Mini-batch Training loss: 0.7595 - Training Acc 1: 0.25
Epoch 26 - Batch (130/363) - Mini-batch Training loss: 0.7636 - Training Acc 1: 0.27
Epoch 26 - Batch (140/363) - Mini-batch Training loss: 0.7573 - Training Acc 1: 0.29
Epoch 26 - Batch (150/363) - Mini-batch Training loss: 0.7404 - Training Acc 1: 0.32
Epoch 26 - Batch (160/363) - Mini-batch Training loss: 0.7279 - Training Acc 1: 0.34
Epoch 26 - Batch (170/363) - Mini-batch Training loss: 0.7189 - Training Acc 1: 0.36
Epoch 26 - Batch (180/363) - Mini-batch Training loss: 0.7019 - Training Acc 1: 0.39
Epoch 26 - Batch (190/363) - Mini-batch Training loss: 0.6973 - Training Acc 1: 0.41
Epoch 26 - Batch (200/363) - Mini-batch Training loss: 0.6904 - Training Acc 1: 0.43
Epoch 26 - Batch (210/363) - Mini-batch Training loss: 0.6853 - Training Acc 1: 0.46
Epoch 26 - Batch (220/363) - Mini-batch Training loss: 0.6797 - Training Acc 1: 0.48
Epoch 26 - Batch (230/363) - Mini-batch Training loss: 0.6744 - Training Acc 1: 0.50
Epoch 26 - Batch (240/363) - Mini-batch Training loss: 0.6807 - Training Acc 1: 0.52
Epoch 26 - Batch (250/363) - Mini-batch Training loss: 0.6664 - Training Acc 1: 0.55
Epoch 26 - Batch (260/363) - Mini-batch Training loss: 0.6632 - Training Acc 1: 0.57
Epoch 26 - Batch (270/363) - Mini-batch Training loss: 0.6627 - Training Acc 1: 0.59
Epoch 26 - Batch (280/363) - Mini-batch Training loss: 0.6537 - Training Acc 1: 0.62
Epoch 26 - Batch (290/363) - Mini-batch Training loss: 0.6481 - Training Acc 1: 0.64
Epoch 26 - Batch (300/363) - Mini-batch Training loss: 0.6472 - Training Acc 1: 0.66
Epoch 26 - Batch (310/363) - Mini-batch Training loss: 0.6490 - Training Acc 1: 0.68
Epoch 26 - Batch (320/363) - Mini-batch Training loss: 0.6565 - Training Acc 1: 0.70
Epoch 26 - Batch (330/363) - Mini-batch Training loss: 0.6504 - Training Acc 1: 0.73
Epoch 26 - Batch (340/363) - Mini-batch Training loss: 0.6520 - Training Acc 1: 0.75
Epoch 26 - Batch (350/363) - Mini-batch Training loss: 0.6464 - Training Acc 1: 0.77
Epoch 26 - Batch (360/363) - Mini-batch Training loss: 0.6419 - Training Acc 1: 0.79
Epoch 26 - Full-batch Training loss: 0.6465 - Training Acc 1: 0.79
Validation set: Average loss: 0.7986, Accuracy: 279.0/363 (77%)

Epoch 27 - Batch (0/363) - Mini-batch Training loss: 1.1570 - Training Acc 1: 0.00
Epoch 27 - Batch (10/363) - Mini-batch Training loss: 0.6348 - Training Acc 1: 0.03
Epoch 27 - Batch (20/363) - Mini-batch Training loss: 0.5812 - Training Acc 1: 0.05
Epoch 27 - Batch (30/363) - Mini-batch Training loss: 0.6018 - Training Acc 1: 0.07
Epoch 27 - Batch (40/363) - Mini-batch Training loss: 0.5928 - Training Acc 1: 0.09
Epoch 27 - Batch (50/363) - Mini-batch Training loss: 0.5405 - Training Acc 1: 0.12
Epoch 27 - Batch (60/363) - Mini-batch Training loss: 0.5640 - Training Acc 1: 0.13
Epoch 27 - Batch (70/363) - Mini-batch Training loss: 0.6007 - Training Acc 1: 0.16
Epoch 27 - Batch (80/363) - Mini-batch Training loss: 0.5873 - Training Acc 1: 0.18
Epoch 27 - Batch (90/363) - Mini-batch Training loss: 0.6070 - Training Acc 1: 0.20
Epoch 27 - Batch (100/363) - Mini-batch Training loss: 0.6198 - Training Acc 1: 0.22
Epoch 27 - Batch (110/363) - Mini-batch Training loss: 0.6113 - Training Acc 1: 0.24
Epoch 27 - Batch (120/363) - Mini-batch Training loss: 0.6351 - Training Acc 1: 0.26
Epoch 27 - Batch (130/363) - Mini-batch Training loss: 0.6434 - Training Acc 1: 0.28
Epoch 27 - Batch (140/363) - Mini-batch Training loss: 0.6218 - Training Acc 1: 0.31
Epoch 27 - Batch (150/363) - Mini-batch Training loss: 0.6243 - Training Acc 1: 0.33
Epoch 27 - Batch (160/363) - Mini-batch Training loss: 0.6303 - Training Acc 1: 0.35
Epoch 27 - Batch (170/363) - Mini-batch Training loss: 0.6340 - Training Acc 1: 0.37
Epoch 27 - Batch (180/363) - Mini-batch Training loss: 0.6389 - Training Acc 1: 0.40
Epoch 27 - Batch (190/363) - Mini-batch Training loss: 0.6412 - Training Acc 1: 0.42
Epoch 27 - Batch (200/363) - Mini-batch Training loss: 0.6496 - Training Acc 1: 0.44
Epoch 27 - Batch (210/363) - Mini-batch Training loss: 0.6634 - Training Acc 1: 0.45
Epoch 27 - Batch (220/363) - Mini-batch Training loss: 0.6607 - Training Acc 1: 0.48
Epoch 27 - Batch (230/363) - Mini-batch Training loss: 0.6748 - Training Acc 1: 0.50
Epoch 27 - Batch (240/363) - Mini-batch Training loss: 0.6761 - Training Acc 1: 0.52
Epoch 27 - Batch (250/363) - Mini-batch Training loss: 0.6720 - Training Acc 1: 0.54
Epoch 27 - Batch (260/363) - Mini-batch Training loss: 0.6707 - Training Acc 1: 0.56
Epoch 27 - Batch (270/363) - Mini-batch Training loss: 0.6737 - Training Acc 1: 0.58
Epoch 27 - Batch (280/363) - Mini-batch Training loss: 0.6715 - Training Acc 1: 0.61
Epoch 27 - Batch (290/363) - Mini-batch Training loss: 0.6711 - Training Acc 1: 0.63
Epoch 27 - Batch (300/363) - Mini-batch Training loss: 0.6780 - Training Acc 1: 0.65
Epoch 27 - Batch (310/363) - Mini-batch Training loss: 0.6774 - Training Acc 1: 0.67
Epoch 27 - Batch (320/363) - Mini-batch Training loss: 0.6698 - Training Acc 1: 0.69
Epoch 27 - Batch (330/363) - Mini-batch Training loss: 0.6720 - Training Acc 1: 0.72
Epoch 27 - Batch (340/363) - Mini-batch Training loss: 0.6669 - Training Acc 1: 0.74
Epoch 27 - Batch (350/363) - Mini-batch Training loss: 0.6640 - Training Acc 1: 0.76
Epoch 27 - Batch (360/363) - Mini-batch Training loss: 0.6643 - Training Acc 1: 0.78
Epoch 27 - Full-batch Training loss: 0.6626 - Training Acc 1: 0.78
Validation set: Average loss: 0.8433, Accuracy: 266.0/363 (73%)

Epoch 28 - Batch (0/363) - Mini-batch Training loss: 0.6590 - Training Acc 1: 0.00
Epoch 28 - Batch (10/363) - Mini-batch Training loss: 0.7510 - Training Acc 1: 0.02
Epoch 28 - Batch (20/363) - Mini-batch Training loss: 0.6217 - Training Acc 1: 0.04
Epoch 28 - Batch (30/363) - Mini-batch Training loss: 0.6723 - Training Acc 1: 0.07
Epoch 28 - Batch (40/363) - Mini-batch Training loss: 0.6875 - Training Acc 1: 0.09
Epoch 28 - Batch (50/363) - Mini-batch Training loss: 0.6795 - Training Acc 1: 0.11
Epoch 28 - Batch (60/363) - Mini-batch Training loss: 0.6730 - Training Acc 1: 0.13
Epoch 28 - Batch (70/363) - Mini-batch Training loss: 0.6519 - Training Acc 1: 0.15
Epoch 28 - Batch (80/363) - Mini-batch Training loss: 0.6441 - Training Acc 1: 0.18
Epoch 28 - Batch (90/363) - Mini-batch Training loss: 0.6266 - Training Acc 1: 0.20
Epoch 28 - Batch (100/363) - Mini-batch Training loss: 0.6157 - Training Acc 1: 0.22
Epoch 28 - Batch (110/363) - Mini-batch Training loss: 0.6037 - Training Acc 1: 0.25
Epoch 28 - Batch (120/363) - Mini-batch Training loss: 0.6090 - Training Acc 1: 0.27
Epoch 28 - Batch (130/363) - Mini-batch Training loss: 0.6055 - Training Acc 1: 0.29
Epoch 28 - Batch (140/363) - Mini-batch Training loss: 0.6020 - Training Acc 1: 0.31
Epoch 28 - Batch (150/363) - Mini-batch Training loss: 0.5990 - Training Acc 1: 0.34
Epoch 28 - Batch (160/363) - Mini-batch Training loss: 0.6024 - Training Acc 1: 0.36
Epoch 28 - Batch (170/363) - Mini-batch Training loss: 0.6075 - Training Acc 1: 0.38
Epoch 28 - Batch (180/363) - Mini-batch Training loss: 0.6086 - Training Acc 1: 0.41
Epoch 28 - Batch (190/363) - Mini-batch Training loss: 0.6152 - Training Acc 1: 0.43
Epoch 28 - Batch (200/363) - Mini-batch Training loss: 0.6114 - Training Acc 1: 0.45
Epoch 28 - Batch (210/363) - Mini-batch Training loss: 0.6095 - Training Acc 1: 0.47
Epoch 28 - Batch (220/363) - Mini-batch Training loss: 0.6101 - Training Acc 1: 0.50
Epoch 28 - Batch (230/363) - Mini-batch Training loss: 0.6147 - Training Acc 1: 0.52
Epoch 28 - Batch (240/363) - Mini-batch Training loss: 0.6111 - Training Acc 1: 0.54
Epoch 28 - Batch (250/363) - Mini-batch Training loss: 0.6065 - Training Acc 1: 0.56
Epoch 28 - Batch (260/363) - Mini-batch Training loss: 0.5986 - Training Acc 1: 0.59
Epoch 28 - Batch (270/363) - Mini-batch Training loss: 0.6074 - Training Acc 1: 0.61
Epoch 28 - Batch (280/363) - Mini-batch Training loss: 0.5992 - Training Acc 1: 0.63
Epoch 28 - Batch (290/363) - Mini-batch Training loss: 0.5923 - Training Acc 1: 0.66
Epoch 28 - Batch (300/363) - Mini-batch Training loss: 0.5916 - Training Acc 1: 0.68
Epoch 28 - Batch (310/363) - Mini-batch Training loss: 0.5874 - Training Acc 1: 0.70
Epoch 28 - Batch (320/363) - Mini-batch Training loss: 0.5991 - Training Acc 1: 0.72
Epoch 28 - Batch (330/363) - Mini-batch Training loss: 0.6032 - Training Acc 1: 0.74
Epoch 28 - Batch (340/363) - Mini-batch Training loss: 0.6074 - Training Acc 1: 0.76
Epoch 28 - Batch (350/363) - Mini-batch Training loss: 0.6028 - Training Acc 1: 0.79
Epoch 28 - Batch (360/363) - Mini-batch Training loss: 0.6075 - Training Acc 1: 0.81
Epoch 28 - Full-batch Training loss: 0.6071 - Training Acc 1: 0.81
Validation set: Average loss: 0.7415, Accuracy: 283.0/363 (78%)

Epoch 29 - Batch (0/363) - Mini-batch Training loss: 0.0786 - Training Acc 1: 0.00
Epoch 29 - Batch (10/363) - Mini-batch Training loss: 0.4587 - Training Acc 1: 0.03
Epoch 29 - Batch (20/363) - Mini-batch Training loss: 0.4640 - Training Acc 1: 0.05
Epoch 29 - Batch (30/363) - Mini-batch Training loss: 0.4940 - Training Acc 1: 0.07
Epoch 29 - Batch (40/363) - Mini-batch Training loss: 0.5275 - Training Acc 1: 0.09
Epoch 29 - Batch (50/363) - Mini-batch Training loss: 0.5049 - Training Acc 1: 0.12
Epoch 29 - Batch (60/363) - Mini-batch Training loss: 0.5217 - Training Acc 1: 0.14
Epoch 29 - Batch (70/363) - Mini-batch Training loss: 0.5434 - Training Acc 1: 0.16
Epoch 29 - Batch (80/363) - Mini-batch Training loss: 0.5422 - Training Acc 1: 0.18
Epoch 29 - Batch (90/363) - Mini-batch Training loss: 0.5041 - Training Acc 1: 0.21
Epoch 29 - Batch (100/363) - Mini-batch Training loss: 0.5135 - Training Acc 1: 0.23
Epoch 29 - Batch (110/363) - Mini-batch Training loss: 0.5474 - Training Acc 1: 0.25
Epoch 29 - Batch (120/363) - Mini-batch Training loss: 0.5453 - Training Acc 1: 0.27
Epoch 29 - Batch (130/363) - Mini-batch Training loss: 0.5324 - Training Acc 1: 0.30
Epoch 29 - Batch (140/363) - Mini-batch Training loss: 0.5503 - Training Acc 1: 0.32
Epoch 29 - Batch (150/363) - Mini-batch Training loss: 0.5840 - Training Acc 1: 0.34
Epoch 29 - Batch (160/363) - Mini-batch Training loss: 0.5825 - Training Acc 1: 0.36
Epoch 29 - Batch (170/363) - Mini-batch Training loss: 0.5901 - Training Acc 1: 0.38
Epoch 29 - Batch (180/363) - Mini-batch Training loss: 0.5954 - Training Acc 1: 0.41
Epoch 29 - Batch (190/363) - Mini-batch Training loss: 0.5898 - Training Acc 1: 0.43
Epoch 29 - Batch (200/363) - Mini-batch Training loss: 0.5903 - Training Acc 1: 0.45
Epoch 29 - Batch (210/363) - Mini-batch Training loss: 0.5905 - Training Acc 1: 0.47
Epoch 29 - Batch (220/363) - Mini-batch Training loss: 0.5857 - Training Acc 1: 0.50
Epoch 29 - Batch (230/363) - Mini-batch Training loss: 0.5980 - Training Acc 1: 0.51
Epoch 29 - Batch (240/363) - Mini-batch Training loss: 0.6017 - Training Acc 1: 0.54
Epoch 29 - Batch (250/363) - Mini-batch Training loss: 0.5973 - Training Acc 1: 0.56
Epoch 29 - Batch (260/363) - Mini-batch Training loss: 0.5970 - Training Acc 1: 0.58
Epoch 29 - Batch (270/363) - Mini-batch Training loss: 0.6010 - Training Acc 1: 0.60
Epoch 29 - Batch (280/363) - Mini-batch Training loss: 0.6044 - Training Acc 1: 0.62
Epoch 29 - Batch (290/363) - Mini-batch Training loss: 0.6010 - Training Acc 1: 0.65
Epoch 29 - Batch (300/363) - Mini-batch Training loss: 0.6077 - Training Acc 1: 0.67
Epoch 29 - Batch (310/363) - Mini-batch Training loss: 0.6024 - Training Acc 1: 0.69
Epoch 29 - Batch (320/363) - Mini-batch Training loss: 0.5976 - Training Acc 1: 0.71
Epoch 29 - Batch (330/363) - Mini-batch Training loss: 0.5902 - Training Acc 1: 0.74
Epoch 29 - Batch (340/363) - Mini-batch Training loss: 0.5797 - Training Acc 1: 0.77
Epoch 29 - Batch (350/363) - Mini-batch Training loss: 0.5838 - Training Acc 1: 0.79
Epoch 29 - Batch (360/363) - Mini-batch Training loss: 0.5931 - Training Acc 1: 0.80
Epoch 29 - Full-batch Training loss: 0.5921 - Training Acc 1: 0.81
Validation set: Average loss: 0.7185, Accuracy: 290.0/363 (80%)

0.7988980716253443
Epoch 30 - Batch (0/363) - Mini-batch Training loss: 0.1368 - Training Acc 1: 0.00
Epoch 30 - Batch (10/363) - Mini-batch Training loss: 0.6715 - Training Acc 1: 0.03
Epoch 30 - Batch (20/363) - Mini-batch Training loss: 0.5138 - Training Acc 1: 0.05
Epoch 30 - Batch (30/363) - Mini-batch Training loss: 0.4965 - Training Acc 1: 0.07
Epoch 30 - Batch (40/363) - Mini-batch Training loss: 0.4822 - Training Acc 1: 0.10
Epoch 30 - Batch (50/363) - Mini-batch Training loss: 0.5270 - Training Acc 1: 0.12
Epoch 30 - Batch (60/363) - Mini-batch Training loss: 0.5468 - Training Acc 1: 0.14
Epoch 30 - Batch (70/363) - Mini-batch Training loss: 0.5457 - Training Acc 1: 0.16
Epoch 30 - Batch (80/363) - Mini-batch Training loss: 0.5833 - Training Acc 1: 0.18
Epoch 30 - Batch (90/363) - Mini-batch Training loss: 0.6095 - Training Acc 1: 0.20
Epoch 30 - Batch (100/363) - Mini-batch Training loss: 0.5935 - Training Acc 1: 0.22
Epoch 30 - Batch (110/363) - Mini-batch Training loss: 0.5841 - Training Acc 1: 0.25
Epoch 30 - Batch (120/363) - Mini-batch Training loss: 0.5773 - Training Acc 1: 0.27
Epoch 30 - Batch (130/363) - Mini-batch Training loss: 0.5722 - Training Acc 1: 0.29
Epoch 30 - Batch (140/363) - Mini-batch Training loss: 0.5609 - Training Acc 1: 0.31
Epoch 30 - Batch (150/363) - Mini-batch Training loss: 0.5597 - Training Acc 1: 0.34
Epoch 30 - Batch (160/363) - Mini-batch Training loss: 0.5520 - Training Acc 1: 0.36
Epoch 30 - Batch (170/363) - Mini-batch Training loss: 0.5666 - Training Acc 1: 0.38
Epoch 30 - Batch (180/363) - Mini-batch Training loss: 0.5595 - Training Acc 1: 0.41
Epoch 30 - Batch (190/363) - Mini-batch Training loss: 0.5619 - Training Acc 1: 0.43
Epoch 30 - Batch (200/363) - Mini-batch Training loss: 0.5617 - Training Acc 1: 0.45
Epoch 30 - Batch (210/363) - Mini-batch Training loss: 0.5641 - Training Acc 1: 0.47
Epoch 30 - Batch (220/363) - Mini-batch Training loss: 0.5586 - Training Acc 1: 0.50
Epoch 30 - Batch (230/363) - Mini-batch Training loss: 0.5691 - Training Acc 1: 0.52
Epoch 30 - Batch (240/363) - Mini-batch Training loss: 0.5794 - Training Acc 1: 0.54
Epoch 30 - Batch (250/363) - Mini-batch Training loss: 0.5814 - Training Acc 1: 0.56
Epoch 30 - Batch (260/363) - Mini-batch Training loss: 0.5797 - Training Acc 1: 0.59
Epoch 30 - Batch (270/363) - Mini-batch Training loss: 0.5892 - Training Acc 1: 0.61
Epoch 30 - Batch (280/363) - Mini-batch Training loss: 0.5948 - Training Acc 1: 0.63
Epoch 30 - Batch (290/363) - Mini-batch Training loss: 0.5928 - Training Acc 1: 0.65
Epoch 30 - Batch (300/363) - Mini-batch Training loss: 0.5871 - Training Acc 1: 0.67
Epoch 30 - Batch (310/363) - Mini-batch Training loss: 0.5909 - Training Acc 1: 0.70
Epoch 30 - Batch (320/363) - Mini-batch Training loss: 0.5901 - Training Acc 1: 0.72
Epoch 30 - Batch (330/363) - Mini-batch Training loss: 0.5883 - Training Acc 1: 0.74
Epoch 30 - Batch (340/363) - Mini-batch Training loss: 0.5900 - Training Acc 1: 0.76
Epoch 30 - Batch (350/363) - Mini-batch Training loss: 0.5836 - Training Acc 1: 0.78
Epoch 30 - Batch (360/363) - Mini-batch Training loss: 0.5804 - Training Acc 1: 0.81
Epoch 30 - Full-batch Training loss: 0.5777 - Training Acc 1: 0.81
Validation set: Average loss: 0.8910, Accuracy: 270.0/363 (74%)

Epoch 31 - Batch (0/363) - Mini-batch Training loss: 0.2560 - Training Acc 1: 0.00
Epoch 31 - Batch (10/363) - Mini-batch Training loss: 0.7005 - Training Acc 1: 0.03
Epoch 31 - Batch (20/363) - Mini-batch Training loss: 0.7884 - Training Acc 1: 0.05
Epoch 31 - Batch (30/363) - Mini-batch Training loss: 0.7127 - Training Acc 1: 0.07
Epoch 31 - Batch (40/363) - Mini-batch Training loss: 0.6742 - Training Acc 1: 0.09
Epoch 31 - Batch (50/363) - Mini-batch Training loss: 0.6405 - Training Acc 1: 0.11
Epoch 31 - Batch (60/363) - Mini-batch Training loss: 0.6197 - Training Acc 1: 0.14
Epoch 31 - Batch (70/363) - Mini-batch Training loss: 0.6061 - Training Acc 1: 0.16
Epoch 31 - Batch (80/363) - Mini-batch Training loss: 0.6168 - Training Acc 1: 0.18
Epoch 31 - Batch (90/363) - Mini-batch Training loss: 0.5933 - Training Acc 1: 0.20
Epoch 31 - Batch (100/363) - Mini-batch Training loss: 0.5813 - Training Acc 1: 0.23
Epoch 31 - Batch (110/363) - Mini-batch Training loss: 0.5767 - Training Acc 1: 0.25
Epoch 31 - Batch (120/363) - Mini-batch Training loss: 0.5908 - Training Acc 1: 0.27
Epoch 31 - Batch (130/363) - Mini-batch Training loss: 0.5818 - Training Acc 1: 0.29
Epoch 31 - Batch (140/363) - Mini-batch Training loss: 0.5861 - Training Acc 1: 0.31
Epoch 31 - Batch (150/363) - Mini-batch Training loss: 0.5796 - Training Acc 1: 0.34
Epoch 31 - Batch (160/363) - Mini-batch Training loss: 0.5782 - Training Acc 1: 0.36
Epoch 31 - Batch (170/363) - Mini-batch Training loss: 0.5856 - Training Acc 1: 0.38
Epoch 31 - Batch (180/363) - Mini-batch Training loss: 0.5937 - Training Acc 1: 0.40
Epoch 31 - Batch (190/363) - Mini-batch Training loss: 0.5825 - Training Acc 1: 0.42
Epoch 31 - Batch (200/363) - Mini-batch Training loss: 0.5728 - Training Acc 1: 0.45
Epoch 31 - Batch (210/363) - Mini-batch Training loss: 0.5689 - Training Acc 1: 0.47
Epoch 31 - Batch (220/363) - Mini-batch Training loss: 0.5631 - Training Acc 1: 0.49
Epoch 31 - Batch (230/363) - Mini-batch Training loss: 0.5594 - Training Acc 1: 0.52
Epoch 31 - Batch (240/363) - Mini-batch Training loss: 0.5609 - Training Acc 1: 0.54
Epoch 31 - Batch (250/363) - Mini-batch Training loss: 0.5738 - Training Acc 1: 0.56
Epoch 31 - Batch (260/363) - Mini-batch Training loss: 0.5729 - Training Acc 1: 0.58
Epoch 31 - Batch (270/363) - Mini-batch Training loss: 0.5670 - Training Acc 1: 0.60
Epoch 31 - Batch (280/363) - Mini-batch Training loss: 0.5677 - Training Acc 1: 0.62
Epoch 31 - Batch (290/363) - Mini-batch Training loss: 0.5733 - Training Acc 1: 0.64
Epoch 31 - Batch (300/363) - Mini-batch Training loss: 0.5754 - Training Acc 1: 0.67
Epoch 31 - Batch (310/363) - Mini-batch Training loss: 0.5744 - Training Acc 1: 0.69
Epoch 31 - Batch (320/363) - Mini-batch Training loss: 0.5741 - Training Acc 1: 0.71
Epoch 31 - Batch (330/363) - Mini-batch Training loss: 0.5727 - Training Acc 1: 0.74
Epoch 31 - Batch (340/363) - Mini-batch Training loss: 0.5774 - Training Acc 1: 0.76
Epoch 31 - Batch (350/363) - Mini-batch Training loss: 0.5748 - Training Acc 1: 0.78
Epoch 31 - Batch (360/363) - Mini-batch Training loss: 0.5795 - Training Acc 1: 0.80
Epoch 31 - Full-batch Training loss: 0.5777 - Training Acc 1: 0.81
Validation set: Average loss: 0.7859, Accuracy: 283.0/363 (78%)

Epoch 32 - Batch (0/363) - Mini-batch Training loss: 0.1770 - Training Acc 1: 0.00
Epoch 32 - Batch (10/363) - Mini-batch Training loss: 0.4427 - Training Acc 1: 0.02
Epoch 32 - Batch (20/363) - Mini-batch Training loss: 0.5598 - Training Acc 1: 0.05
Epoch 32 - Batch (30/363) - Mini-batch Training loss: 0.4925 - Training Acc 1: 0.07
Epoch 32 - Batch (40/363) - Mini-batch Training loss: 0.5055 - Training Acc 1: 0.09
Epoch 32 - Batch (50/363) - Mini-batch Training loss: 0.5434 - Training Acc 1: 0.11
Epoch 32 - Batch (60/363) - Mini-batch Training loss: 0.5316 - Training Acc 1: 0.14
Epoch 32 - Batch (70/363) - Mini-batch Training loss: 0.5118 - Training Acc 1: 0.16
Epoch 32 - Batch (80/363) - Mini-batch Training loss: 0.5178 - Training Acc 1: 0.18
Epoch 32 - Batch (90/363) - Mini-batch Training loss: 0.5323 - Training Acc 1: 0.21
Epoch 32 - Batch (100/363) - Mini-batch Training loss: 0.5411 - Training Acc 1: 0.23
Epoch 32 - Batch (110/363) - Mini-batch Training loss: 0.5506 - Training Acc 1: 0.25
Epoch 32 - Batch (120/363) - Mini-batch Training loss: 0.5630 - Training Acc 1: 0.27
Epoch 32 - Batch (130/363) - Mini-batch Training loss: 0.5662 - Training Acc 1: 0.29
Epoch 32 - Batch (140/363) - Mini-batch Training loss: 0.5647 - Training Acc 1: 0.32
Epoch 32 - Batch (150/363) - Mini-batch Training loss: 0.5477 - Training Acc 1: 0.34
Epoch 32 - Batch (160/363) - Mini-batch Training loss: 0.5383 - Training Acc 1: 0.37
Epoch 32 - Batch (170/363) - Mini-batch Training loss: 0.5417 - Training Acc 1: 0.39
Epoch 32 - Batch (180/363) - Mini-batch Training loss: 0.5514 - Training Acc 1: 0.41
Epoch 32 - Batch (190/363) - Mini-batch Training loss: 0.5711 - Training Acc 1: 0.43
Epoch 32 - Batch (200/363) - Mini-batch Training loss: 0.5545 - Training Acc 1: 0.46
Epoch 32 - Batch (210/363) - Mini-batch Training loss: 0.5502 - Training Acc 1: 0.48
Epoch 32 - Batch (220/363) - Mini-batch Training loss: 0.5550 - Training Acc 1: 0.50
Epoch 32 - Batch (230/363) - Mini-batch Training loss: 0.5470 - Training Acc 1: 0.53
Epoch 32 - Batch (240/363) - Mini-batch Training loss: 0.5499 - Training Acc 1: 0.55
Epoch 32 - Batch (250/363) - Mini-batch Training loss: 0.5454 - Training Acc 1: 0.57
Epoch 32 - Batch (260/363) - Mini-batch Training loss: 0.5534 - Training Acc 1: 0.60
Epoch 32 - Batch (270/363) - Mini-batch Training loss: 0.5492 - Training Acc 1: 0.62
Epoch 32 - Batch (280/363) - Mini-batch Training loss: 0.5445 - Training Acc 1: 0.64
Epoch 32 - Batch (290/363) - Mini-batch Training loss: 0.5478 - Training Acc 1: 0.66
Epoch 32 - Batch (300/363) - Mini-batch Training loss: 0.5557 - Training Acc 1: 0.69
Epoch 32 - Batch (310/363) - Mini-batch Training loss: 0.5622 - Training Acc 1: 0.71
Epoch 32 - Batch (320/363) - Mini-batch Training loss: 0.5550 - Training Acc 1: 0.73
Epoch 32 - Batch (330/363) - Mini-batch Training loss: 0.5543 - Training Acc 1: 0.75
Epoch 32 - Batch (340/363) - Mini-batch Training loss: 0.5550 - Training Acc 1: 0.78
Epoch 32 - Batch (350/363) - Mini-batch Training loss: 0.5573 - Training Acc 1: 0.80
Epoch 32 - Batch (360/363) - Mini-batch Training loss: 0.5608 - Training Acc 1: 0.82
Epoch 32 - Full-batch Training loss: 0.5580 - Training Acc 1: 0.82
Validation set: Average loss: 0.8064, Accuracy: 282.0/363 (78%)

Epoch 33 - Batch (0/363) - Mini-batch Training loss: 1.0707 - Training Acc 1: 0.00
Epoch 33 - Batch (10/363) - Mini-batch Training loss: 0.4207 - Training Acc 1: 0.03
Epoch 33 - Batch (20/363) - Mini-batch Training loss: 0.5058 - Training Acc 1: 0.05
Epoch 33 - Batch (30/363) - Mini-batch Training loss: 0.5262 - Training Acc 1: 0.07
Epoch 33 - Batch (40/363) - Mini-batch Training loss: 0.5827 - Training Acc 1: 0.09
Epoch 33 - Batch (50/363) - Mini-batch Training loss: 0.5697 - Training Acc 1: 0.12
Epoch 33 - Batch (60/363) - Mini-batch Training loss: 0.5913 - Training Acc 1: 0.14
Epoch 33 - Batch (70/363) - Mini-batch Training loss: 0.5625 - Training Acc 1: 0.16
Epoch 33 - Batch (80/363) - Mini-batch Training loss: 0.5285 - Training Acc 1: 0.19
Epoch 33 - Batch (90/363) - Mini-batch Training loss: 0.5285 - Training Acc 1: 0.21
Epoch 33 - Batch (100/363) - Mini-batch Training loss: 0.5238 - Training Acc 1: 0.23
Epoch 33 - Batch (110/363) - Mini-batch Training loss: 0.5235 - Training Acc 1: 0.25
Epoch 33 - Batch (120/363) - Mini-batch Training loss: 0.5274 - Training Acc 1: 0.28
Epoch 33 - Batch (130/363) - Mini-batch Training loss: 0.5112 - Training Acc 1: 0.30
Epoch 33 - Batch (140/363) - Mini-batch Training loss: 0.5091 - Training Acc 1: 0.32
Epoch 33 - Batch (150/363) - Mini-batch Training loss: 0.5031 - Training Acc 1: 0.35
Epoch 33 - Batch (160/363) - Mini-batch Training loss: 0.5076 - Training Acc 1: 0.37
Epoch 33 - Batch (170/363) - Mini-batch Training loss: 0.5097 - Training Acc 1: 0.39
Epoch 33 - Batch (180/363) - Mini-batch Training loss: 0.5201 - Training Acc 1: 0.41
Epoch 33 - Batch (190/363) - Mini-batch Training loss: 0.5201 - Training Acc 1: 0.44
Epoch 33 - Batch (200/363) - Mini-batch Training loss: 0.5148 - Training Acc 1: 0.46
Epoch 33 - Batch (210/363) - Mini-batch Training loss: 0.5142 - Training Acc 1: 0.48
Epoch 33 - Batch (220/363) - Mini-batch Training loss: 0.5250 - Training Acc 1: 0.50
Epoch 33 - Batch (230/363) - Mini-batch Training loss: 0.5322 - Training Acc 1: 0.53
Epoch 33 - Batch (240/363) - Mini-batch Training loss: 0.5250 - Training Acc 1: 0.55
Epoch 33 - Batch (250/363) - Mini-batch Training loss: 0.5250 - Training Acc 1: 0.57
Epoch 33 - Batch (260/363) - Mini-batch Training loss: 0.5207 - Training Acc 1: 0.60
Epoch 33 - Batch (270/363) - Mini-batch Training loss: 0.5189 - Training Acc 1: 0.62
Epoch 33 - Batch (280/363) - Mini-batch Training loss: 0.5148 - Training Acc 1: 0.64
Epoch 33 - Batch (290/363) - Mini-batch Training loss: 0.5140 - Training Acc 1: 0.67
Epoch 33 - Batch (300/363) - Mini-batch Training loss: 0.5200 - Training Acc 1: 0.69
Epoch 33 - Batch (310/363) - Mini-batch Training loss: 0.5310 - Training Acc 1: 0.71
Epoch 33 - Batch (320/363) - Mini-batch Training loss: 0.5325 - Training Acc 1: 0.73
Epoch 33 - Batch (330/363) - Mini-batch Training loss: 0.5278 - Training Acc 1: 0.75
Epoch 33 - Batch (340/363) - Mini-batch Training loss: 0.5328 - Training Acc 1: 0.77
Epoch 33 - Batch (350/363) - Mini-batch Training loss: 0.5366 - Training Acc 1: 0.80
Epoch 33 - Batch (360/363) - Mini-batch Training loss: 0.5417 - Training Acc 1: 0.82
Epoch 33 - Full-batch Training loss: 0.5430 - Training Acc 1: 0.82
Validation set: Average loss: 0.6892, Accuracy: 291.0/363 (80%)

0.8016528925619835
Epoch 34 - Batch (0/363) - Mini-batch Training loss: 0.0236 - Training Acc 1: 0.00
Epoch 34 - Batch (10/363) - Mini-batch Training loss: 0.6031 - Training Acc 1: 0.02
Epoch 34 - Batch (20/363) - Mini-batch Training loss: 0.6362 - Training Acc 1: 0.05
Epoch 34 - Batch (30/363) - Mini-batch Training loss: 0.5647 - Training Acc 1: 0.07
Epoch 34 - Batch (40/363) - Mini-batch Training loss: 0.5714 - Training Acc 1: 0.09
Epoch 34 - Batch (50/363) - Mini-batch Training loss: 0.5905 - Training Acc 1: 0.11
Epoch 34 - Batch (60/363) - Mini-batch Training loss: 0.5517 - Training Acc 1: 0.14
Epoch 34 - Batch (70/363) - Mini-batch Training loss: 0.5413 - Training Acc 1: 0.16
Epoch 34 - Batch (80/363) - Mini-batch Training loss: 0.5617 - Training Acc 1: 0.18
Epoch 34 - Batch (90/363) - Mini-batch Training loss: 0.5385 - Training Acc 1: 0.21
Epoch 34 - Batch (100/363) - Mini-batch Training loss: 0.5298 - Training Acc 1: 0.23
Epoch 34 - Batch (110/363) - Mini-batch Training loss: 0.5240 - Training Acc 1: 0.25
Epoch 34 - Batch (120/363) - Mini-batch Training loss: 0.5191 - Training Acc 1: 0.28
Epoch 34 - Batch (130/363) - Mini-batch Training loss: 0.5186 - Training Acc 1: 0.30
Epoch 34 - Batch (140/363) - Mini-batch Training loss: 0.4998 - Training Acc 1: 0.33
Epoch 34 - Batch (150/363) - Mini-batch Training loss: 0.5035 - Training Acc 1: 0.35
Epoch 34 - Batch (160/363) - Mini-batch Training loss: 0.4983 - Training Acc 1: 0.37
Epoch 34 - Batch (170/363) - Mini-batch Training loss: 0.4978 - Training Acc 1: 0.40
Epoch 34 - Batch (180/363) - Mini-batch Training loss: 0.4966 - Training Acc 1: 0.42
Epoch 34 - Batch (190/363) - Mini-batch Training loss: 0.4982 - Training Acc 1: 0.44
Epoch 34 - Batch (200/363) - Mini-batch Training loss: 0.5051 - Training Acc 1: 0.46
Epoch 34 - Batch (210/363) - Mini-batch Training loss: 0.5000 - Training Acc 1: 0.49
Epoch 34 - Batch (220/363) - Mini-batch Training loss: 0.5028 - Training Acc 1: 0.51
Epoch 34 - Batch (230/363) - Mini-batch Training loss: 0.5058 - Training Acc 1: 0.53
Epoch 34 - Batch (240/363) - Mini-batch Training loss: 0.5097 - Training Acc 1: 0.55
Epoch 34 - Batch (250/363) - Mini-batch Training loss: 0.5161 - Training Acc 1: 0.58
Epoch 34 - Batch (260/363) - Mini-batch Training loss: 0.5117 - Training Acc 1: 0.60
Epoch 34 - Batch (270/363) - Mini-batch Training loss: 0.5071 - Training Acc 1: 0.62
Epoch 34 - Batch (280/363) - Mini-batch Training loss: 0.5132 - Training Acc 1: 0.64
Epoch 34 - Batch (290/363) - Mini-batch Training loss: 0.5149 - Training Acc 1: 0.66
Epoch 34 - Batch (300/363) - Mini-batch Training loss: 0.5153 - Training Acc 1: 0.69
Epoch 34 - Batch (310/363) - Mini-batch Training loss: 0.5137 - Training Acc 1: 0.71
Epoch 34 - Batch (320/363) - Mini-batch Training loss: 0.5143 - Training Acc 1: 0.73
Epoch 34 - Batch (330/363) - Mini-batch Training loss: 0.5144 - Training Acc 1: 0.76
Epoch 34 - Batch (340/363) - Mini-batch Training loss: 0.5115 - Training Acc 1: 0.78
Epoch 34 - Batch (350/363) - Mini-batch Training loss: 0.5061 - Training Acc 1: 0.81
Epoch 34 - Batch (360/363) - Mini-batch Training loss: 0.5091 - Training Acc 1: 0.83
Epoch 34 - Full-batch Training loss: 0.5126 - Training Acc 1: 0.83
Validation set: Average loss: 0.7418, Accuracy: 284.0/363 (78%)

Epoch 35 - Batch (0/363) - Mini-batch Training loss: 1.2539 - Training Acc 1: 0.00
Epoch 35 - Batch (10/363) - Mini-batch Training loss: 0.3891 - Training Acc 1: 0.03
Epoch 35 - Batch (20/363) - Mini-batch Training loss: 0.3883 - Training Acc 1: 0.05
Epoch 35 - Batch (30/363) - Mini-batch Training loss: 0.4211 - Training Acc 1: 0.08
Epoch 35 - Batch (40/363) - Mini-batch Training loss: 0.4538 - Training Acc 1: 0.10
Epoch 35 - Batch (50/363) - Mini-batch Training loss: 0.4750 - Training Acc 1: 0.12
Epoch 35 - Batch (60/363) - Mini-batch Training loss: 0.5125 - Training Acc 1: 0.14
Epoch 35 - Batch (70/363) - Mini-batch Training loss: 0.5257 - Training Acc 1: 0.16
Epoch 35 - Batch (80/363) - Mini-batch Training loss: 0.4974 - Training Acc 1: 0.19
Epoch 35 - Batch (90/363) - Mini-batch Training loss: 0.5012 - Training Acc 1: 0.21
Epoch 35 - Batch (100/363) - Mini-batch Training loss: 0.4914 - Training Acc 1: 0.23
Epoch 35 - Batch (110/363) - Mini-batch Training loss: 0.4835 - Training Acc 1: 0.26
Epoch 35 - Batch (120/363) - Mini-batch Training loss: 0.4791 - Training Acc 1: 0.28
Epoch 35 - Batch (130/363) - Mini-batch Training loss: 0.4840 - Training Acc 1: 0.31
Epoch 35 - Batch (140/363) - Mini-batch Training loss: 0.4753 - Training Acc 1: 0.33
Epoch 35 - Batch (150/363) - Mini-batch Training loss: 0.4957 - Training Acc 1: 0.35
Epoch 35 - Batch (160/363) - Mini-batch Training loss: 0.4904 - Training Acc 1: 0.38
Epoch 35 - Batch (170/363) - Mini-batch Training loss: 0.4836 - Training Acc 1: 0.40
Epoch 35 - Batch (180/363) - Mini-batch Training loss: 0.4775 - Training Acc 1: 0.42
Epoch 35 - Batch (190/363) - Mini-batch Training loss: 0.4762 - Training Acc 1: 0.45
Epoch 35 - Batch (200/363) - Mini-batch Training loss: 0.4824 - Training Acc 1: 0.47
Epoch 35 - Batch (210/363) - Mini-batch Training loss: 0.4859 - Training Acc 1: 0.49
Epoch 35 - Batch (220/363) - Mini-batch Training loss: 0.4943 - Training Acc 1: 0.51
Epoch 35 - Batch (230/363) - Mini-batch Training loss: 0.4976 - Training Acc 1: 0.53
Epoch 35 - Batch (240/363) - Mini-batch Training loss: 0.5144 - Training Acc 1: 0.55
Epoch 35 - Batch (250/363) - Mini-batch Training loss: 0.5139 - Training Acc 1: 0.58
Epoch 35 - Batch (260/363) - Mini-batch Training loss: 0.5155 - Training Acc 1: 0.60
Epoch 35 - Batch (270/363) - Mini-batch Training loss: 0.5101 - Training Acc 1: 0.62
Epoch 35 - Batch (280/363) - Mini-batch Training loss: 0.5137 - Training Acc 1: 0.65
Epoch 35 - Batch (290/363) - Mini-batch Training loss: 0.5090 - Training Acc 1: 0.67
Epoch 35 - Batch (300/363) - Mini-batch Training loss: 0.5063 - Training Acc 1: 0.70
Epoch 35 - Batch (310/363) - Mini-batch Training loss: 0.5095 - Training Acc 1: 0.72
Epoch 35 - Batch (320/363) - Mini-batch Training loss: 0.5138 - Training Acc 1: 0.74
Epoch 35 - Batch (330/363) - Mini-batch Training loss: 0.5087 - Training Acc 1: 0.76
Epoch 35 - Batch (340/363) - Mini-batch Training loss: 0.5110 - Training Acc 1: 0.78
Epoch 35 - Batch (350/363) - Mini-batch Training loss: 0.5106 - Training Acc 1: 0.81
Epoch 35 - Batch (360/363) - Mini-batch Training loss: 0.5103 - Training Acc 1: 0.83
Epoch 35 - Full-batch Training loss: 0.5089 - Training Acc 1: 0.84
Validation set: Average loss: 0.7249, Accuracy: 280.0/363 (77%)

Epoch 36 - Batch (0/363) - Mini-batch Training loss: 0.3880 - Training Acc 1: 0.00
Epoch 36 - Batch (10/363) - Mini-batch Training loss: 0.6478 - Training Acc 1: 0.02
Epoch 36 - Batch (20/363) - Mini-batch Training loss: 0.5387 - Training Acc 1: 0.04
Epoch 36 - Batch (30/363) - Mini-batch Training loss: 0.5279 - Training Acc 1: 0.07
Epoch 36 - Batch (40/363) - Mini-batch Training loss: 0.5030 - Training Acc 1: 0.09
Epoch 36 - Batch (50/363) - Mini-batch Training loss: 0.4823 - Training Acc 1: 0.11
Epoch 36 - Batch (60/363) - Mini-batch Training loss: 0.4528 - Training Acc 1: 0.14
Epoch 36 - Batch (70/363) - Mini-batch Training loss: 0.4860 - Training Acc 1: 0.16
Epoch 36 - Batch (80/363) - Mini-batch Training loss: 0.4796 - Training Acc 1: 0.19
Epoch 36 - Batch (90/363) - Mini-batch Training loss: 0.4685 - Training Acc 1: 0.21
Epoch 36 - Batch (100/363) - Mini-batch Training loss: 0.4939 - Training Acc 1: 0.23
Epoch 36 - Batch (110/363) - Mini-batch Training loss: 0.5176 - Training Acc 1: 0.25
Epoch 36 - Batch (120/363) - Mini-batch Training loss: 0.5141 - Training Acc 1: 0.27
Epoch 36 - Batch (130/363) - Mini-batch Training loss: 0.5268 - Training Acc 1: 0.29
Epoch 36 - Batch (140/363) - Mini-batch Training loss: 0.5267 - Training Acc 1: 0.31
Epoch 36 - Batch (150/363) - Mini-batch Training loss: 0.5257 - Training Acc 1: 0.34
Epoch 36 - Batch (160/363) - Mini-batch Training loss: 0.5263 - Training Acc 1: 0.36
Epoch 36 - Batch (170/363) - Mini-batch Training loss: 0.5136 - Training Acc 1: 0.39
Epoch 36 - Batch (180/363) - Mini-batch Training loss: 0.5456 - Training Acc 1: 0.41
Epoch 36 - Batch (190/363) - Mini-batch Training loss: 0.5436 - Training Acc 1: 0.43
Epoch 36 - Batch (200/363) - Mini-batch Training loss: 0.5425 - Training Acc 1: 0.45
Epoch 36 - Batch (210/363) - Mini-batch Training loss: 0.5389 - Training Acc 1: 0.48
Epoch 36 - Batch (220/363) - Mini-batch Training loss: 0.5325 - Training Acc 1: 0.50
Epoch 36 - Batch (230/363) - Mini-batch Training loss: 0.5371 - Training Acc 1: 0.52
Epoch 36 - Batch (240/363) - Mini-batch Training loss: 0.5329 - Training Acc 1: 0.55
Epoch 36 - Batch (250/363) - Mini-batch Training loss: 0.5295 - Training Acc 1: 0.57
Epoch 36 - Batch (260/363) - Mini-batch Training loss: 0.5211 - Training Acc 1: 0.60
Epoch 36 - Batch (270/363) - Mini-batch Training loss: 0.5216 - Training Acc 1: 0.62
Epoch 36 - Batch (280/363) - Mini-batch Training loss: 0.5158 - Training Acc 1: 0.64
Epoch 36 - Batch (290/363) - Mini-batch Training loss: 0.5116 - Training Acc 1: 0.67
Epoch 36 - Batch (300/363) - Mini-batch Training loss: 0.5069 - Training Acc 1: 0.69
Epoch 36 - Batch (310/363) - Mini-batch Training loss: 0.5077 - Training Acc 1: 0.72
Epoch 36 - Batch (320/363) - Mini-batch Training loss: 0.5045 - Training Acc 1: 0.74
Epoch 36 - Batch (330/363) - Mini-batch Training loss: 0.5097 - Training Acc 1: 0.76
Epoch 36 - Batch (340/363) - Mini-batch Training loss: 0.5107 - Training Acc 1: 0.79
Epoch 36 - Batch (350/363) - Mini-batch Training loss: 0.5186 - Training Acc 1: 0.81
Epoch 36 - Batch (360/363) - Mini-batch Training loss: 0.5188 - Training Acc 1: 0.83
Epoch 36 - Full-batch Training loss: 0.5171 - Training Acc 1: 0.83
Validation set: Average loss: 0.9540, Accuracy: 276.0/363 (76%)

Epoch 37 - Batch (0/363) - Mini-batch Training loss: 0.1830 - Training Acc 1: 0.00
Epoch 37 - Batch (10/363) - Mini-batch Training loss: 0.5775 - Training Acc 1: 0.03
Epoch 37 - Batch (20/363) - Mini-batch Training loss: 0.5260 - Training Acc 1: 0.05
Epoch 37 - Batch (30/363) - Mini-batch Training loss: 0.5413 - Training Acc 1: 0.07
Epoch 37 - Batch (40/363) - Mini-batch Training loss: 0.5136 - Training Acc 1: 0.09
Epoch 37 - Batch (50/363) - Mini-batch Training loss: 0.5077 - Training Acc 1: 0.12
Epoch 37 - Batch (60/363) - Mini-batch Training loss: 0.4923 - Training Acc 1: 0.14
Epoch 37 - Batch (70/363) - Mini-batch Training loss: 0.4681 - Training Acc 1: 0.17
Epoch 37 - Batch (80/363) - Mini-batch Training loss: 0.4812 - Training Acc 1: 0.19
Epoch 37 - Batch (90/363) - Mini-batch Training loss: 0.4858 - Training Acc 1: 0.21
Epoch 37 - Batch (100/363) - Mini-batch Training loss: 0.4893 - Training Acc 1: 0.23
Epoch 37 - Batch (110/363) - Mini-batch Training loss: 0.4825 - Training Acc 1: 0.26
Epoch 37 - Batch (120/363) - Mini-batch Training loss: 0.4954 - Training Acc 1: 0.28
Epoch 37 - Batch (130/363) - Mini-batch Training loss: 0.4986 - Training Acc 1: 0.30
Epoch 37 - Batch (140/363) - Mini-batch Training loss: 0.5144 - Training Acc 1: 0.32
Epoch 37 - Batch (150/363) - Mini-batch Training loss: 0.5183 - Training Acc 1: 0.34
Epoch 37 - Batch (160/363) - Mini-batch Training loss: 0.5337 - Training Acc 1: 0.36
Epoch 37 - Batch (170/363) - Mini-batch Training loss: 0.5408 - Training Acc 1: 0.38
Epoch 37 - Batch (180/363) - Mini-batch Training loss: 0.5332 - Training Acc 1: 0.40
Epoch 37 - Batch (190/363) - Mini-batch Training loss: 0.5498 - Training Acc 1: 0.43
Epoch 37 - Batch (200/363) - Mini-batch Training loss: 0.5621 - Training Acc 1: 0.45
Epoch 37 - Batch (210/363) - Mini-batch Training loss: 0.5607 - Training Acc 1: 0.47
Epoch 37 - Batch (220/363) - Mini-batch Training loss: 0.5566 - Training Acc 1: 0.49
Epoch 37 - Batch (230/363) - Mini-batch Training loss: 0.5498 - Training Acc 1: 0.52
Epoch 37 - Batch (240/363) - Mini-batch Training loss: 0.5430 - Training Acc 1: 0.54
Epoch 37 - Batch (250/363) - Mini-batch Training loss: 0.5349 - Training Acc 1: 0.57
Epoch 37 - Batch (260/363) - Mini-batch Training loss: 0.5326 - Training Acc 1: 0.59
Epoch 37 - Batch (270/363) - Mini-batch Training loss: 0.5317 - Training Acc 1: 0.61
Epoch 37 - Batch (280/363) - Mini-batch Training loss: 0.5323 - Training Acc 1: 0.64
Epoch 37 - Batch (290/363) - Mini-batch Training loss: 0.5295 - Training Acc 1: 0.66
Epoch 37 - Batch (300/363) - Mini-batch Training loss: 0.5306 - Training Acc 1: 0.68
Epoch 37 - Batch (310/363) - Mini-batch Training loss: 0.5372 - Training Acc 1: 0.70
Epoch 37 - Batch (320/363) - Mini-batch Training loss: 0.5311 - Training Acc 1: 0.73
Epoch 37 - Batch (330/363) - Mini-batch Training loss: 0.5245 - Training Acc 1: 0.75
Epoch 37 - Batch (340/363) - Mini-batch Training loss: 0.5211 - Training Acc 1: 0.78
Epoch 37 - Batch (350/363) - Mini-batch Training loss: 0.5176 - Training Acc 1: 0.80
Epoch 37 - Batch (360/363) - Mini-batch Training loss: 0.5288 - Training Acc 1: 0.82
Epoch 37 - Full-batch Training loss: 0.5268 - Training Acc 1: 0.82
Validation set: Average loss: 0.7392, Accuracy: 284.0/363 (78%)

Epoch 38 - Batch (0/363) - Mini-batch Training loss: 0.3028 - Training Acc 1: 0.00
Epoch 38 - Batch (10/363) - Mini-batch Training loss: 0.2901 - Training Acc 1: 0.03
Epoch 38 - Batch (20/363) - Mini-batch Training loss: 0.4922 - Training Acc 1: 0.05
Epoch 38 - Batch (30/363) - Mini-batch Training loss: 0.5086 - Training Acc 1: 0.07
Epoch 38 - Batch (40/363) - Mini-batch Training loss: 0.5856 - Training Acc 1: 0.09
Epoch 38 - Batch (50/363) - Mini-batch Training loss: 0.5429 - Training Acc 1: 0.12
Epoch 38 - Batch (60/363) - Mini-batch Training loss: 0.5679 - Training Acc 1: 0.14
Epoch 38 - Batch (70/363) - Mini-batch Training loss: 0.5370 - Training Acc 1: 0.16
Epoch 38 - Batch (80/363) - Mini-batch Training loss: 0.5299 - Training Acc 1: 0.19
Epoch 38 - Batch (90/363) - Mini-batch Training loss: 0.5045 - Training Acc 1: 0.21
Epoch 38 - Batch (100/363) - Mini-batch Training loss: 0.5224 - Training Acc 1: 0.23
Epoch 38 - Batch (110/363) - Mini-batch Training loss: 0.5164 - Training Acc 1: 0.25
Epoch 38 - Batch (120/363) - Mini-batch Training loss: 0.5171 - Training Acc 1: 0.28
Epoch 38 - Batch (130/363) - Mini-batch Training loss: 0.4882 - Training Acc 1: 0.30
Epoch 38 - Batch (140/363) - Mini-batch Training loss: 0.4765 - Training Acc 1: 0.33
Epoch 38 - Batch (150/363) - Mini-batch Training loss: 0.4666 - Training Acc 1: 0.35
Epoch 38 - Batch (160/363) - Mini-batch Training loss: 0.4837 - Training Acc 1: 0.37
Epoch 38 - Batch (170/363) - Mini-batch Training loss: 0.4825 - Training Acc 1: 0.40
Epoch 38 - Batch (180/363) - Mini-batch Training loss: 0.4822 - Training Acc 1: 0.42
Epoch 38 - Batch (190/363) - Mini-batch Training loss: 0.4813 - Training Acc 1: 0.44
Epoch 38 - Batch (200/363) - Mini-batch Training loss: 0.4798 - Training Acc 1: 0.47
Epoch 38 - Batch (210/363) - Mini-batch Training loss: 0.4741 - Training Acc 1: 0.49
Epoch 38 - Batch (220/363) - Mini-batch Training loss: 0.4705 - Training Acc 1: 0.52
Epoch 38 - Batch (230/363) - Mini-batch Training loss: 0.4693 - Training Acc 1: 0.54
Epoch 38 - Batch (240/363) - Mini-batch Training loss: 0.4724 - Training Acc 1: 0.56
Epoch 38 - Batch (250/363) - Mini-batch Training loss: 0.4792 - Training Acc 1: 0.58
Epoch 38 - Batch (260/363) - Mini-batch Training loss: 0.4884 - Training Acc 1: 0.60
Epoch 38 - Batch (270/363) - Mini-batch Training loss: 0.4897 - Training Acc 1: 0.63
Epoch 38 - Batch (280/363) - Mini-batch Training loss: 0.4861 - Training Acc 1: 0.65
Epoch 38 - Batch (290/363) - Mini-batch Training loss: 0.4781 - Training Acc 1: 0.67
Epoch 38 - Batch (300/363) - Mini-batch Training loss: 0.4771 - Training Acc 1: 0.70
Epoch 38 - Batch (310/363) - Mini-batch Training loss: 0.4784 - Training Acc 1: 0.72
Epoch 38 - Batch (320/363) - Mini-batch Training loss: 0.4905 - Training Acc 1: 0.74
Epoch 38 - Batch (330/363) - Mini-batch Training loss: 0.4903 - Training Acc 1: 0.76
Epoch 38 - Batch (340/363) - Mini-batch Training loss: 0.4873 - Training Acc 1: 0.79
Epoch 38 - Batch (350/363) - Mini-batch Training loss: 0.4887 - Training Acc 1: 0.81
Epoch 38 - Batch (360/363) - Mini-batch Training loss: 0.4851 - Training Acc 1: 0.84
Epoch 38 - Full-batch Training loss: 0.4829 - Training Acc 1: 0.84
Validation set: Average loss: 0.7335, Accuracy: 282.0/363 (78%)

Epoch 39 - Batch (0/363) - Mini-batch Training loss: 0.5057 - Training Acc 1: 0.00
Epoch 39 - Batch (10/363) - Mini-batch Training loss: 0.6878 - Training Acc 1: 0.02
Epoch 39 - Batch (20/363) - Mini-batch Training loss: 0.5481 - Training Acc 1: 0.05
Epoch 39 - Batch (30/363) - Mini-batch Training loss: 0.4627 - Training Acc 1: 0.07
Epoch 39 - Batch (40/363) - Mini-batch Training loss: 0.5225 - Training Acc 1: 0.09
Epoch 39 - Batch (50/363) - Mini-batch Training loss: 0.4813 - Training Acc 1: 0.12
Epoch 39 - Batch (60/363) - Mini-batch Training loss: 0.4453 - Training Acc 1: 0.14
Epoch 39 - Batch (70/363) - Mini-batch Training loss: 0.4559 - Training Acc 1: 0.17
Epoch 39 - Batch (80/363) - Mini-batch Training loss: 0.4400 - Training Acc 1: 0.19
Epoch 39 - Batch (90/363) - Mini-batch Training loss: 0.4450 - Training Acc 1: 0.22
Epoch 39 - Batch (100/363) - Mini-batch Training loss: 0.4814 - Training Acc 1: 0.24
Epoch 39 - Batch (110/363) - Mini-batch Training loss: 0.4875 - Training Acc 1: 0.26
Epoch 39 - Batch (120/363) - Mini-batch Training loss: 0.5088 - Training Acc 1: 0.28
Epoch 39 - Batch (130/363) - Mini-batch Training loss: 0.5042 - Training Acc 1: 0.30
Epoch 39 - Batch (140/363) - Mini-batch Training loss: 0.5058 - Training Acc 1: 0.32
Epoch 39 - Batch (150/363) - Mini-batch Training loss: 0.5233 - Training Acc 1: 0.34
Epoch 39 - Batch (160/363) - Mini-batch Training loss: 0.5155 - Training Acc 1: 0.37
Epoch 39 - Batch (170/363) - Mini-batch Training loss: 0.4949 - Training Acc 1: 0.39
Epoch 39 - Batch (180/363) - Mini-batch Training loss: 0.5031 - Training Acc 1: 0.41
Epoch 39 - Batch (190/363) - Mini-batch Training loss: 0.4938 - Training Acc 1: 0.44
Epoch 39 - Batch (200/363) - Mini-batch Training loss: 0.5016 - Training Acc 1: 0.46
Epoch 39 - Batch (210/363) - Mini-batch Training loss: 0.4975 - Training Acc 1: 0.49
Epoch 39 - Batch (220/363) - Mini-batch Training loss: 0.4944 - Training Acc 1: 0.51
Epoch 39 - Batch (230/363) - Mini-batch Training loss: 0.4842 - Training Acc 1: 0.54
Epoch 39 - Batch (240/363) - Mini-batch Training loss: 0.4806 - Training Acc 1: 0.56
Epoch 39 - Batch (250/363) - Mini-batch Training loss: 0.4770 - Training Acc 1: 0.58
Epoch 39 - Batch (260/363) - Mini-batch Training loss: 0.4758 - Training Acc 1: 0.61
Epoch 39 - Batch (270/363) - Mini-batch Training loss: 0.4714 - Training Acc 1: 0.63
Epoch 39 - Batch (280/363) - Mini-batch Training loss: 0.4736 - Training Acc 1: 0.66
Epoch 39 - Batch (290/363) - Mini-batch Training loss: 0.4704 - Training Acc 1: 0.68
Epoch 39 - Batch (300/363) - Mini-batch Training loss: 0.4694 - Training Acc 1: 0.70
Epoch 39 - Batch (310/363) - Mini-batch Training loss: 0.4771 - Training Acc 1: 0.72
Epoch 39 - Batch (320/363) - Mini-batch Training loss: 0.4805 - Training Acc 1: 0.75
Epoch 39 - Batch (330/363) - Mini-batch Training loss: 0.4821 - Training Acc 1: 0.77
Epoch 39 - Batch (340/363) - Mini-batch Training loss: 0.4834 - Training Acc 1: 0.79
Epoch 39 - Batch (350/363) - Mini-batch Training loss: 0.4801 - Training Acc 1: 0.81
Epoch 39 - Batch (360/363) - Mini-batch Training loss: 0.4829 - Training Acc 1: 0.84
Epoch 39 - Full-batch Training loss: 0.4828 - Training Acc 1: 0.84
Validation set: Average loss: 0.7627, Accuracy: 287.0/363 (79%)

Epoch 40 - Batch (0/363) - Mini-batch Training loss: 0.1314 - Training Acc 1: 0.00
Epoch 40 - Batch (10/363) - Mini-batch Training loss: 0.4235 - Training Acc 1: 0.03
Epoch 40 - Batch (20/363) - Mini-batch Training loss: 0.3134 - Training Acc 1: 0.05
Epoch 40 - Batch (30/363) - Mini-batch Training loss: 0.3266 - Training Acc 1: 0.08
Epoch 40 - Batch (40/363) - Mini-batch Training loss: 0.4434 - Training Acc 1: 0.10
Epoch 40 - Batch (50/363) - Mini-batch Training loss: 0.4857 - Training Acc 1: 0.12
Epoch 40 - Batch (60/363) - Mini-batch Training loss: 0.5186 - Training Acc 1: 0.14
Epoch 40 - Batch (70/363) - Mini-batch Training loss: 0.5229 - Training Acc 1: 0.17
Epoch 40 - Batch (80/363) - Mini-batch Training loss: 0.5159 - Training Acc 1: 0.19
Epoch 40 - Batch (90/363) - Mini-batch Training loss: 0.4929 - Training Acc 1: 0.21
Epoch 40 - Batch (100/363) - Mini-batch Training loss: 0.5064 - Training Acc 1: 0.24
Epoch 40 - Batch (110/363) - Mini-batch Training loss: 0.4782 - Training Acc 1: 0.26
Epoch 40 - Batch (120/363) - Mini-batch Training loss: 0.4691 - Training Acc 1: 0.29
Epoch 40 - Batch (130/363) - Mini-batch Training loss: 0.4815 - Training Acc 1: 0.31
Epoch 40 - Batch (140/363) - Mini-batch Training loss: 0.4846 - Training Acc 1: 0.33
Epoch 40 - Batch (150/363) - Mini-batch Training loss: 0.5047 - Training Acc 1: 0.35
Epoch 40 - Batch (160/363) - Mini-batch Training loss: 0.5157 - Training Acc 1: 0.37
Epoch 40 - Batch (170/363) - Mini-batch Training loss: 0.5096 - Training Acc 1: 0.40
Epoch 40 - Batch (180/363) - Mini-batch Training loss: 0.5101 - Training Acc 1: 0.42
Epoch 40 - Batch (190/363) - Mini-batch Training loss: 0.5186 - Training Acc 1: 0.44
Epoch 40 - Batch (200/363) - Mini-batch Training loss: 0.5089 - Training Acc 1: 0.47
Epoch 40 - Batch (210/363) - Mini-batch Training loss: 0.5047 - Training Acc 1: 0.49
Epoch 40 - Batch (220/363) - Mini-batch Training loss: 0.5052 - Training Acc 1: 0.52
Epoch 40 - Batch (230/363) - Mini-batch Training loss: 0.5168 - Training Acc 1: 0.54
Epoch 40 - Batch (240/363) - Mini-batch Training loss: 0.5268 - Training Acc 1: 0.56
Epoch 40 - Batch (250/363) - Mini-batch Training loss: 0.5277 - Training Acc 1: 0.58
Epoch 40 - Batch (260/363) - Mini-batch Training loss: 0.5262 - Training Acc 1: 0.61
Epoch 40 - Batch (270/363) - Mini-batch Training loss: 0.5258 - Training Acc 1: 0.63
Epoch 40 - Batch (280/363) - Mini-batch Training loss: 0.5222 - Training Acc 1: 0.65
Epoch 40 - Batch (290/363) - Mini-batch Training loss: 0.5135 - Training Acc 1: 0.68
Epoch 40 - Batch (300/363) - Mini-batch Training loss: 0.5155 - Training Acc 1: 0.70
Epoch 40 - Batch (310/363) - Mini-batch Training loss: 0.5107 - Training Acc 1: 0.73
Epoch 40 - Batch (320/363) - Mini-batch Training loss: 0.5048 - Training Acc 1: 0.75
Epoch 40 - Batch (330/363) - Mini-batch Training loss: 0.5100 - Training Acc 1: 0.77
Epoch 40 - Batch (340/363) - Mini-batch Training loss: 0.5069 - Training Acc 1: 0.80
Epoch 40 - Batch (350/363) - Mini-batch Training loss: 0.5075 - Training Acc 1: 0.82
Epoch 40 - Batch (360/363) - Mini-batch Training loss: 0.5063 - Training Acc 1: 0.84
Epoch 40 - Full-batch Training loss: 0.5044 - Training Acc 1: 0.85
Validation set: Average loss: 0.7118, Accuracy: 296.0/363 (82%)

0.8154269972451791
Epoch 41 - Batch (0/363) - Mini-batch Training loss: 0.0243 - Training Acc 1: 0.00
Epoch 41 - Batch (10/363) - Mini-batch Training loss: 0.6177 - Training Acc 1: 0.02
Epoch 41 - Batch (20/363) - Mini-batch Training loss: 0.5141 - Training Acc 1: 0.05
Epoch 41 - Batch (30/363) - Mini-batch Training loss: 0.4988 - Training Acc 1: 0.07
Epoch 41 - Batch (40/363) - Mini-batch Training loss: 0.4853 - Training Acc 1: 0.09
Epoch 41 - Batch (50/363) - Mini-batch Training loss: 0.4778 - Training Acc 1: 0.12
Epoch 41 - Batch (60/363) - Mini-batch Training loss: 0.4466 - Training Acc 1: 0.14
Epoch 41 - Batch (70/363) - Mini-batch Training loss: 0.4534 - Training Acc 1: 0.16
Epoch 41 - Batch (80/363) - Mini-batch Training loss: 0.4299 - Training Acc 1: 0.19
Epoch 41 - Batch (90/363) - Mini-batch Training loss: 0.4381 - Training Acc 1: 0.21
Epoch 41 - Batch (100/363) - Mini-batch Training loss: 0.4510 - Training Acc 1: 0.23
Epoch 41 - Batch (110/363) - Mini-batch Training loss: 0.4378 - Training Acc 1: 0.26
Epoch 41 - Batch (120/363) - Mini-batch Training loss: 0.4604 - Training Acc 1: 0.28
Epoch 41 - Batch (130/363) - Mini-batch Training loss: 0.4761 - Training Acc 1: 0.30
Epoch 41 - Batch (140/363) - Mini-batch Training loss: 0.4899 - Training Acc 1: 0.32
Epoch 41 - Batch (150/363) - Mini-batch Training loss: 0.5024 - Training Acc 1: 0.34
Epoch 41 - Batch (160/363) - Mini-batch Training loss: 0.4971 - Training Acc 1: 0.36
Epoch 41 - Batch (170/363) - Mini-batch Training loss: 0.4922 - Training Acc 1: 0.39
Epoch 41 - Batch (180/363) - Mini-batch Training loss: 0.4819 - Training Acc 1: 0.41
Epoch 41 - Batch (190/363) - Mini-batch Training loss: 0.4795 - Training Acc 1: 0.44
Epoch 41 - Batch (200/363) - Mini-batch Training loss: 0.4727 - Training Acc 1: 0.46
Epoch 41 - Batch (210/363) - Mini-batch Training loss: 0.4613 - Training Acc 1: 0.49
Epoch 41 - Batch (220/363) - Mini-batch Training loss: 0.4682 - Training Acc 1: 0.51
Epoch 41 - Batch (230/363) - Mini-batch Training loss: 0.4638 - Training Acc 1: 0.53
Epoch 41 - Batch (240/363) - Mini-batch Training loss: 0.4595 - Training Acc 1: 0.56
Epoch 41 - Batch (250/363) - Mini-batch Training loss: 0.4688 - Training Acc 1: 0.58
Epoch 41 - Batch (260/363) - Mini-batch Training loss: 0.4822 - Training Acc 1: 0.60
Epoch 41 - Batch (270/363) - Mini-batch Training loss: 0.4847 - Training Acc 1: 0.62
Epoch 41 - Batch (280/363) - Mini-batch Training loss: 0.4818 - Training Acc 1: 0.64
Epoch 41 - Batch (290/363) - Mini-batch Training loss: 0.4841 - Training Acc 1: 0.67
Epoch 41 - Batch (300/363) - Mini-batch Training loss: 0.4895 - Training Acc 1: 0.69
Epoch 41 - Batch (310/363) - Mini-batch Training loss: 0.4879 - Training Acc 1: 0.71
Epoch 41 - Batch (320/363) - Mini-batch Training loss: 0.4911 - Training Acc 1: 0.73
Epoch 41 - Batch (330/363) - Mini-batch Training loss: 0.4904 - Training Acc 1: 0.76
Epoch 41 - Batch (340/363) - Mini-batch Training loss: 0.4870 - Training Acc 1: 0.78
Epoch 41 - Batch (350/363) - Mini-batch Training loss: 0.4845 - Training Acc 1: 0.81
Epoch 41 - Batch (360/363) - Mini-batch Training loss: 0.4837 - Training Acc 1: 0.83
Epoch 41 - Full-batch Training loss: 0.4816 - Training Acc 1: 0.83
Validation set: Average loss: 0.7052, Accuracy: 287.0/363 (79%)

Epoch 42 - Batch (0/363) - Mini-batch Training loss: 0.5043 - Training Acc 1: 0.00
Epoch 42 - Batch (10/363) - Mini-batch Training loss: 0.3203 - Training Acc 1: 0.03
Epoch 42 - Batch (20/363) - Mini-batch Training loss: 0.3506 - Training Acc 1: 0.05
Epoch 42 - Batch (30/363) - Mini-batch Training loss: 0.3618 - Training Acc 1: 0.08
Epoch 42 - Batch (40/363) - Mini-batch Training loss: 0.3226 - Training Acc 1: 0.10
Epoch 42 - Batch (50/363) - Mini-batch Training loss: 0.3724 - Training Acc 1: 0.12
Epoch 42 - Batch (60/363) - Mini-batch Training loss: 0.3791 - Training Acc 1: 0.15
Epoch 42 - Batch (70/363) - Mini-batch Training loss: 0.3917 - Training Acc 1: 0.17
Epoch 42 - Batch (80/363) - Mini-batch Training loss: 0.3933 - Training Acc 1: 0.19
Epoch 42 - Batch (90/363) - Mini-batch Training loss: 0.4136 - Training Acc 1: 0.22
Epoch 42 - Batch (100/363) - Mini-batch Training loss: 0.4193 - Training Acc 1: 0.24
Epoch 42 - Batch (110/363) - Mini-batch Training loss: 0.4549 - Training Acc 1: 0.26
Epoch 42 - Batch (120/363) - Mini-batch Training loss: 0.4610 - Training Acc 1: 0.28
Epoch 42 - Batch (130/363) - Mini-batch Training loss: 0.4607 - Training Acc 1: 0.31
Epoch 42 - Batch (140/363) - Mini-batch Training loss: 0.4562 - Training Acc 1: 0.33
Epoch 42 - Batch (150/363) - Mini-batch Training loss: 0.4743 - Training Acc 1: 0.35
Epoch 42 - Batch (160/363) - Mini-batch Training loss: 0.4796 - Training Acc 1: 0.37
Epoch 42 - Batch (170/363) - Mini-batch Training loss: 0.4733 - Training Acc 1: 0.40
Epoch 42 - Batch (180/363) - Mini-batch Training loss: 0.4714 - Training Acc 1: 0.42
Epoch 42 - Batch (190/363) - Mini-batch Training loss: 0.4663 - Training Acc 1: 0.44
Epoch 42 - Batch (200/363) - Mini-batch Training loss: 0.4706 - Training Acc 1: 0.47
Epoch 42 - Batch (210/363) - Mini-batch Training loss: 0.4644 - Training Acc 1: 0.49
Epoch 42 - Batch (220/363) - Mini-batch Training loss: 0.4602 - Training Acc 1: 0.51
Epoch 42 - Batch (230/363) - Mini-batch Training loss: 0.4597 - Training Acc 1: 0.54
Epoch 42 - Batch (240/363) - Mini-batch Training loss: 0.4703 - Training Acc 1: 0.56
Epoch 42 - Batch (250/363) - Mini-batch Training loss: 0.4718 - Training Acc 1: 0.58
Epoch 42 - Batch (260/363) - Mini-batch Training loss: 0.4655 - Training Acc 1: 0.61
Epoch 42 - Batch (270/363) - Mini-batch Training loss: 0.4691 - Training Acc 1: 0.63
Epoch 42 - Batch (280/363) - Mini-batch Training loss: 0.4693 - Training Acc 1: 0.65
Epoch 42 - Batch (290/363) - Mini-batch Training loss: 0.4623 - Training Acc 1: 0.68
Epoch 42 - Batch (300/363) - Mini-batch Training loss: 0.4615 - Training Acc 1: 0.70
Epoch 42 - Batch (310/363) - Mini-batch Training loss: 0.4595 - Training Acc 1: 0.73
Epoch 42 - Batch (320/363) - Mini-batch Training loss: 0.4598 - Training Acc 1: 0.75
Epoch 42 - Batch (330/363) - Mini-batch Training loss: 0.4657 - Training Acc 1: 0.77
Epoch 42 - Batch (340/363) - Mini-batch Training loss: 0.4601 - Training Acc 1: 0.80
Epoch 42 - Batch (350/363) - Mini-batch Training loss: 0.4550 - Training Acc 1: 0.82
Epoch 42 - Batch (360/363) - Mini-batch Training loss: 0.4590 - Training Acc 1: 0.85
Epoch 42 - Full-batch Training loss: 0.4568 - Training Acc 1: 0.85
Validation set: Average loss: 0.6513, Accuracy: 297.0/363 (82%)

0.8181818181818182
Epoch 43 - Batch (0/363) - Mini-batch Training loss: 0.0136 - Training Acc 1: 0.00
Epoch 43 - Batch (10/363) - Mini-batch Training loss: 0.4461 - Training Acc 1: 0.03
Epoch 43 - Batch (20/363) - Mini-batch Training loss: 0.4997 - Training Acc 1: 0.05
Epoch 43 - Batch (30/363) - Mini-batch Training loss: 0.5229 - Training Acc 1: 0.07
Epoch 43 - Batch (40/363) - Mini-batch Training loss: 0.5169 - Training Acc 1: 0.10
Epoch 43 - Batch (50/363) - Mini-batch Training loss: 0.5088 - Training Acc 1: 0.12
Epoch 43 - Batch (60/363) - Mini-batch Training loss: 0.5225 - Training Acc 1: 0.14
Epoch 43 - Batch (70/363) - Mini-batch Training loss: 0.5182 - Training Acc 1: 0.16
Epoch 43 - Batch (80/363) - Mini-batch Training loss: 0.5150 - Training Acc 1: 0.18
Epoch 43 - Batch (90/363) - Mini-batch Training loss: 0.5304 - Training Acc 1: 0.21
Epoch 43 - Batch (100/363) - Mini-batch Training loss: 0.5117 - Training Acc 1: 0.23
Epoch 43 - Batch (110/363) - Mini-batch Training loss: 0.5064 - Training Acc 1: 0.25
Epoch 43 - Batch (120/363) - Mini-batch Training loss: 0.4986 - Training Acc 1: 0.28
Epoch 43 - Batch (130/363) - Mini-batch Training loss: 0.5162 - Training Acc 1: 0.30
Epoch 43 - Batch (140/363) - Mini-batch Training loss: 0.5119 - Training Acc 1: 0.32
Epoch 43 - Batch (150/363) - Mini-batch Training loss: 0.5078 - Training Acc 1: 0.34
Epoch 43 - Batch (160/363) - Mini-batch Training loss: 0.4983 - Training Acc 1: 0.37
Epoch 43 - Batch (170/363) - Mini-batch Training loss: 0.4867 - Training Acc 1: 0.39
Epoch 43 - Batch (180/363) - Mini-batch Training loss: 0.4774 - Training Acc 1: 0.42
Epoch 43 - Batch (190/363) - Mini-batch Training loss: 0.4828 - Training Acc 1: 0.44
Epoch 43 - Batch (200/363) - Mini-batch Training loss: 0.4798 - Training Acc 1: 0.46
Epoch 43 - Batch (210/363) - Mini-batch Training loss: 0.4780 - Training Acc 1: 0.49
Epoch 43 - Batch (220/363) - Mini-batch Training loss: 0.4807 - Training Acc 1: 0.51
Epoch 43 - Batch (230/363) - Mini-batch Training loss: 0.4879 - Training Acc 1: 0.53
Epoch 43 - Batch (240/363) - Mini-batch Training loss: 0.4812 - Training Acc 1: 0.55
Epoch 43 - Batch (250/363) - Mini-batch Training loss: 0.4803 - Training Acc 1: 0.58
Epoch 43 - Batch (260/363) - Mini-batch Training loss: 0.4848 - Training Acc 1: 0.60
Epoch 43 - Batch (270/363) - Mini-batch Training loss: 0.4863 - Training Acc 1: 0.62
Epoch 43 - Batch (280/363) - Mini-batch Training loss: 0.4852 - Training Acc 1: 0.65
Epoch 43 - Batch (290/363) - Mini-batch Training loss: 0.4837 - Training Acc 1: 0.67
Epoch 43 - Batch (300/363) - Mini-batch Training loss: 0.4766 - Training Acc 1: 0.69
Epoch 43 - Batch (310/363) - Mini-batch Training loss: 0.4734 - Training Acc 1: 0.72
Epoch 43 - Batch (320/363) - Mini-batch Training loss: 0.4719 - Training Acc 1: 0.74
Epoch 43 - Batch (330/363) - Mini-batch Training loss: 0.4639 - Training Acc 1: 0.77
Epoch 43 - Batch (340/363) - Mini-batch Training loss: 0.4626 - Training Acc 1: 0.79
Epoch 43 - Batch (350/363) - Mini-batch Training loss: 0.4576 - Training Acc 1: 0.82
Epoch 43 - Batch (360/363) - Mini-batch Training loss: 0.4537 - Training Acc 1: 0.84
Epoch 43 - Full-batch Training loss: 0.4525 - Training Acc 1: 0.84
Validation set: Average loss: 0.7768, Accuracy: 283.0/363 (78%)

Epoch 44 - Batch (0/363) - Mini-batch Training loss: 0.3064 - Training Acc 1: 0.00
Epoch 44 - Batch (10/363) - Mini-batch Training loss: 0.6051 - Training Acc 1: 0.02
Epoch 44 - Batch (20/363) - Mini-batch Training loss: 0.5311 - Training Acc 1: 0.05
Epoch 44 - Batch (30/363) - Mini-batch Training loss: 0.4612 - Training Acc 1: 0.07
Epoch 44 - Batch (40/363) - Mini-batch Training loss: 0.4851 - Training Acc 1: 0.09
Epoch 44 - Batch (50/363) - Mini-batch Training loss: 0.4962 - Training Acc 1: 0.12
Epoch 44 - Batch (60/363) - Mini-batch Training loss: 0.5098 - Training Acc 1: 0.14
Epoch 44 - Batch (70/363) - Mini-batch Training loss: 0.4771 - Training Acc 1: 0.16
Epoch 44 - Batch (80/363) - Mini-batch Training loss: 0.5036 - Training Acc 1: 0.18
Epoch 44 - Batch (90/363) - Mini-batch Training loss: 0.4835 - Training Acc 1: 0.21
Epoch 44 - Batch (100/363) - Mini-batch Training loss: 0.4944 - Training Acc 1: 0.23
Epoch 44 - Batch (110/363) - Mini-batch Training loss: 0.4785 - Training Acc 1: 0.26
Epoch 44 - Batch (120/363) - Mini-batch Training loss: 0.4621 - Training Acc 1: 0.28
Epoch 44 - Batch (130/363) - Mini-batch Training loss: 0.4606 - Training Acc 1: 0.31
Epoch 44 - Batch (140/363) - Mini-batch Training loss: 0.4514 - Training Acc 1: 0.33
Epoch 44 - Batch (150/363) - Mini-batch Training loss: 0.4616 - Training Acc 1: 0.35
Epoch 44 - Batch (160/363) - Mini-batch Training loss: 0.4489 - Training Acc 1: 0.38
Epoch 44 - Batch (170/363) - Mini-batch Training loss: 0.4433 - Training Acc 1: 0.40
Epoch 44 - Batch (180/363) - Mini-batch Training loss: 0.4392 - Training Acc 1: 0.43
Epoch 44 - Batch (190/363) - Mini-batch Training loss: 0.4376 - Training Acc 1: 0.45
Epoch 44 - Batch (200/363) - Mini-batch Training loss: 0.4420 - Training Acc 1: 0.47
Epoch 44 - Batch (210/363) - Mini-batch Training loss: 0.4379 - Training Acc 1: 0.50
Epoch 44 - Batch (220/363) - Mini-batch Training loss: 0.4328 - Training Acc 1: 0.52
Epoch 44 - Batch (230/363) - Mini-batch Training loss: 0.4395 - Training Acc 1: 0.54
Epoch 44 - Batch (240/363) - Mini-batch Training loss: 0.4415 - Training Acc 1: 0.57
Epoch 44 - Batch (250/363) - Mini-batch Training loss: 0.4399 - Training Acc 1: 0.59
Epoch 44 - Batch (260/363) - Mini-batch Training loss: 0.4446 - Training Acc 1: 0.62
Epoch 44 - Batch (270/363) - Mini-batch Training loss: 0.4420 - Training Acc 1: 0.64
Epoch 44 - Batch (280/363) - Mini-batch Training loss: 0.4491 - Training Acc 1: 0.66
Epoch 44 - Batch (290/363) - Mini-batch Training loss: 0.4666 - Training Acc 1: 0.68
Epoch 44 - Batch (300/363) - Mini-batch Training loss: 0.4626 - Training Acc 1: 0.71
Epoch 44 - Batch (310/363) - Mini-batch Training loss: 0.4625 - Training Acc 1: 0.73
Epoch 44 - Batch (320/363) - Mini-batch Training loss: 0.4620 - Training Acc 1: 0.76
Epoch 44 - Batch (330/363) - Mini-batch Training loss: 0.4716 - Training Acc 1: 0.78
Epoch 44 - Batch (340/363) - Mini-batch Training loss: 0.4661 - Training Acc 1: 0.80
Epoch 44 - Batch (350/363) - Mini-batch Training loss: 0.4601 - Training Acc 1: 0.83
Epoch 44 - Batch (360/363) - Mini-batch Training loss: 0.4581 - Training Acc 1: 0.85
Epoch 44 - Full-batch Training loss: 0.4643 - Training Acc 1: 0.85
Validation set: Average loss: 0.7299, Accuracy: 293.0/363 (81%)

Epoch 45 - Batch (0/363) - Mini-batch Training loss: 0.9604 - Training Acc 1: 0.00
Epoch 45 - Batch (10/363) - Mini-batch Training loss: 0.3469 - Training Acc 1: 0.03
Epoch 45 - Batch (20/363) - Mini-batch Training loss: 0.4479 - Training Acc 1: 0.05
Epoch 45 - Batch (30/363) - Mini-batch Training loss: 0.4023 - Training Acc 1: 0.07
Epoch 45 - Batch (40/363) - Mini-batch Training loss: 0.4104 - Training Acc 1: 0.10
Epoch 45 - Batch (50/363) - Mini-batch Training loss: 0.4554 - Training Acc 1: 0.12
Epoch 45 - Batch (60/363) - Mini-batch Training loss: 0.4404 - Training Acc 1: 0.14
Epoch 45 - Batch (70/363) - Mini-batch Training loss: 0.4258 - Training Acc 1: 0.17
Epoch 45 - Batch (80/363) - Mini-batch Training loss: 0.4042 - Training Acc 1: 0.19
Epoch 45 - Batch (90/363) - Mini-batch Training loss: 0.4474 - Training Acc 1: 0.22
Epoch 45 - Batch (100/363) - Mini-batch Training loss: 0.4464 - Training Acc 1: 0.24
Epoch 45 - Batch (110/363) - Mini-batch Training loss: 0.4551 - Training Acc 1: 0.26
Epoch 45 - Batch (120/363) - Mini-batch Training loss: 0.4462 - Training Acc 1: 0.29
Epoch 45 - Batch (130/363) - Mini-batch Training loss: 0.4530 - Training Acc 1: 0.31
Epoch 45 - Batch (140/363) - Mini-batch Training loss: 0.4496 - Training Acc 1: 0.33
Epoch 45 - Batch (150/363) - Mini-batch Training loss: 0.4421 - Training Acc 1: 0.36
Epoch 45 - Batch (160/363) - Mini-batch Training loss: 0.4399 - Training Acc 1: 0.38
Epoch 45 - Batch (170/363) - Mini-batch Training loss: 0.4453 - Training Acc 1: 0.40
Epoch 45 - Batch (180/363) - Mini-batch Training loss: 0.4647 - Training Acc 1: 0.42
Epoch 45 - Batch (190/363) - Mini-batch Training loss: 0.4696 - Training Acc 1: 0.45
Epoch 45 - Batch (200/363) - Mini-batch Training loss: 0.4671 - Training Acc 1: 0.47
Epoch 45 - Batch (210/363) - Mini-batch Training loss: 0.4695 - Training Acc 1: 0.49
Epoch 45 - Batch (220/363) - Mini-batch Training loss: 0.4678 - Training Acc 1: 0.51
Epoch 45 - Batch (230/363) - Mini-batch Training loss: 0.4648 - Training Acc 1: 0.54
Epoch 45 - Batch (240/363) - Mini-batch Training loss: 0.4599 - Training Acc 1: 0.56
Epoch 45 - Batch (250/363) - Mini-batch Training loss: 0.4587 - Training Acc 1: 0.59
Epoch 45 - Batch (260/363) - Mini-batch Training loss: 0.4509 - Training Acc 1: 0.61
Epoch 45 - Batch (270/363) - Mini-batch Training loss: 0.4473 - Training Acc 1: 0.64
Epoch 45 - Batch (280/363) - Mini-batch Training loss: 0.4418 - Training Acc 1: 0.66
Epoch 45 - Batch (290/363) - Mini-batch Training loss: 0.4328 - Training Acc 1: 0.69
Epoch 45 - Batch (300/363) - Mini-batch Training loss: 0.4299 - Training Acc 1: 0.71
Epoch 45 - Batch (310/363) - Mini-batch Training loss: 0.4332 - Training Acc 1: 0.73
Epoch 45 - Batch (320/363) - Mini-batch Training loss: 0.4253 - Training Acc 1: 0.76
Epoch 45 - Batch (330/363) - Mini-batch Training loss: 0.4215 - Training Acc 1: 0.78
Epoch 45 - Batch (340/363) - Mini-batch Training loss: 0.4251 - Training Acc 1: 0.81
Epoch 45 - Batch (350/363) - Mini-batch Training loss: 0.4287 - Training Acc 1: 0.83
Epoch 45 - Batch (360/363) - Mini-batch Training loss: 0.4270 - Training Acc 1: 0.85
Epoch 45 - Full-batch Training loss: 0.4248 - Training Acc 1: 0.86
Validation set: Average loss: 0.6925, Accuracy: 299.0/363 (82%)

0.8236914600550964
Epoch 46 - Batch (0/363) - Mini-batch Training loss: 0.1045 - Training Acc 1: 0.00
Epoch 46 - Batch (10/363) - Mini-batch Training loss: 0.3789 - Training Acc 1: 0.03
Epoch 46 - Batch (20/363) - Mini-batch Training loss: 0.3405 - Training Acc 1: 0.05
Epoch 46 - Batch (30/363) - Mini-batch Training loss: 0.3629 - Training Acc 1: 0.08
Epoch 46 - Batch (40/363) - Mini-batch Training loss: 0.4029 - Training Acc 1: 0.10
Epoch 46 - Batch (50/363) - Mini-batch Training loss: 0.4349 - Training Acc 1: 0.12
Epoch 46 - Batch (60/363) - Mini-batch Training loss: 0.4131 - Training Acc 1: 0.15
Epoch 46 - Batch (70/363) - Mini-batch Training loss: 0.4091 - Training Acc 1: 0.17
Epoch 46 - Batch (80/363) - Mini-batch Training loss: 0.3879 - Training Acc 1: 0.20
Epoch 46 - Batch (90/363) - Mini-batch Training loss: 0.4020 - Training Acc 1: 0.22
Epoch 46 - Batch (100/363) - Mini-batch Training loss: 0.4073 - Training Acc 1: 0.24
Epoch 46 - Batch (110/363) - Mini-batch Training loss: 0.4236 - Training Acc 1: 0.27
Epoch 46 - Batch (120/363) - Mini-batch Training loss: 0.4254 - Training Acc 1: 0.29
Epoch 46 - Batch (130/363) - Mini-batch Training loss: 0.4324 - Training Acc 1: 0.31
Epoch 46 - Batch (140/363) - Mini-batch Training loss: 0.4408 - Training Acc 1: 0.34
Epoch 46 - Batch (150/363) - Mini-batch Training loss: 0.4352 - Training Acc 1: 0.36
Epoch 46 - Batch (160/363) - Mini-batch Training loss: 0.4340 - Training Acc 1: 0.39
Epoch 46 - Batch (170/363) - Mini-batch Training loss: 0.4274 - Training Acc 1: 0.41
Epoch 46 - Batch (180/363) - Mini-batch Training loss: 0.4174 - Training Acc 1: 0.44
Epoch 46 - Batch (190/363) - Mini-batch Training loss: 0.4231 - Training Acc 1: 0.46
Epoch 46 - Batch (200/363) - Mini-batch Training loss: 0.4216 - Training Acc 1: 0.48
Epoch 46 - Batch (210/363) - Mini-batch Training loss: 0.4274 - Training Acc 1: 0.51
Epoch 46 - Batch (220/363) - Mini-batch Training loss: 0.4347 - Training Acc 1: 0.53
Epoch 46 - Batch (230/363) - Mini-batch Training loss: 0.4393 - Training Acc 1: 0.55
Epoch 46 - Batch (240/363) - Mini-batch Training loss: 0.4457 - Training Acc 1: 0.57
Epoch 46 - Batch (250/363) - Mini-batch Training loss: 0.4454 - Training Acc 1: 0.60
Epoch 46 - Batch (260/363) - Mini-batch Training loss: 0.4455 - Training Acc 1: 0.62
Epoch 46 - Batch (270/363) - Mini-batch Training loss: 0.4438 - Training Acc 1: 0.65
Epoch 46 - Batch (280/363) - Mini-batch Training loss: 0.4364 - Training Acc 1: 0.67
Epoch 46 - Batch (290/363) - Mini-batch Training loss: 0.4374 - Training Acc 1: 0.70
Epoch 46 - Batch (300/363) - Mini-batch Training loss: 0.4432 - Training Acc 1: 0.72
Epoch 46 - Batch (310/363) - Mini-batch Training loss: 0.4434 - Training Acc 1: 0.74
Epoch 46 - Batch (320/363) - Mini-batch Training loss: 0.4424 - Training Acc 1: 0.77
Epoch 46 - Batch (330/363) - Mini-batch Training loss: 0.4414 - Training Acc 1: 0.79
Epoch 46 - Batch (340/363) - Mini-batch Training loss: 0.4390 - Training Acc 1: 0.81
Epoch 46 - Batch (350/363) - Mini-batch Training loss: 0.4350 - Training Acc 1: 0.84
Epoch 46 - Batch (360/363) - Mini-batch Training loss: 0.4407 - Training Acc 1: 0.86
Epoch 46 - Full-batch Training loss: 0.4418 - Training Acc 1: 0.86
Validation set: Average loss: 0.7482, Accuracy: 291.0/363 (80%)

Epoch 47 - Batch (0/363) - Mini-batch Training loss: 0.4851 - Training Acc 1: 0.00
Epoch 47 - Batch (10/363) - Mini-batch Training loss: 0.4402 - Training Acc 1: 0.03
Epoch 47 - Batch (20/363) - Mini-batch Training loss: 0.4078 - Training Acc 1: 0.05
Epoch 47 - Batch (30/363) - Mini-batch Training loss: 0.4448 - Training Acc 1: 0.07
Epoch 47 - Batch (40/363) - Mini-batch Training loss: 0.4699 - Training Acc 1: 0.09
Epoch 47 - Batch (50/363) - Mini-batch Training loss: 0.4618 - Training Acc 1: 0.12
Epoch 47 - Batch (60/363) - Mini-batch Training loss: 0.4656 - Training Acc 1: 0.14
Epoch 47 - Batch (70/363) - Mini-batch Training loss: 0.4530 - Training Acc 1: 0.17
Epoch 47 - Batch (80/363) - Mini-batch Training loss: 0.4431 - Training Acc 1: 0.19
Epoch 47 - Batch (90/363) - Mini-batch Training loss: 0.4654 - Training Acc 1: 0.21
Epoch 47 - Batch (100/363) - Mini-batch Training loss: 0.4596 - Training Acc 1: 0.24
Epoch 47 - Batch (110/363) - Mini-batch Training loss: 0.4434 - Training Acc 1: 0.26
Epoch 47 - Batch (120/363) - Mini-batch Training loss: 0.4379 - Training Acc 1: 0.29
Epoch 47 - Batch (130/363) - Mini-batch Training loss: 0.4315 - Training Acc 1: 0.31
Epoch 47 - Batch (140/363) - Mini-batch Training loss: 0.4321 - Training Acc 1: 0.34
Epoch 47 - Batch (150/363) - Mini-batch Training loss: 0.4267 - Training Acc 1: 0.36
Epoch 47 - Batch (160/363) - Mini-batch Training loss: 0.4174 - Training Acc 1: 0.39
Epoch 47 - Batch (170/363) - Mini-batch Training loss: 0.4166 - Training Acc 1: 0.41
Epoch 47 - Batch (180/363) - Mini-batch Training loss: 0.4112 - Training Acc 1: 0.44
Epoch 47 - Batch (190/363) - Mini-batch Training loss: 0.4085 - Training Acc 1: 0.46
Epoch 47 - Batch (200/363) - Mini-batch Training loss: 0.4092 - Training Acc 1: 0.48
Epoch 47 - Batch (210/363) - Mini-batch Training loss: 0.4119 - Training Acc 1: 0.51
Epoch 47 - Batch (220/363) - Mini-batch Training loss: 0.4060 - Training Acc 1: 0.53
Epoch 47 - Batch (230/363) - Mini-batch Training loss: 0.4238 - Training Acc 1: 0.55
Epoch 47 - Batch (240/363) - Mini-batch Training loss: 0.4193 - Training Acc 1: 0.58
Epoch 47 - Batch (250/363) - Mini-batch Training loss: 0.4157 - Training Acc 1: 0.60
Epoch 47 - Batch (260/363) - Mini-batch Training loss: 0.4137 - Training Acc 1: 0.63
Epoch 47 - Batch (270/363) - Mini-batch Training loss: 0.4050 - Training Acc 1: 0.65
Epoch 47 - Batch (280/363) - Mini-batch Training loss: 0.4041 - Training Acc 1: 0.68
Epoch 47 - Batch (290/363) - Mini-batch Training loss: 0.4031 - Training Acc 1: 0.70
Epoch 47 - Batch (300/363) - Mini-batch Training loss: 0.4069 - Training Acc 1: 0.73
Epoch 47 - Batch (310/363) - Mini-batch Training loss: 0.4112 - Training Acc 1: 0.75
Epoch 47 - Batch (320/363) - Mini-batch Training loss: 0.4158 - Training Acc 1: 0.77
Epoch 47 - Batch (330/363) - Mini-batch Training loss: 0.4171 - Training Acc 1: 0.79
Epoch 47 - Batch (340/363) - Mini-batch Training loss: 0.4110 - Training Acc 1: 0.82
Epoch 47 - Batch (350/363) - Mini-batch Training loss: 0.4127 - Training Acc 1: 0.84
Epoch 47 - Batch (360/363) - Mini-batch Training loss: 0.4125 - Training Acc 1: 0.86
Epoch 47 - Full-batch Training loss: 0.4113 - Training Acc 1: 0.87
Validation set: Average loss: 0.6682, Accuracy: 295.0/363 (81%)

Epoch 48 - Batch (0/363) - Mini-batch Training loss: 0.8475 - Training Acc 1: 0.00
Epoch 48 - Batch (10/363) - Mini-batch Training loss: 0.3377 - Training Acc 1: 0.03
Epoch 48 - Batch (20/363) - Mini-batch Training loss: 0.4364 - Training Acc 1: 0.05
Epoch 48 - Batch (30/363) - Mini-batch Training loss: 0.4064 - Training Acc 1: 0.07
Epoch 48 - Batch (40/363) - Mini-batch Training loss: 0.4301 - Training Acc 1: 0.10
Epoch 48 - Batch (50/363) - Mini-batch Training loss: 0.4144 - Training Acc 1: 0.12
Epoch 48 - Batch (60/363) - Mini-batch Training loss: 0.4011 - Training Acc 1: 0.14
Epoch 48 - Batch (70/363) - Mini-batch Training loss: 0.4132 - Training Acc 1: 0.16
Epoch 48 - Batch (80/363) - Mini-batch Training loss: 0.4046 - Training Acc 1: 0.19
Epoch 48 - Batch (90/363) - Mini-batch Training loss: 0.4100 - Training Acc 1: 0.21
Epoch 48 - Batch (100/363) - Mini-batch Training loss: 0.4222 - Training Acc 1: 0.24
Epoch 48 - Batch (110/363) - Mini-batch Training loss: 0.4170 - Training Acc 1: 0.26
Epoch 48 - Batch (120/363) - Mini-batch Training loss: 0.4108 - Training Acc 1: 0.29
Epoch 48 - Batch (130/363) - Mini-batch Training loss: 0.4154 - Training Acc 1: 0.31
Epoch 48 - Batch (140/363) - Mini-batch Training loss: 0.4228 - Training Acc 1: 0.33
Epoch 48 - Batch (150/363) - Mini-batch Training loss: 0.4173 - Training Acc 1: 0.36
Epoch 48 - Batch (160/363) - Mini-batch Training loss: 0.4062 - Training Acc 1: 0.39
Epoch 48 - Batch (170/363) - Mini-batch Training loss: 0.4048 - Training Acc 1: 0.41
Epoch 48 - Batch (180/363) - Mini-batch Training loss: 0.4113 - Training Acc 1: 0.43
Epoch 48 - Batch (190/363) - Mini-batch Training loss: 0.4113 - Training Acc 1: 0.45
Epoch 48 - Batch (200/363) - Mini-batch Training loss: 0.4084 - Training Acc 1: 0.48
Epoch 48 - Batch (210/363) - Mini-batch Training loss: 0.4065 - Training Acc 1: 0.50
Epoch 48 - Batch (220/363) - Mini-batch Training loss: 0.4088 - Training Acc 1: 0.53
Epoch 48 - Batch (230/363) - Mini-batch Training loss: 0.4086 - Training Acc 1: 0.55
Epoch 48 - Batch (240/363) - Mini-batch Training loss: 0.4050 - Training Acc 1: 0.58
Epoch 48 - Batch (250/363) - Mini-batch Training loss: 0.4077 - Training Acc 1: 0.60
Epoch 48 - Batch (260/363) - Mini-batch Training loss: 0.4099 - Training Acc 1: 0.63
Epoch 48 - Batch (270/363) - Mini-batch Training loss: 0.4205 - Training Acc 1: 0.65
Epoch 48 - Batch (280/363) - Mini-batch Training loss: 0.4179 - Training Acc 1: 0.67
Epoch 48 - Batch (290/363) - Mini-batch Training loss: 0.4196 - Training Acc 1: 0.70
Epoch 48 - Batch (300/363) - Mini-batch Training loss: 0.4219 - Training Acc 1: 0.72
Epoch 48 - Batch (310/363) - Mini-batch Training loss: 0.4198 - Training Acc 1: 0.74
Epoch 48 - Batch (320/363) - Mini-batch Training loss: 0.4213 - Training Acc 1: 0.77
Epoch 48 - Batch (330/363) - Mini-batch Training loss: 0.4179 - Training Acc 1: 0.79
Epoch 48 - Batch (340/363) - Mini-batch Training loss: 0.4128 - Training Acc 1: 0.82
Epoch 48 - Batch (350/363) - Mini-batch Training loss: 0.4178 - Training Acc 1: 0.84
Epoch 48 - Batch (360/363) - Mini-batch Training loss: 0.4159 - Training Acc 1: 0.87
Epoch 48 - Full-batch Training loss: 0.4163 - Training Acc 1: 0.87
Validation set: Average loss: 0.6873, Accuracy: 289.0/363 (80%)

Epoch 49 - Batch (0/363) - Mini-batch Training loss: 0.0086 - Training Acc 1: 0.00
Epoch 49 - Batch (10/363) - Mini-batch Training loss: 0.3741 - Training Acc 1: 0.03
Epoch 49 - Batch (20/363) - Mini-batch Training loss: 0.4954 - Training Acc 1: 0.05
Epoch 49 - Batch (30/363) - Mini-batch Training loss: 0.4335 - Training Acc 1: 0.07
Epoch 49 - Batch (40/363) - Mini-batch Training loss: 0.4442 - Training Acc 1: 0.10
Epoch 49 - Batch (50/363) - Mini-batch Training loss: 0.4126 - Training Acc 1: 0.12
Epoch 49 - Batch (60/363) - Mini-batch Training loss: 0.4064 - Training Acc 1: 0.15
Epoch 49 - Batch (70/363) - Mini-batch Training loss: 0.3957 - Training Acc 1: 0.17
Epoch 49 - Batch (80/363) - Mini-batch Training loss: 0.3897 - Training Acc 1: 0.20
Epoch 49 - Batch (90/363) - Mini-batch Training loss: 0.3978 - Training Acc 1: 0.22
Epoch 49 - Batch (100/363) - Mini-batch Training loss: 0.3908 - Training Acc 1: 0.24
Epoch 49 - Batch (110/363) - Mini-batch Training loss: 0.4044 - Training Acc 1: 0.27
Epoch 49 - Batch (120/363) - Mini-batch Training loss: 0.4211 - Training Acc 1: 0.29
Epoch 49 - Batch (130/363) - Mini-batch Training loss: 0.4097 - Training Acc 1: 0.31
Epoch 49 - Batch (140/363) - Mini-batch Training loss: 0.4282 - Training Acc 1: 0.34
Epoch 49 - Batch (150/363) - Mini-batch Training loss: 0.4275 - Training Acc 1: 0.36
Epoch 49 - Batch (160/363) - Mini-batch Training loss: 0.4531 - Training Acc 1: 0.38
Epoch 49 - Batch (170/363) - Mini-batch Training loss: 0.4391 - Training Acc 1: 0.41
Epoch 49 - Batch (180/363) - Mini-batch Training loss: 0.4378 - Training Acc 1: 0.43
Epoch 49 - Batch (190/363) - Mini-batch Training loss: 0.4516 - Training Acc 1: 0.45
Epoch 49 - Batch (200/363) - Mini-batch Training loss: 0.4414 - Training Acc 1: 0.48
Epoch 49 - Batch (210/363) - Mini-batch Training loss: 0.4343 - Training Acc 1: 0.50
Epoch 49 - Batch (220/363) - Mini-batch Training loss: 0.4315 - Training Acc 1: 0.53
Epoch 49 - Batch (230/363) - Mini-batch Training loss: 0.4328 - Training Acc 1: 0.55
Epoch 49 - Batch (240/363) - Mini-batch Training loss: 0.4224 - Training Acc 1: 0.57
Epoch 49 - Batch (250/363) - Mini-batch Training loss: 0.4295 - Training Acc 1: 0.60
Epoch 49 - Batch (260/363) - Mini-batch Training loss: 0.4363 - Training Acc 1: 0.62
Epoch 49 - Batch (270/363) - Mini-batch Training loss: 0.4351 - Training Acc 1: 0.64
Epoch 49 - Batch (280/363) - Mini-batch Training loss: 0.4329 - Training Acc 1: 0.67
Epoch 49 - Batch (290/363) - Mini-batch Training loss: 0.4294 - Training Acc 1: 0.69
Epoch 49 - Batch (300/363) - Mini-batch Training loss: 0.4298 - Training Acc 1: 0.72
Epoch 49 - Batch (310/363) - Mini-batch Training loss: 0.4245 - Training Acc 1: 0.74
Epoch 49 - Batch (320/363) - Mini-batch Training loss: 0.4261 - Training Acc 1: 0.77
Epoch 49 - Batch (330/363) - Mini-batch Training loss: 0.4279 - Training Acc 1: 0.79
Epoch 49 - Batch (340/363) - Mini-batch Training loss: 0.4294 - Training Acc 1: 0.81
Epoch 49 - Batch (350/363) - Mini-batch Training loss: 0.4312 - Training Acc 1: 0.83
Epoch 49 - Batch (360/363) - Mini-batch Training loss: 0.4318 - Training Acc 1: 0.86
Epoch 49 - Full-batch Training loss: 0.4295 - Training Acc 1: 0.86
Validation set: Average loss: 0.8076, Accuracy: 278.0/363 (77%)

Epoch 50 - Batch (0/363) - Mini-batch Training loss: 0.9488 - Training Acc 1: 0.00
Epoch 50 - Batch (10/363) - Mini-batch Training loss: 0.4886 - Training Acc 1: 0.02
Epoch 50 - Batch (20/363) - Mini-batch Training loss: 0.4103 - Training Acc 1: 0.05
Epoch 50 - Batch (30/363) - Mini-batch Training loss: 0.4427 - Training Acc 1: 0.07
Epoch 50 - Batch (40/363) - Mini-batch Training loss: 0.4264 - Training Acc 1: 0.10
Epoch 50 - Batch (50/363) - Mini-batch Training loss: 0.3739 - Training Acc 1: 0.12
Epoch 50 - Batch (60/363) - Mini-batch Training loss: 0.3964 - Training Acc 1: 0.15
Epoch 50 - Batch (70/363) - Mini-batch Training loss: 0.4054 - Training Acc 1: 0.17
Epoch 50 - Batch (80/363) - Mini-batch Training loss: 0.3866 - Training Acc 1: 0.20
Epoch 50 - Batch (90/363) - Mini-batch Training loss: 0.3804 - Training Acc 1: 0.22
Epoch 50 - Batch (100/363) - Mini-batch Training loss: 0.3748 - Training Acc 1: 0.24
Epoch 50 - Batch (110/363) - Mini-batch Training loss: 0.3782 - Training Acc 1: 0.27
Epoch 50 - Batch (120/363) - Mini-batch Training loss: 0.3738 - Training Acc 1: 0.29
Epoch 50 - Batch (130/363) - Mini-batch Training loss: 0.3634 - Training Acc 1: 0.32
Epoch 50 - Batch (140/363) - Mini-batch Training loss: 0.3669 - Training Acc 1: 0.34
Epoch 50 - Batch (150/363) - Mini-batch Training loss: 0.3834 - Training Acc 1: 0.36
Epoch 50 - Batch (160/363) - Mini-batch Training loss: 0.4002 - Training Acc 1: 0.39
Epoch 50 - Batch (170/363) - Mini-batch Training loss: 0.4070 - Training Acc 1: 0.41
Epoch 50 - Batch (180/363) - Mini-batch Training loss: 0.4048 - Training Acc 1: 0.43
Epoch 50 - Batch (190/363) - Mini-batch Training loss: 0.4065 - Training Acc 1: 0.46
Epoch 50 - Batch (200/363) - Mini-batch Training loss: 0.4015 - Training Acc 1: 0.48
Epoch 50 - Batch (210/363) - Mini-batch Training loss: 0.3882 - Training Acc 1: 0.51
Epoch 50 - Batch (220/363) - Mini-batch Training loss: 0.3837 - Training Acc 1: 0.53
Epoch 50 - Batch (230/363) - Mini-batch Training loss: 0.3848 - Training Acc 1: 0.56
Epoch 50 - Batch (240/363) - Mini-batch Training loss: 0.3905 - Training Acc 1: 0.58
Epoch 50 - Batch (250/363) - Mini-batch Training loss: 0.3881 - Training Acc 1: 0.60
Epoch 50 - Batch (260/363) - Mini-batch Training loss: 0.3934 - Training Acc 1: 0.63
Epoch 50 - Batch (270/363) - Mini-batch Training loss: 0.3950 - Training Acc 1: 0.65
Epoch 50 - Batch (280/363) - Mini-batch Training loss: 0.4020 - Training Acc 1: 0.67
Epoch 50 - Batch (290/363) - Mini-batch Training loss: 0.4082 - Training Acc 1: 0.69
Epoch 50 - Batch (300/363) - Mini-batch Training loss: 0.4044 - Training Acc 1: 0.72
Epoch 50 - Batch (310/363) - Mini-batch Training loss: 0.4017 - Training Acc 1: 0.74
Epoch 50 - Batch (320/363) - Mini-batch Training loss: 0.3950 - Training Acc 1: 0.77
Epoch 50 - Batch (330/363) - Mini-batch Training loss: 0.3956 - Training Acc 1: 0.79
Epoch 50 - Batch (340/363) - Mini-batch Training loss: 0.3917 - Training Acc 1: 0.82
Epoch 50 - Batch (350/363) - Mini-batch Training loss: 0.3939 - Training Acc 1: 0.84
Epoch 50 - Batch (360/363) - Mini-batch Training loss: 0.3922 - Training Acc 1: 0.86
Epoch 50 - Full-batch Training loss: 0.3905 - Training Acc 1: 0.87
Validation set: Average loss: 0.6908, Accuracy: 291.0/363 (80%)

Epoch 51 - Batch (0/363) - Mini-batch Training loss: 1.1021 - Training Acc 1: 0.00
Epoch 51 - Batch (10/363) - Mini-batch Training loss: 0.3796 - Training Acc 1: 0.03
Epoch 51 - Batch (20/363) - Mini-batch Training loss: 0.3914 - Training Acc 1: 0.05
Epoch 51 - Batch (30/363) - Mini-batch Training loss: 0.3799 - Training Acc 1: 0.07
Epoch 51 - Batch (40/363) - Mini-batch Training loss: 0.3706 - Training Acc 1: 0.10
Epoch 51 - Batch (50/363) - Mini-batch Training loss: 0.3447 - Training Acc 1: 0.12
Epoch 51 - Batch (60/363) - Mini-batch Training loss: 0.3478 - Training Acc 1: 0.15
Epoch 51 - Batch (70/363) - Mini-batch Training loss: 0.3485 - Training Acc 1: 0.17
Epoch 51 - Batch (80/363) - Mini-batch Training loss: 0.3325 - Training Acc 1: 0.20
Epoch 51 - Batch (90/363) - Mini-batch Training loss: 0.3440 - Training Acc 1: 0.22
Epoch 51 - Batch (100/363) - Mini-batch Training loss: 0.3475 - Training Acc 1: 0.25
Epoch 51 - Batch (110/363) - Mini-batch Training loss: 0.3396 - Training Acc 1: 0.27
Epoch 51 - Batch (120/363) - Mini-batch Training loss: 0.3326 - Training Acc 1: 0.30
Epoch 51 - Batch (130/363) - Mini-batch Training loss: 0.3388 - Training Acc 1: 0.32
Epoch 51 - Batch (140/363) - Mini-batch Training loss: 0.3379 - Training Acc 1: 0.35
Epoch 51 - Batch (150/363) - Mini-batch Training loss: 0.3395 - Training Acc 1: 0.37
Epoch 51 - Batch (160/363) - Mini-batch Training loss: 0.3355 - Training Acc 1: 0.39
Epoch 51 - Batch (170/363) - Mini-batch Training loss: 0.3353 - Training Acc 1: 0.42
Epoch 51 - Batch (180/363) - Mini-batch Training loss: 0.3462 - Training Acc 1: 0.44
Epoch 51 - Batch (190/363) - Mini-batch Training loss: 0.3578 - Training Acc 1: 0.46
Epoch 51 - Batch (200/363) - Mini-batch Training loss: 0.3677 - Training Acc 1: 0.49
Epoch 51 - Batch (210/363) - Mini-batch Training loss: 0.3726 - Training Acc 1: 0.51
Epoch 51 - Batch (220/363) - Mini-batch Training loss: 0.3725 - Training Acc 1: 0.53
Epoch 51 - Batch (230/363) - Mini-batch Training loss: 0.3839 - Training Acc 1: 0.55
Epoch 51 - Batch (240/363) - Mini-batch Training loss: 0.3878 - Training Acc 1: 0.58
Epoch 51 - Batch (250/363) - Mini-batch Training loss: 0.3810 - Training Acc 1: 0.60
Epoch 51 - Batch (260/363) - Mini-batch Training loss: 0.3855 - Training Acc 1: 0.63
Epoch 51 - Batch (270/363) - Mini-batch Training loss: 0.3891 - Training Acc 1: 0.65
Epoch 51 - Batch (280/363) - Mini-batch Training loss: 0.3869 - Training Acc 1: 0.67
Epoch 51 - Batch (290/363) - Mini-batch Training loss: 0.3890 - Training Acc 1: 0.70
Epoch 51 - Batch (300/363) - Mini-batch Training loss: 0.3863 - Training Acc 1: 0.72
Epoch 51 - Batch (310/363) - Mini-batch Training loss: 0.3815 - Training Acc 1: 0.75
Epoch 51 - Batch (320/363) - Mini-batch Training loss: 0.3829 - Training Acc 1: 0.77
Epoch 51 - Batch (330/363) - Mini-batch Training loss: 0.3812 - Training Acc 1: 0.80
Epoch 51 - Batch (340/363) - Mini-batch Training loss: 0.3845 - Training Acc 1: 0.82
Epoch 51 - Batch (350/363) - Mini-batch Training loss: 0.3864 - Training Acc 1: 0.84
Epoch 51 - Batch (360/363) - Mini-batch Training loss: 0.3829 - Training Acc 1: 0.87
Epoch 51 - Full-batch Training loss: 0.3823 - Training Acc 1: 0.87
Validation set: Average loss: 0.6809, Accuracy: 296.0/363 (82%)

Epoch 52 - Batch (0/363) - Mini-batch Training loss: 0.5813 - Training Acc 1: 0.00
Epoch 52 - Batch (10/363) - Mini-batch Training loss: 0.3059 - Training Acc 1: 0.03
Epoch 52 - Batch (20/363) - Mini-batch Training loss: 0.3504 - Training Acc 1: 0.05
Epoch 52 - Batch (30/363) - Mini-batch Training loss: 0.3119 - Training Acc 1: 0.08
Epoch 52 - Batch (40/363) - Mini-batch Training loss: 0.3566 - Training Acc 1: 0.10
Epoch 52 - Batch (50/363) - Mini-batch Training loss: 0.3824 - Training Acc 1: 0.12
Epoch 52 - Batch (60/363) - Mini-batch Training loss: 0.3685 - Training Acc 1: 0.15
Epoch 52 - Batch (70/363) - Mini-batch Training loss: 0.3742 - Training Acc 1: 0.17
Epoch 52 - Batch (80/363) - Mini-batch Training loss: 0.3812 - Training Acc 1: 0.20
Epoch 52 - Batch (90/363) - Mini-batch Training loss: 0.3707 - Training Acc 1: 0.22
Epoch 52 - Batch (100/363) - Mini-batch Training loss: 0.3841 - Training Acc 1: 0.25
Epoch 52 - Batch (110/363) - Mini-batch Training loss: 0.3615 - Training Acc 1: 0.27
Epoch 52 - Batch (120/363) - Mini-batch Training loss: 0.3594 - Training Acc 1: 0.30
Epoch 52 - Batch (130/363) - Mini-batch Training loss: 0.3613 - Training Acc 1: 0.32
Epoch 52 - Batch (140/363) - Mini-batch Training loss: 0.3688 - Training Acc 1: 0.34
Epoch 52 - Batch (150/363) - Mini-batch Training loss: 0.3716 - Training Acc 1: 0.37
Epoch 52 - Batch (160/363) - Mini-batch Training loss: 0.3650 - Training Acc 1: 0.39
Epoch 52 - Batch (170/363) - Mini-batch Training loss: 0.3687 - Training Acc 1: 0.42
Epoch 52 - Batch (180/363) - Mini-batch Training loss: 0.3674 - Training Acc 1: 0.44
Epoch 52 - Batch (190/363) - Mini-batch Training loss: 0.3596 - Training Acc 1: 0.47
Epoch 52 - Batch (200/363) - Mini-batch Training loss: 0.3606 - Training Acc 1: 0.49
Epoch 52 - Batch (210/363) - Mini-batch Training loss: 0.3639 - Training Acc 1: 0.52
Epoch 52 - Batch (220/363) - Mini-batch Training loss: 0.3732 - Training Acc 1: 0.54
Epoch 52 - Batch (230/363) - Mini-batch Training loss: 0.3785 - Training Acc 1: 0.56
Epoch 52 - Batch (240/363) - Mini-batch Training loss: 0.3792 - Training Acc 1: 0.58
Epoch 52 - Batch (250/363) - Mini-batch Training loss: 0.3800 - Training Acc 1: 0.61
Epoch 52 - Batch (260/363) - Mini-batch Training loss: 0.3860 - Training Acc 1: 0.63
Epoch 52 - Batch (270/363) - Mini-batch Training loss: 0.3844 - Training Acc 1: 0.65
Epoch 52 - Batch (280/363) - Mini-batch Training loss: 0.3839 - Training Acc 1: 0.68
Epoch 52 - Batch (290/363) - Mini-batch Training loss: 0.3862 - Training Acc 1: 0.70
Epoch 52 - Batch (300/363) - Mini-batch Training loss: 0.3972 - Training Acc 1: 0.72
Epoch 52 - Batch (310/363) - Mini-batch Training loss: 0.3965 - Training Acc 1: 0.75
Epoch 52 - Batch (320/363) - Mini-batch Training loss: 0.4006 - Training Acc 1: 0.77
Epoch 52 - Batch (330/363) - Mini-batch Training loss: 0.4021 - Training Acc 1: 0.79
Epoch 52 - Batch (340/363) - Mini-batch Training loss: 0.4026 - Training Acc 1: 0.82
Epoch 52 - Batch (350/363) - Mini-batch Training loss: 0.3998 - Training Acc 1: 0.84
Epoch 52 - Batch (360/363) - Mini-batch Training loss: 0.4001 - Training Acc 1: 0.86
Epoch 52 - Full-batch Training loss: 0.3983 - Training Acc 1: 0.87
Validation set: Average loss: 0.6779, Accuracy: 291.0/363 (80%)

Epoch 53 - Batch (0/363) - Mini-batch Training loss: 0.8251 - Training Acc 1: 0.00
Epoch 53 - Batch (10/363) - Mini-batch Training loss: 0.2588 - Training Acc 1: 0.03
Epoch 53 - Batch (20/363) - Mini-batch Training loss: 0.3426 - Training Acc 1: 0.05
Epoch 53 - Batch (30/363) - Mini-batch Training loss: 0.3507 - Training Acc 1: 0.08
Epoch 53 - Batch (40/363) - Mini-batch Training loss: 0.2882 - Training Acc 1: 0.10
Epoch 53 - Batch (50/363) - Mini-batch Training loss: 0.2908 - Training Acc 1: 0.13
Epoch 53 - Batch (60/363) - Mini-batch Training loss: 0.2998 - Training Acc 1: 0.15
Epoch 53 - Batch (70/363) - Mini-batch Training loss: 0.2915 - Training Acc 1: 0.18
Epoch 53 - Batch (80/363) - Mini-batch Training loss: 0.3209 - Training Acc 1: 0.20
Epoch 53 - Batch (90/363) - Mini-batch Training loss: 0.3282 - Training Acc 1: 0.22
Epoch 53 - Batch (100/363) - Mini-batch Training loss: 0.3318 - Training Acc 1: 0.25
Epoch 53 - Batch (110/363) - Mini-batch Training loss: 0.3287 - Training Acc 1: 0.27
Epoch 53 - Batch (120/363) - Mini-batch Training loss: 0.3249 - Training Acc 1: 0.30
Epoch 53 - Batch (130/363) - Mini-batch Training loss: 0.3337 - Training Acc 1: 0.32
Epoch 53 - Batch (140/363) - Mini-batch Training loss: 0.3365 - Training Acc 1: 0.35
Epoch 53 - Batch (150/363) - Mini-batch Training loss: 0.3319 - Training Acc 1: 0.37
Epoch 53 - Batch (160/363) - Mini-batch Training loss: 0.3368 - Training Acc 1: 0.40
Epoch 53 - Batch (170/363) - Mini-batch Training loss: 0.3396 - Training Acc 1: 0.42
Epoch 53 - Batch (180/363) - Mini-batch Training loss: 0.3374 - Training Acc 1: 0.44
Epoch 53 - Batch (190/363) - Mini-batch Training loss: 0.3323 - Training Acc 1: 0.47
Epoch 53 - Batch (200/363) - Mini-batch Training loss: 0.3340 - Training Acc 1: 0.49
Epoch 53 - Batch (210/363) - Mini-batch Training loss: 0.3332 - Training Acc 1: 0.52
Epoch 53 - Batch (220/363) - Mini-batch Training loss: 0.3385 - Training Acc 1: 0.54
Epoch 53 - Batch (230/363) - Mini-batch Training loss: 0.3385 - Training Acc 1: 0.57
Epoch 53 - Batch (240/363) - Mini-batch Training loss: 0.3399 - Training Acc 1: 0.59
Epoch 53 - Batch (250/363) - Mini-batch Training loss: 0.3571 - Training Acc 1: 0.61
Epoch 53 - Batch (260/363) - Mini-batch Training loss: 0.3586 - Training Acc 1: 0.63
Epoch 53 - Batch (270/363) - Mini-batch Training loss: 0.3703 - Training Acc 1: 0.65
Epoch 53 - Batch (280/363) - Mini-batch Training loss: 0.3668 - Training Acc 1: 0.68
Epoch 53 - Batch (290/363) - Mini-batch Training loss: 0.3661 - Training Acc 1: 0.71
Epoch 53 - Batch (300/363) - Mini-batch Training loss: 0.3653 - Training Acc 1: 0.73
Epoch 53 - Batch (310/363) - Mini-batch Training loss: 0.3655 - Training Acc 1: 0.75
Epoch 53 - Batch (320/363) - Mini-batch Training loss: 0.3687 - Training Acc 1: 0.78
Epoch 53 - Batch (330/363) - Mini-batch Training loss: 0.3722 - Training Acc 1: 0.80
Epoch 53 - Batch (340/363) - Mini-batch Training loss: 0.3688 - Training Acc 1: 0.82
Epoch 53 - Batch (350/363) - Mini-batch Training loss: 0.3665 - Training Acc 1: 0.85
Epoch 53 - Batch (360/363) - Mini-batch Training loss: 0.3706 - Training Acc 1: 0.87
Epoch 53 - Full-batch Training loss: 0.3692 - Training Acc 1: 0.88
Validation set: Average loss: 0.7126, Accuracy: 288.0/363 (79%)

Epoch 54 - Batch (0/363) - Mini-batch Training loss: 0.8801 - Training Acc 1: 0.00
Epoch 54 - Batch (10/363) - Mini-batch Training loss: 0.5197 - Training Acc 1: 0.02
Epoch 54 - Batch (20/363) - Mini-batch Training loss: 0.5373 - Training Acc 1: 0.05
Epoch 54 - Batch (30/363) - Mini-batch Training loss: 0.4986 - Training Acc 1: 0.07
Epoch 54 - Batch (40/363) - Mini-batch Training loss: 0.4625 - Training Acc 1: 0.10
Epoch 54 - Batch (50/363) - Mini-batch Training loss: 0.4863 - Training Acc 1: 0.12
Epoch 54 - Batch (60/363) - Mini-batch Training loss: 0.4622 - Training Acc 1: 0.14
Epoch 54 - Batch (70/363) - Mini-batch Training loss: 0.4695 - Training Acc 1: 0.16
Epoch 54 - Batch (80/363) - Mini-batch Training loss: 0.4609 - Training Acc 1: 0.19
Epoch 54 - Batch (90/363) - Mini-batch Training loss: 0.4392 - Training Acc 1: 0.21
Epoch 54 - Batch (100/363) - Mini-batch Training loss: 0.4325 - Training Acc 1: 0.24
Epoch 54 - Batch (110/363) - Mini-batch Training loss: 0.4064 - Training Acc 1: 0.27
Epoch 54 - Batch (120/363) - Mini-batch Training loss: 0.3889 - Training Acc 1: 0.29
Epoch 54 - Batch (130/363) - Mini-batch Training loss: 0.3808 - Training Acc 1: 0.32
Epoch 54 - Batch (140/363) - Mini-batch Training loss: 0.3781 - Training Acc 1: 0.34
Epoch 54 - Batch (150/363) - Mini-batch Training loss: 0.3745 - Training Acc 1: 0.37
Epoch 54 - Batch (160/363) - Mini-batch Training loss: 0.3769 - Training Acc 1: 0.39
Epoch 54 - Batch (170/363) - Mini-batch Training loss: 0.3822 - Training Acc 1: 0.41
Epoch 54 - Batch (180/363) - Mini-batch Training loss: 0.3872 - Training Acc 1: 0.43
Epoch 54 - Batch (190/363) - Mini-batch Training loss: 0.3864 - Training Acc 1: 0.46
Epoch 54 - Batch (200/363) - Mini-batch Training loss: 0.3860 - Training Acc 1: 0.49
Epoch 54 - Batch (210/363) - Mini-batch Training loss: 0.3805 - Training Acc 1: 0.51
Epoch 54 - Batch (220/363) - Mini-batch Training loss: 0.3735 - Training Acc 1: 0.54
Epoch 54 - Batch (230/363) - Mini-batch Training loss: 0.3791 - Training Acc 1: 0.56
Epoch 54 - Batch (240/363) - Mini-batch Training loss: 0.3732 - Training Acc 1: 0.59
Epoch 54 - Batch (250/363) - Mini-batch Training loss: 0.3742 - Training Acc 1: 0.61
Epoch 54 - Batch (260/363) - Mini-batch Training loss: 0.3696 - Training Acc 1: 0.63
Epoch 54 - Batch (270/363) - Mini-batch Training loss: 0.3714 - Training Acc 1: 0.66
Epoch 54 - Batch (280/363) - Mini-batch Training loss: 0.3641 - Training Acc 1: 0.68
Epoch 54 - Batch (290/363) - Mini-batch Training loss: 0.3600 - Training Acc 1: 0.71
Epoch 54 - Batch (300/363) - Mini-batch Training loss: 0.3568 - Training Acc 1: 0.73
Epoch 54 - Batch (310/363) - Mini-batch Training loss: 0.3596 - Training Acc 1: 0.76
Epoch 54 - Batch (320/363) - Mini-batch Training loss: 0.3653 - Training Acc 1: 0.78
Epoch 54 - Batch (330/363) - Mini-batch Training loss: 0.3724 - Training Acc 1: 0.80
Epoch 54 - Batch (340/363) - Mini-batch Training loss: 0.3757 - Training Acc 1: 0.83
Epoch 54 - Batch (350/363) - Mini-batch Training loss: 0.3762 - Training Acc 1: 0.85
Epoch 54 - Batch (360/363) - Mini-batch Training loss: 0.3740 - Training Acc 1: 0.87
Epoch 54 - Full-batch Training loss: 0.3724 - Training Acc 1: 0.88
Validation set: Average loss: 0.7355, Accuracy: 294.0/363 (81%)

Epoch 55 - Batch (0/363) - Mini-batch Training loss: 0.7791 - Training Acc 1: 0.00
Epoch 55 - Batch (10/363) - Mini-batch Training loss: 0.2885 - Training Acc 1: 0.03
Epoch 55 - Batch (20/363) - Mini-batch Training loss: 0.3099 - Training Acc 1: 0.05
Epoch 55 - Batch (30/363) - Mini-batch Training loss: 0.3205 - Training Acc 1: 0.08
Epoch 55 - Batch (40/363) - Mini-batch Training loss: 0.3171 - Training Acc 1: 0.10
Epoch 55 - Batch (50/363) - Mini-batch Training loss: 0.2864 - Training Acc 1: 0.13
Epoch 55 - Batch (60/363) - Mini-batch Training loss: 0.2862 - Training Acc 1: 0.15
Epoch 55 - Batch (70/363) - Mini-batch Training loss: 0.2911 - Training Acc 1: 0.18
Epoch 55 - Batch (80/363) - Mini-batch Training loss: 0.3032 - Training Acc 1: 0.20
Epoch 55 - Batch (90/363) - Mini-batch Training loss: 0.3130 - Training Acc 1: 0.22
Epoch 55 - Batch (100/363) - Mini-batch Training loss: 0.3127 - Training Acc 1: 0.25
Epoch 55 - Batch (110/363) - Mini-batch Training loss: 0.3031 - Training Acc 1: 0.27
Epoch 55 - Batch (120/363) - Mini-batch Training loss: 0.3008 - Training Acc 1: 0.30
Epoch 55 - Batch (130/363) - Mini-batch Training loss: 0.2969 - Training Acc 1: 0.33
Epoch 55 - Batch (140/363) - Mini-batch Training loss: 0.2944 - Training Acc 1: 0.35
Epoch 55 - Batch (150/363) - Mini-batch Training loss: 0.3012 - Training Acc 1: 0.37
Epoch 55 - Batch (160/363) - Mini-batch Training loss: 0.3083 - Training Acc 1: 0.39
Epoch 55 - Batch (170/363) - Mini-batch Training loss: 0.3136 - Training Acc 1: 0.42
Epoch 55 - Batch (180/363) - Mini-batch Training loss: 0.3210 - Training Acc 1: 0.44
Epoch 55 - Batch (190/363) - Mini-batch Training loss: 0.3214 - Training Acc 1: 0.47
Epoch 55 - Batch (200/363) - Mini-batch Training loss: 0.3218 - Training Acc 1: 0.49
Epoch 55 - Batch (210/363) - Mini-batch Training loss: 0.3352 - Training Acc 1: 0.51
Epoch 55 - Batch (220/363) - Mini-batch Training loss: 0.3567 - Training Acc 1: 0.53
Epoch 55 - Batch (230/363) - Mini-batch Training loss: 0.3842 - Training Acc 1: 0.55
Epoch 55 - Batch (240/363) - Mini-batch Training loss: 0.3868 - Training Acc 1: 0.58
Epoch 55 - Batch (250/363) - Mini-batch Training loss: 0.4034 - Training Acc 1: 0.60
Epoch 55 - Batch (260/363) - Mini-batch Training loss: 0.4100 - Training Acc 1: 0.62
Epoch 55 - Batch (270/363) - Mini-batch Training loss: 0.4110 - Training Acc 1: 0.64
Epoch 55 - Batch (280/363) - Mini-batch Training loss: 0.4102 - Training Acc 1: 0.67
Epoch 55 - Batch (290/363) - Mini-batch Training loss: 0.4131 - Training Acc 1: 0.69
Epoch 55 - Batch (300/363) - Mini-batch Training loss: 0.4089 - Training Acc 1: 0.72
Epoch 55 - Batch (310/363) - Mini-batch Training loss: 0.4117 - Training Acc 1: 0.74
Epoch 55 - Batch (320/363) - Mini-batch Training loss: 0.4208 - Training Acc 1: 0.76
Epoch 55 - Batch (330/363) - Mini-batch Training loss: 0.4175 - Training Acc 1: 0.79
Epoch 55 - Batch (340/363) - Mini-batch Training loss: 0.4166 - Training Acc 1: 0.81
Epoch 55 - Batch (350/363) - Mini-batch Training loss: 0.4115 - Training Acc 1: 0.83
Epoch 55 - Batch (360/363) - Mini-batch Training loss: 0.4078 - Training Acc 1: 0.86
Epoch 55 - Full-batch Training loss: 0.4113 - Training Acc 1: 0.86
Validation set: Average loss: 0.6355, Accuracy: 292.0/363 (80%)

Epoch 56 - Batch (0/363) - Mini-batch Training loss: 1.6196 - Training Acc 1: 0.00
Epoch 56 - Batch (10/363) - Mini-batch Training loss: 0.4152 - Training Acc 1: 0.03
Epoch 56 - Batch (20/363) - Mini-batch Training loss: 0.4045 - Training Acc 1: 0.05
Epoch 56 - Batch (30/363) - Mini-batch Training loss: 0.3854 - Training Acc 1: 0.07
Epoch 56 - Batch (40/363) - Mini-batch Training loss: 0.3799 - Training Acc 1: 0.10
Epoch 56 - Batch (50/363) - Mini-batch Training loss: 0.3756 - Training Acc 1: 0.12
Epoch 56 - Batch (60/363) - Mini-batch Training loss: 0.3574 - Training Acc 1: 0.15
Epoch 56 - Batch (70/363) - Mini-batch Training loss: 0.3736 - Training Acc 1: 0.17
Epoch 56 - Batch (80/363) - Mini-batch Training loss: 0.3608 - Training Acc 1: 0.20
Epoch 56 - Batch (90/363) - Mini-batch Training loss: 0.3743 - Training Acc 1: 0.22
Epoch 56 - Batch (100/363) - Mini-batch Training loss: 0.3680 - Training Acc 1: 0.24
Epoch 56 - Batch (110/363) - Mini-batch Training loss: 0.3640 - Training Acc 1: 0.27
Epoch 56 - Batch (120/363) - Mini-batch Training loss: 0.3743 - Training Acc 1: 0.29
Epoch 56 - Batch (130/363) - Mini-batch Training loss: 0.3663 - Training Acc 1: 0.32
Epoch 56 - Batch (140/363) - Mini-batch Training loss: 0.3675 - Training Acc 1: 0.34
Epoch 56 - Batch (150/363) - Mini-batch Training loss: 0.3574 - Training Acc 1: 0.37
Epoch 56 - Batch (160/363) - Mini-batch Training loss: 0.3615 - Training Acc 1: 0.39
Epoch 56 - Batch (170/363) - Mini-batch Training loss: 0.3670 - Training Acc 1: 0.42
Epoch 56 - Batch (180/363) - Mini-batch Training loss: 0.3673 - Training Acc 1: 0.44
Epoch 56 - Batch (190/363) - Mini-batch Training loss: 0.3796 - Training Acc 1: 0.46
Epoch 56 - Batch (200/363) - Mini-batch Training loss: 0.3809 - Training Acc 1: 0.49
Epoch 56 - Batch (210/363) - Mini-batch Training loss: 0.3724 - Training Acc 1: 0.51
Epoch 56 - Batch (220/363) - Mini-batch Training loss: 0.3688 - Training Acc 1: 0.53
Epoch 56 - Batch (230/363) - Mini-batch Training loss: 0.3665 - Training Acc 1: 0.56
Epoch 56 - Batch (240/363) - Mini-batch Training loss: 0.3697 - Training Acc 1: 0.58
Epoch 56 - Batch (250/363) - Mini-batch Training loss: 0.3633 - Training Acc 1: 0.61
Epoch 56 - Batch (260/363) - Mini-batch Training loss: 0.3588 - Training Acc 1: 0.63
Epoch 56 - Batch (270/363) - Mini-batch Training loss: 0.3662 - Training Acc 1: 0.66
Epoch 56 - Batch (280/363) - Mini-batch Training loss: 0.3622 - Training Acc 1: 0.68
Epoch 56 - Batch (290/363) - Mini-batch Training loss: 0.3631 - Training Acc 1: 0.71
Epoch 56 - Batch (300/363) - Mini-batch Training loss: 0.3627 - Training Acc 1: 0.73
Epoch 56 - Batch (310/363) - Mini-batch Training loss: 0.3627 - Training Acc 1: 0.76
Epoch 56 - Batch (320/363) - Mini-batch Training loss: 0.3605 - Training Acc 1: 0.78
Epoch 56 - Batch (330/363) - Mini-batch Training loss: 0.3671 - Training Acc 1: 0.80
Epoch 56 - Batch (340/363) - Mini-batch Training loss: 0.3714 - Training Acc 1: 0.83
Epoch 56 - Batch (350/363) - Mini-batch Training loss: 0.3735 - Training Acc 1: 0.85
Epoch 56 - Batch (360/363) - Mini-batch Training loss: 0.3678 - Training Acc 1: 0.88
Epoch 56 - Full-batch Training loss: 0.3696 - Training Acc 1: 0.88
Validation set: Average loss: 0.6318, Accuracy: 296.0/363 (82%)

Epoch 57 - Batch (0/363) - Mini-batch Training loss: 0.0710 - Training Acc 1: 0.00
Epoch 57 - Batch (10/363) - Mini-batch Training loss: 0.1488 - Training Acc 1: 0.03
Epoch 57 - Batch (20/363) - Mini-batch Training loss: 0.1337 - Training Acc 1: 0.05
Epoch 57 - Batch (30/363) - Mini-batch Training loss: 0.2546 - Training Acc 1: 0.08
Epoch 57 - Batch (40/363) - Mini-batch Training loss: 0.2481 - Training Acc 1: 0.10
Epoch 57 - Batch (50/363) - Mini-batch Training loss: 0.2808 - Training Acc 1: 0.13
Epoch 57 - Batch (60/363) - Mini-batch Training loss: 0.2733 - Training Acc 1: 0.15
Epoch 57 - Batch (70/363) - Mini-batch Training loss: 0.2645 - Training Acc 1: 0.18
Epoch 57 - Batch (80/363) - Mini-batch Training loss: 0.2809 - Training Acc 1: 0.20
Epoch 57 - Batch (90/363) - Mini-batch Training loss: 0.2869 - Training Acc 1: 0.23
Epoch 57 - Batch (100/363) - Mini-batch Training loss: 0.2786 - Training Acc 1: 0.25
Epoch 57 - Batch (110/363) - Mini-batch Training loss: 0.3102 - Training Acc 1: 0.28
Epoch 57 - Batch (120/363) - Mini-batch Training loss: 0.3127 - Training Acc 1: 0.30
Epoch 57 - Batch (130/363) - Mini-batch Training loss: 0.3220 - Training Acc 1: 0.33
Epoch 57 - Batch (140/363) - Mini-batch Training loss: 0.3288 - Training Acc 1: 0.35
Epoch 57 - Batch (150/363) - Mini-batch Training loss: 0.3335 - Training Acc 1: 0.37
Epoch 57 - Batch (160/363) - Mini-batch Training loss: 0.3322 - Training Acc 1: 0.40
Epoch 57 - Batch (170/363) - Mini-batch Training loss: 0.3289 - Training Acc 1: 0.42
Epoch 57 - Batch (180/363) - Mini-batch Training loss: 0.3221 - Training Acc 1: 0.45
Epoch 57 - Batch (190/363) - Mini-batch Training loss: 0.3241 - Training Acc 1: 0.47
Epoch 57 - Batch (200/363) - Mini-batch Training loss: 0.3304 - Training Acc 1: 0.50
Epoch 57 - Batch (210/363) - Mini-batch Training loss: 0.3233 - Training Acc 1: 0.52
Epoch 57 - Batch (220/363) - Mini-batch Training loss: 0.3196 - Training Acc 1: 0.55
Epoch 57 - Batch (230/363) - Mini-batch Training loss: 0.3262 - Training Acc 1: 0.57
Epoch 57 - Batch (240/363) - Mini-batch Training loss: 0.3237 - Training Acc 1: 0.59
Epoch 57 - Batch (250/363) - Mini-batch Training loss: 0.3284 - Training Acc 1: 0.62
Epoch 57 - Batch (260/363) - Mini-batch Training loss: 0.3271 - Training Acc 1: 0.64
Epoch 57 - Batch (270/363) - Mini-batch Training loss: 0.3305 - Training Acc 1: 0.67
Epoch 57 - Batch (280/363) - Mini-batch Training loss: 0.3267 - Training Acc 1: 0.69
Epoch 57 - Batch (290/363) - Mini-batch Training loss: 0.3272 - Training Acc 1: 0.72
Epoch 57 - Batch (300/363) - Mini-batch Training loss: 0.3328 - Training Acc 1: 0.74
Epoch 57 - Batch (310/363) - Mini-batch Training loss: 0.3320 - Training Acc 1: 0.77
Epoch 57 - Batch (320/363) - Mini-batch Training loss: 0.3385 - Training Acc 1: 0.79
Epoch 57 - Batch (330/363) - Mini-batch Training loss: 0.3372 - Training Acc 1: 0.82
Epoch 57 - Batch (340/363) - Mini-batch Training loss: 0.3410 - Training Acc 1: 0.84
Epoch 57 - Batch (350/363) - Mini-batch Training loss: 0.3397 - Training Acc 1: 0.86
Epoch 57 - Batch (360/363) - Mini-batch Training loss: 0.3431 - Training Acc 1: 0.89
Epoch 57 - Full-batch Training loss: 0.3418 - Training Acc 1: 0.89
Validation set: Average loss: 0.7416, Accuracy: 289.0/363 (80%)

Epoch 58 - Batch (0/363) - Mini-batch Training loss: 0.0807 - Training Acc 1: 0.00
Epoch 58 - Batch (10/363) - Mini-batch Training loss: 0.1703 - Training Acc 1: 0.03
Epoch 58 - Batch (20/363) - Mini-batch Training loss: 0.2462 - Training Acc 1: 0.05
Epoch 58 - Batch (30/363) - Mini-batch Training loss: 0.2535 - Training Acc 1: 0.08
Epoch 58 - Batch (40/363) - Mini-batch Training loss: 0.2572 - Training Acc 1: 0.10
Epoch 58 - Batch (50/363) - Mini-batch Training loss: 0.2850 - Training Acc 1: 0.13
Epoch 58 - Batch (60/363) - Mini-batch Training loss: 0.2812 - Training Acc 1: 0.15
Epoch 58 - Batch (70/363) - Mini-batch Training loss: 0.2955 - Training Acc 1: 0.18
Epoch 58 - Batch (80/363) - Mini-batch Training loss: 0.2946 - Training Acc 1: 0.20
Epoch 58 - Batch (90/363) - Mini-batch Training loss: 0.2844 - Training Acc 1: 0.23
Epoch 58 - Batch (100/363) - Mini-batch Training loss: 0.2966 - Training Acc 1: 0.25
Epoch 58 - Batch (110/363) - Mini-batch Training loss: 0.3236 - Training Acc 1: 0.27
Epoch 58 - Batch (120/363) - Mini-batch Training loss: 0.3387 - Training Acc 1: 0.30
Epoch 58 - Batch (130/363) - Mini-batch Training loss: 0.3466 - Training Acc 1: 0.32
Epoch 58 - Batch (140/363) - Mini-batch Training loss: 0.3551 - Training Acc 1: 0.34
Epoch 58 - Batch (150/363) - Mini-batch Training loss: 0.3490 - Training Acc 1: 0.37
Epoch 58 - Batch (160/363) - Mini-batch Training loss: 0.3552 - Training Acc 1: 0.39
Epoch 58 - Batch (170/363) - Mini-batch Training loss: 0.3495 - Training Acc 1: 0.42
Epoch 58 - Batch (180/363) - Mini-batch Training loss: 0.3577 - Training Acc 1: 0.44
Epoch 58 - Batch (190/363) - Mini-batch Training loss: 0.3655 - Training Acc 1: 0.47
Epoch 58 - Batch (200/363) - Mini-batch Training loss: 0.3667 - Training Acc 1: 0.49
Epoch 58 - Batch (210/363) - Mini-batch Training loss: 0.3622 - Training Acc 1: 0.51
Epoch 58 - Batch (220/363) - Mini-batch Training loss: 0.3576 - Training Acc 1: 0.54
Epoch 58 - Batch (230/363) - Mini-batch Training loss: 0.3509 - Training Acc 1: 0.57
Epoch 58 - Batch (240/363) - Mini-batch Training loss: 0.3550 - Training Acc 1: 0.59
Epoch 58 - Batch (250/363) - Mini-batch Training loss: 0.3499 - Training Acc 1: 0.61
Epoch 58 - Batch (260/363) - Mini-batch Training loss: 0.3455 - Training Acc 1: 0.64
Epoch 58 - Batch (270/363) - Mini-batch Training loss: 0.3471 - Training Acc 1: 0.66
Epoch 58 - Batch (280/363) - Mini-batch Training loss: 0.3423 - Training Acc 1: 0.69
Epoch 58 - Batch (290/363) - Mini-batch Training loss: 0.3351 - Training Acc 1: 0.72
Epoch 58 - Batch (300/363) - Mini-batch Training loss: 0.3379 - Training Acc 1: 0.74
Epoch 58 - Batch (310/363) - Mini-batch Training loss: 0.3329 - Training Acc 1: 0.77
Epoch 58 - Batch (320/363) - Mini-batch Training loss: 0.3304 - Training Acc 1: 0.79
Epoch 58 - Batch (330/363) - Mini-batch Training loss: 0.3312 - Training Acc 1: 0.82
Epoch 58 - Batch (340/363) - Mini-batch Training loss: 0.3364 - Training Acc 1: 0.84
Epoch 58 - Batch (350/363) - Mini-batch Training loss: 0.3400 - Training Acc 1: 0.86
Epoch 58 - Batch (360/363) - Mini-batch Training loss: 0.3444 - Training Acc 1: 0.88
Epoch 58 - Full-batch Training loss: 0.3436 - Training Acc 1: 0.89
Validation set: Average loss: 0.6789, Accuracy: 293.0/363 (81%)

Epoch 59 - Batch (0/363) - Mini-batch Training loss: 0.1404 - Training Acc 1: 0.00
Epoch 59 - Batch (10/363) - Mini-batch Training loss: 0.2481 - Training Acc 1: 0.03
Epoch 59 - Batch (20/363) - Mini-batch Training loss: 0.2918 - Training Acc 1: 0.05
Epoch 59 - Batch (30/363) - Mini-batch Training loss: 0.2736 - Training Acc 1: 0.08
Epoch 59 - Batch (40/363) - Mini-batch Training loss: 0.3114 - Training Acc 1: 0.10
Epoch 59 - Batch (50/363) - Mini-batch Training loss: 0.3249 - Training Acc 1: 0.13
Epoch 59 - Batch (60/363) - Mini-batch Training loss: 0.3084 - Training Acc 1: 0.15
Epoch 59 - Batch (70/363) - Mini-batch Training loss: 0.3037 - Training Acc 1: 0.18
Epoch 59 - Batch (80/363) - Mini-batch Training loss: 0.3220 - Training Acc 1: 0.20
Epoch 59 - Batch (90/363) - Mini-batch Training loss: 0.3478 - Training Acc 1: 0.22
Epoch 59 - Batch (100/363) - Mini-batch Training loss: 0.3434 - Training Acc 1: 0.25
Epoch 59 - Batch (110/363) - Mini-batch Training loss: 0.3381 - Training Acc 1: 0.27
Epoch 59 - Batch (120/363) - Mini-batch Training loss: 0.3440 - Training Acc 1: 0.30
Epoch 59 - Batch (130/363) - Mini-batch Training loss: 0.3376 - Training Acc 1: 0.32
Epoch 59 - Batch (140/363) - Mini-batch Training loss: 0.3320 - Training Acc 1: 0.35
Epoch 59 - Batch (150/363) - Mini-batch Training loss: 0.3264 - Training Acc 1: 0.37
Epoch 59 - Batch (160/363) - Mini-batch Training loss: 0.3307 - Training Acc 1: 0.40
Epoch 59 - Batch (170/363) - Mini-batch Training loss: 0.3300 - Training Acc 1: 0.42
Epoch 59 - Batch (180/363) - Mini-batch Training loss: 0.3363 - Training Acc 1: 0.44
Epoch 59 - Batch (190/363) - Mini-batch Training loss: 0.3379 - Training Acc 1: 0.47
Epoch 59 - Batch (200/363) - Mini-batch Training loss: 0.3302 - Training Acc 1: 0.49
Epoch 59 - Batch (210/363) - Mini-batch Training loss: 0.3322 - Training Acc 1: 0.51
Epoch 59 - Batch (220/363) - Mini-batch Training loss: 0.3239 - Training Acc 1: 0.54
Epoch 59 - Batch (230/363) - Mini-batch Training loss: 0.3280 - Training Acc 1: 0.57
Epoch 59 - Batch (240/363) - Mini-batch Training loss: 0.3405 - Training Acc 1: 0.59
Epoch 59 - Batch (250/363) - Mini-batch Training loss: 0.3394 - Training Acc 1: 0.61
Epoch 59 - Batch (260/363) - Mini-batch Training loss: 0.3419 - Training Acc 1: 0.64
Epoch 59 - Batch (270/363) - Mini-batch Training loss: 0.3406 - Training Acc 1: 0.66
Epoch 59 - Batch (280/363) - Mini-batch Training loss: 0.3452 - Training Acc 1: 0.68
Epoch 59 - Batch (290/363) - Mini-batch Training loss: 0.3424 - Training Acc 1: 0.71
Epoch 59 - Batch (300/363) - Mini-batch Training loss: 0.3517 - Training Acc 1: 0.73
Epoch 59 - Batch (310/363) - Mini-batch Training loss: 0.3556 - Training Acc 1: 0.76
Epoch 59 - Batch (320/363) - Mini-batch Training loss: 0.3573 - Training Acc 1: 0.78
Epoch 59 - Batch (330/363) - Mini-batch Training loss: 0.3521 - Training Acc 1: 0.80
Epoch 59 - Batch (340/363) - Mini-batch Training loss: 0.3519 - Training Acc 1: 0.83
Epoch 59 - Batch (350/363) - Mini-batch Training loss: 0.3494 - Training Acc 1: 0.85
Epoch 59 - Batch (360/363) - Mini-batch Training loss: 0.3471 - Training Acc 1: 0.88
Epoch 59 - Full-batch Training loss: 0.3470 - Training Acc 1: 0.88
Validation set: Average loss: 0.6474, Accuracy: 303.0/363 (83%)

0.8347107438016529
Epoch 60 - Batch (0/363) - Mini-batch Training loss: 0.4785 - Training Acc 1: 0.00
Epoch 60 - Batch (10/363) - Mini-batch Training loss: 0.2686 - Training Acc 1: 0.03
Epoch 60 - Batch (20/363) - Mini-batch Training loss: 0.3080 - Training Acc 1: 0.05
Epoch 60 - Batch (30/363) - Mini-batch Training loss: 0.3540 - Training Acc 1: 0.07
Epoch 60 - Batch (40/363) - Mini-batch Training loss: 0.3248 - Training Acc 1: 0.10
Epoch 60 - Batch (50/363) - Mini-batch Training loss: 0.3731 - Training Acc 1: 0.12
Epoch 60 - Batch (60/363) - Mini-batch Training loss: 0.3756 - Training Acc 1: 0.15
Epoch 60 - Batch (70/363) - Mini-batch Training loss: 0.4016 - Training Acc 1: 0.17
Epoch 60 - Batch (80/363) - Mini-batch Training loss: 0.4083 - Training Acc 1: 0.19
Epoch 60 - Batch (90/363) - Mini-batch Training loss: 0.4030 - Training Acc 1: 0.21
Epoch 60 - Batch (100/363) - Mini-batch Training loss: 0.3888 - Training Acc 1: 0.24
Epoch 60 - Batch (110/363) - Mini-batch Training loss: 0.4244 - Training Acc 1: 0.26
Epoch 60 - Batch (120/363) - Mini-batch Training loss: 0.4115 - Training Acc 1: 0.28
Epoch 60 - Batch (130/363) - Mini-batch Training loss: 0.4122 - Training Acc 1: 0.31
Epoch 60 - Batch (140/363) - Mini-batch Training loss: 0.4103 - Training Acc 1: 0.33
Epoch 60 - Batch (150/363) - Mini-batch Training loss: 0.3990 - Training Acc 1: 0.36
Epoch 60 - Batch (160/363) - Mini-batch Training loss: 0.3829 - Training Acc 1: 0.38
Epoch 60 - Batch (170/363) - Mini-batch Training loss: 0.3801 - Training Acc 1: 0.41
Epoch 60 - Batch (180/363) - Mini-batch Training loss: 0.3993 - Training Acc 1: 0.43
Epoch 60 - Batch (190/363) - Mini-batch Training loss: 0.3947 - Training Acc 1: 0.45
Epoch 60 - Batch (200/363) - Mini-batch Training loss: 0.3953 - Training Acc 1: 0.48
Epoch 60 - Batch (210/363) - Mini-batch Training loss: 0.3937 - Training Acc 1: 0.50
Epoch 60 - Batch (220/363) - Mini-batch Training loss: 0.3965 - Training Acc 1: 0.53
Epoch 60 - Batch (230/363) - Mini-batch Training loss: 0.3930 - Training Acc 1: 0.55
Epoch 60 - Batch (240/363) - Mini-batch Training loss: 0.3887 - Training Acc 1: 0.57
Epoch 60 - Batch (250/363) - Mini-batch Training loss: 0.3826 - Training Acc 1: 0.60
Epoch 60 - Batch (260/363) - Mini-batch Training loss: 0.3785 - Training Acc 1: 0.62
Epoch 60 - Batch (270/363) - Mini-batch Training loss: 0.3778 - Training Acc 1: 0.65
Epoch 60 - Batch (280/363) - Mini-batch Training loss: 0.3783 - Training Acc 1: 0.67
Epoch 60 - Batch (290/363) - Mini-batch Training loss: 0.3727 - Training Acc 1: 0.70
Epoch 60 - Batch (300/363) - Mini-batch Training loss: 0.3701 - Training Acc 1: 0.72
Epoch 60 - Batch (310/363) - Mini-batch Training loss: 0.3701 - Training Acc 1: 0.75
Epoch 60 - Batch (320/363) - Mini-batch Training loss: 0.3695 - Training Acc 1: 0.77
Epoch 60 - Batch (330/363) - Mini-batch Training loss: 0.3670 - Training Acc 1: 0.80
Epoch 60 - Batch (340/363) - Mini-batch Training loss: 0.3621 - Training Acc 1: 0.82
Epoch 60 - Batch (350/363) - Mini-batch Training loss: 0.3613 - Training Acc 1: 0.85
Epoch 60 - Batch (360/363) - Mini-batch Training loss: 0.3595 - Training Acc 1: 0.87
Epoch 60 - Full-batch Training loss: 0.3582 - Training Acc 1: 0.88
Validation set: Average loss: 0.7527, Accuracy: 282.0/363 (78%)

Epoch 61 - Batch (0/363) - Mini-batch Training loss: 0.0013 - Training Acc 1: 0.00
Epoch 61 - Batch (10/363) - Mini-batch Training loss: 0.3451 - Training Acc 1: 0.03
Epoch 61 - Batch (20/363) - Mini-batch Training loss: 0.4035 - Training Acc 1: 0.05
Epoch 61 - Batch (30/363) - Mini-batch Training loss: 0.3729 - Training Acc 1: 0.07
Epoch 61 - Batch (40/363) - Mini-batch Training loss: 0.4474 - Training Acc 1: 0.09
Epoch 61 - Batch (50/363) - Mini-batch Training loss: 0.4116 - Training Acc 1: 0.12
Epoch 61 - Batch (60/363) - Mini-batch Training loss: 0.4052 - Training Acc 1: 0.14
Epoch 61 - Batch (70/363) - Mini-batch Training loss: 0.4231 - Training Acc 1: 0.16
Epoch 61 - Batch (80/363) - Mini-batch Training loss: 0.4121 - Training Acc 1: 0.19
Epoch 61 - Batch (90/363) - Mini-batch Training loss: 0.4110 - Training Acc 1: 0.21
Epoch 61 - Batch (100/363) - Mini-batch Training loss: 0.3982 - Training Acc 1: 0.24
Epoch 61 - Batch (110/363) - Mini-batch Training loss: 0.3945 - Training Acc 1: 0.26
Epoch 61 - Batch (120/363) - Mini-batch Training loss: 0.3844 - Training Acc 1: 0.29
Epoch 61 - Batch (130/363) - Mini-batch Training loss: 0.4018 - Training Acc 1: 0.31
Epoch 61 - Batch (140/363) - Mini-batch Training loss: 0.4017 - Training Acc 1: 0.33
Epoch 61 - Batch (150/363) - Mini-batch Training loss: 0.3837 - Training Acc 1: 0.36
Epoch 61 - Batch (160/363) - Mini-batch Training loss: 0.3860 - Training Acc 1: 0.38
Epoch 61 - Batch (170/363) - Mini-batch Training loss: 0.3836 - Training Acc 1: 0.41
Epoch 61 - Batch (180/363) - Mini-batch Training loss: 0.3907 - Training Acc 1: 0.43
Epoch 61 - Batch (190/363) - Mini-batch Training loss: 0.3843 - Training Acc 1: 0.46
Epoch 61 - Batch (200/363) - Mini-batch Training loss: 0.3758 - Training Acc 1: 0.48
Epoch 61 - Batch (210/363) - Mini-batch Training loss: 0.3820 - Training Acc 1: 0.50
Epoch 61 - Batch (220/363) - Mini-batch Training loss: 0.3774 - Training Acc 1: 0.53
Epoch 61 - Batch (230/363) - Mini-batch Training loss: 0.3863 - Training Acc 1: 0.55
Epoch 61 - Batch (240/363) - Mini-batch Training loss: 0.3817 - Training Acc 1: 0.58
Epoch 61 - Batch (250/363) - Mini-batch Training loss: 0.3822 - Training Acc 1: 0.60
Epoch 61 - Batch (260/363) - Mini-batch Training loss: 0.3779 - Training Acc 1: 0.62
Epoch 61 - Batch (270/363) - Mini-batch Training loss: 0.3872 - Training Acc 1: 0.65
Epoch 61 - Batch (280/363) - Mini-batch Training loss: 0.3858 - Training Acc 1: 0.67
Epoch 61 - Batch (290/363) - Mini-batch Training loss: 0.3850 - Training Acc 1: 0.69
Epoch 61 - Batch (300/363) - Mini-batch Training loss: 0.3848 - Training Acc 1: 0.72
Epoch 61 - Batch (310/363) - Mini-batch Training loss: 0.3832 - Training Acc 1: 0.74
Epoch 61 - Batch (320/363) - Mini-batch Training loss: 0.3893 - Training Acc 1: 0.77
Epoch 61 - Batch (330/363) - Mini-batch Training loss: 0.3910 - Training Acc 1: 0.79
Epoch 61 - Batch (340/363) - Mini-batch Training loss: 0.3903 - Training Acc 1: 0.81
Epoch 61 - Batch (350/363) - Mini-batch Training loss: 0.3876 - Training Acc 1: 0.84
Epoch 61 - Batch (360/363) - Mini-batch Training loss: 0.3841 - Training Acc 1: 0.86
Epoch 61 - Full-batch Training loss: 0.3844 - Training Acc 1: 0.86
Validation set: Average loss: 0.5964, Accuracy: 303.0/363 (83%)

Epoch 62 - Batch (0/363) - Mini-batch Training loss: 0.0799 - Training Acc 1: 0.00
Epoch 62 - Batch (10/363) - Mini-batch Training loss: 0.2637 - Training Acc 1: 0.03
Epoch 62 - Batch (20/363) - Mini-batch Training loss: 0.3100 - Training Acc 1: 0.05
Epoch 62 - Batch (30/363) - Mini-batch Training loss: 0.2556 - Training Acc 1: 0.08
Epoch 62 - Batch (40/363) - Mini-batch Training loss: 0.2616 - Training Acc 1: 0.10
Epoch 62 - Batch (50/363) - Mini-batch Training loss: 0.2981 - Training Acc 1: 0.13
Epoch 62 - Batch (60/363) - Mini-batch Training loss: 0.3071 - Training Acc 1: 0.15
Epoch 62 - Batch (70/363) - Mini-batch Training loss: 0.3212 - Training Acc 1: 0.17
Epoch 62 - Batch (80/363) - Mini-batch Training loss: 0.3104 - Training Acc 1: 0.20
Epoch 62 - Batch (90/363) - Mini-batch Training loss: 0.3073 - Training Acc 1: 0.22
Epoch 62 - Batch (100/363) - Mini-batch Training loss: 0.3017 - Training Acc 1: 0.25
Epoch 62 - Batch (110/363) - Mini-batch Training loss: 0.3010 - Training Acc 1: 0.27
Epoch 62 - Batch (120/363) - Mini-batch Training loss: 0.3013 - Training Acc 1: 0.30
Epoch 62 - Batch (130/363) - Mini-batch Training loss: 0.3046 - Training Acc 1: 0.32
Epoch 62 - Batch (140/363) - Mini-batch Training loss: 0.3037 - Training Acc 1: 0.35
Epoch 62 - Batch (150/363) - Mini-batch Training loss: 0.2979 - Training Acc 1: 0.38
Epoch 62 - Batch (160/363) - Mini-batch Training loss: 0.2946 - Training Acc 1: 0.40
Epoch 62 - Batch (170/363) - Mini-batch Training loss: 0.2880 - Training Acc 1: 0.43
Epoch 62 - Batch (180/363) - Mini-batch Training loss: 0.2948 - Training Acc 1: 0.45
Epoch 62 - Batch (190/363) - Mini-batch Training loss: 0.2927 - Training Acc 1: 0.48
Epoch 62 - Batch (200/363) - Mini-batch Training loss: 0.2899 - Training Acc 1: 0.50
Epoch 62 - Batch (210/363) - Mini-batch Training loss: 0.2989 - Training Acc 1: 0.52
Epoch 62 - Batch (220/363) - Mini-batch Training loss: 0.3063 - Training Acc 1: 0.55
Epoch 62 - Batch (230/363) - Mini-batch Training loss: 0.3084 - Training Acc 1: 0.57
Epoch 62 - Batch (240/363) - Mini-batch Training loss: 0.3054 - Training Acc 1: 0.60
Epoch 62 - Batch (250/363) - Mini-batch Training loss: 0.3100 - Training Acc 1: 0.62
Epoch 62 - Batch (260/363) - Mini-batch Training loss: 0.3193 - Training Acc 1: 0.64
Epoch 62 - Batch (270/363) - Mini-batch Training loss: 0.3202 - Training Acc 1: 0.67
Epoch 62 - Batch (280/363) - Mini-batch Training loss: 0.3166 - Training Acc 1: 0.69
Epoch 62 - Batch (290/363) - Mini-batch Training loss: 0.3166 - Training Acc 1: 0.72
Epoch 62 - Batch (300/363) - Mini-batch Training loss: 0.3260 - Training Acc 1: 0.74
Epoch 62 - Batch (310/363) - Mini-batch Training loss: 0.3268 - Training Acc 1: 0.76
Epoch 62 - Batch (320/363) - Mini-batch Training loss: 0.3265 - Training Acc 1: 0.79
Epoch 62 - Batch (330/363) - Mini-batch Training loss: 0.3272 - Training Acc 1: 0.82
Epoch 62 - Batch (340/363) - Mini-batch Training loss: 0.3255 - Training Acc 1: 0.84
Epoch 62 - Batch (350/363) - Mini-batch Training loss: 0.3276 - Training Acc 1: 0.86
Epoch 62 - Batch (360/363) - Mini-batch Training loss: 0.3261 - Training Acc 1: 0.89
Epoch 62 - Full-batch Training loss: 0.3290 - Training Acc 1: 0.89
Validation set: Average loss: 0.7041, Accuracy: 284.0/363 (78%)

Epoch 63 - Batch (0/363) - Mini-batch Training loss: 0.0090 - Training Acc 1: 0.00
Epoch 63 - Batch (10/363) - Mini-batch Training loss: 0.2855 - Training Acc 1: 0.03
Epoch 63 - Batch (20/363) - Mini-batch Training loss: 0.2936 - Training Acc 1: 0.05
Epoch 63 - Batch (30/363) - Mini-batch Training loss: 0.2388 - Training Acc 1: 0.08
Epoch 63 - Batch (40/363) - Mini-batch Training loss: 0.3299 - Training Acc 1: 0.10
Epoch 63 - Batch (50/363) - Mini-batch Training loss: 0.3391 - Training Acc 1: 0.13
Epoch 63 - Batch (60/363) - Mini-batch Training loss: 0.3322 - Training Acc 1: 0.15
Epoch 63 - Batch (70/363) - Mini-batch Training loss: 0.3237 - Training Acc 1: 0.18
Epoch 63 - Batch (80/363) - Mini-batch Training loss: 0.3401 - Training Acc 1: 0.20
Epoch 63 - Batch (90/363) - Mini-batch Training loss: 0.3218 - Training Acc 1: 0.22
Epoch 63 - Batch (100/363) - Mini-batch Training loss: 0.3175 - Training Acc 1: 0.25
Epoch 63 - Batch (110/363) - Mini-batch Training loss: 0.3176 - Training Acc 1: 0.27
Epoch 63 - Batch (120/363) - Mini-batch Training loss: 0.3027 - Training Acc 1: 0.30
Epoch 63 - Batch (130/363) - Mini-batch Training loss: 0.2974 - Training Acc 1: 0.33
Epoch 63 - Batch (140/363) - Mini-batch Training loss: 0.3075 - Training Acc 1: 0.35
Epoch 63 - Batch (150/363) - Mini-batch Training loss: 0.3092 - Training Acc 1: 0.37
Epoch 63 - Batch (160/363) - Mini-batch Training loss: 0.3018 - Training Acc 1: 0.40
Epoch 63 - Batch (170/363) - Mini-batch Training loss: 0.3008 - Training Acc 1: 0.42
Epoch 63 - Batch (180/363) - Mini-batch Training loss: 0.3138 - Training Acc 1: 0.45
Epoch 63 - Batch (190/363) - Mini-batch Training loss: 0.3142 - Training Acc 1: 0.47
Epoch 63 - Batch (200/363) - Mini-batch Training loss: 0.3065 - Training Acc 1: 0.50
Epoch 63 - Batch (210/363) - Mini-batch Training loss: 0.3122 - Training Acc 1: 0.52
Epoch 63 - Batch (220/363) - Mini-batch Training loss: 0.3156 - Training Acc 1: 0.54
Epoch 63 - Batch (230/363) - Mini-batch Training loss: 0.3130 - Training Acc 1: 0.57
Epoch 63 - Batch (240/363) - Mini-batch Training loss: 0.3096 - Training Acc 1: 0.59
Epoch 63 - Batch (250/363) - Mini-batch Training loss: 0.3119 - Training Acc 1: 0.62
Epoch 63 - Batch (260/363) - Mini-batch Training loss: 0.3071 - Training Acc 1: 0.64
Epoch 63 - Batch (270/363) - Mini-batch Training loss: 0.3155 - Training Acc 1: 0.67
Epoch 63 - Batch (280/363) - Mini-batch Training loss: 0.3149 - Training Acc 1: 0.69
Epoch 63 - Batch (290/363) - Mini-batch Training loss: 0.3197 - Training Acc 1: 0.71
Epoch 63 - Batch (300/363) - Mini-batch Training loss: 0.3257 - Training Acc 1: 0.74
Epoch 63 - Batch (310/363) - Mini-batch Training loss: 0.3262 - Training Acc 1: 0.76
Epoch 63 - Batch (320/363) - Mini-batch Training loss: 0.3299 - Training Acc 1: 0.79
Epoch 63 - Batch (330/363) - Mini-batch Training loss: 0.3280 - Training Acc 1: 0.81
Epoch 63 - Batch (340/363) - Mini-batch Training loss: 0.3267 - Training Acc 1: 0.84
Epoch 63 - Batch (350/363) - Mini-batch Training loss: 0.3207 - Training Acc 1: 0.86
Epoch 63 - Batch (360/363) - Mini-batch Training loss: 0.3210 - Training Acc 1: 0.89
Epoch 63 - Full-batch Training loss: 0.3220 - Training Acc 1: 0.89
Validation set: Average loss: 0.8060, Accuracy: 282.0/363 (78%)

Epoch 64 - Batch (0/363) - Mini-batch Training loss: 0.0451 - Training Acc 1: 0.00
Epoch 64 - Batch (10/363) - Mini-batch Training loss: 0.2761 - Training Acc 1: 0.03
Epoch 64 - Batch (20/363) - Mini-batch Training loss: 0.2069 - Training Acc 1: 0.06
Epoch 64 - Batch (30/363) - Mini-batch Training loss: 0.2170 - Training Acc 1: 0.08
Epoch 64 - Batch (40/363) - Mini-batch Training loss: 0.2375 - Training Acc 1: 0.10
Epoch 64 - Batch (50/363) - Mini-batch Training loss: 0.2288 - Training Acc 1: 0.13
Epoch 64 - Batch (60/363) - Mini-batch Training loss: 0.2526 - Training Acc 1: 0.15
Epoch 64 - Batch (70/363) - Mini-batch Training loss: 0.2453 - Training Acc 1: 0.18
Epoch 64 - Batch (80/363) - Mini-batch Training loss: 0.2631 - Training Acc 1: 0.20
Epoch 64 - Batch (90/363) - Mini-batch Training loss: 0.2899 - Training Acc 1: 0.23
Epoch 64 - Batch (100/363) - Mini-batch Training loss: 0.2870 - Training Acc 1: 0.25
Epoch 64 - Batch (110/363) - Mini-batch Training loss: 0.2831 - Training Acc 1: 0.28
Epoch 64 - Batch (120/363) - Mini-batch Training loss: 0.2725 - Training Acc 1: 0.30
Epoch 64 - Batch (130/363) - Mini-batch Training loss: 0.2688 - Training Acc 1: 0.33
Epoch 64 - Batch (140/363) - Mini-batch Training loss: 0.2730 - Training Acc 1: 0.35
Epoch 64 - Batch (150/363) - Mini-batch Training loss: 0.2741 - Training Acc 1: 0.38
Epoch 64 - Batch (160/363) - Mini-batch Training loss: 0.2705 - Training Acc 1: 0.41
Epoch 64 - Batch (170/363) - Mini-batch Training loss: 0.2735 - Training Acc 1: 0.43
Epoch 64 - Batch (180/363) - Mini-batch Training loss: 0.2678 - Training Acc 1: 0.46
Epoch 64 - Batch (190/363) - Mini-batch Training loss: 0.2698 - Training Acc 1: 0.48
Epoch 64 - Batch (200/363) - Mini-batch Training loss: 0.2709 - Training Acc 1: 0.51
Epoch 64 - Batch (210/363) - Mini-batch Training loss: 0.2654 - Training Acc 1: 0.53
Epoch 64 - Batch (220/363) - Mini-batch Training loss: 0.2730 - Training Acc 1: 0.56
Epoch 64 - Batch (230/363) - Mini-batch Training loss: 0.2786 - Training Acc 1: 0.58
Epoch 64 - Batch (240/363) - Mini-batch Training loss: 0.2823 - Training Acc 1: 0.60
Epoch 64 - Batch (250/363) - Mini-batch Training loss: 0.2925 - Training Acc 1: 0.63
Epoch 64 - Batch (260/363) - Mini-batch Training loss: 0.2940 - Training Acc 1: 0.65
Epoch 64 - Batch (270/363) - Mini-batch Training loss: 0.2875 - Training Acc 1: 0.68
Epoch 64 - Batch (280/363) - Mini-batch Training loss: 0.2900 - Training Acc 1: 0.70
Epoch 64 - Batch (290/363) - Mini-batch Training loss: 0.2918 - Training Acc 1: 0.73
Epoch 64 - Batch (300/363) - Mini-batch Training loss: 0.2992 - Training Acc 1: 0.75
Epoch 64 - Batch (310/363) - Mini-batch Training loss: 0.2996 - Training Acc 1: 0.78
Epoch 64 - Batch (320/363) - Mini-batch Training loss: 0.3041 - Training Acc 1: 0.80
Epoch 64 - Batch (330/363) - Mini-batch Training loss: 0.3006 - Training Acc 1: 0.82
Epoch 64 - Batch (340/363) - Mini-batch Training loss: 0.3066 - Training Acc 1: 0.85
Epoch 64 - Batch (350/363) - Mini-batch Training loss: 0.3067 - Training Acc 1: 0.87
Epoch 64 - Batch (360/363) - Mini-batch Training loss: 0.3068 - Training Acc 1: 0.90
Epoch 64 - Full-batch Training loss: 0.3061 - Training Acc 1: 0.90
Validation set: Average loss: 0.7166, Accuracy: 291.0/363 (80%)

Epoch 65 - Batch (0/363) - Mini-batch Training loss: 0.1321 - Training Acc 1: 0.00
Epoch 65 - Batch (10/363) - Mini-batch Training loss: 0.1757 - Training Acc 1: 0.03
Epoch 65 - Batch (20/363) - Mini-batch Training loss: 0.1421 - Training Acc 1: 0.06
Epoch 65 - Batch (30/363) - Mini-batch Training loss: 0.2040 - Training Acc 1: 0.08
Epoch 65 - Batch (40/363) - Mini-batch Training loss: 0.2214 - Training Acc 1: 0.11
Epoch 65 - Batch (50/363) - Mini-batch Training loss: 0.1954 - Training Acc 1: 0.13
Epoch 65 - Batch (60/363) - Mini-batch Training loss: 0.2015 - Training Acc 1: 0.16
Epoch 65 - Batch (70/363) - Mini-batch Training loss: 0.2116 - Training Acc 1: 0.18
Epoch 65 - Batch (80/363) - Mini-batch Training loss: 0.2154 - Training Acc 1: 0.21
Epoch 65 - Batch (90/363) - Mini-batch Training loss: 0.2561 - Training Acc 1: 0.23
Epoch 65 - Batch (100/363) - Mini-batch Training loss: 0.2539 - Training Acc 1: 0.26
Epoch 65 - Batch (110/363) - Mini-batch Training loss: 0.2527 - Training Acc 1: 0.29
Epoch 65 - Batch (120/363) - Mini-batch Training loss: 0.2667 - Training Acc 1: 0.31
Epoch 65 - Batch (130/363) - Mini-batch Training loss: 0.2669 - Training Acc 1: 0.33
Epoch 65 - Batch (140/363) - Mini-batch Training loss: 0.2583 - Training Acc 1: 0.36
Epoch 65 - Batch (150/363) - Mini-batch Training loss: 0.2663 - Training Acc 1: 0.38
Epoch 65 - Batch (160/363) - Mini-batch Training loss: 0.2679 - Training Acc 1: 0.41
Epoch 65 - Batch (170/363) - Mini-batch Training loss: 0.2596 - Training Acc 1: 0.44
Epoch 65 - Batch (180/363) - Mini-batch Training loss: 0.2637 - Training Acc 1: 0.46
Epoch 65 - Batch (190/363) - Mini-batch Training loss: 0.2573 - Training Acc 1: 0.49
Epoch 65 - Batch (200/363) - Mini-batch Training loss: 0.2595 - Training Acc 1: 0.51
Epoch 65 - Batch (210/363) - Mini-batch Training loss: 0.2534 - Training Acc 1: 0.54
Epoch 65 - Batch (220/363) - Mini-batch Training loss: 0.2527 - Training Acc 1: 0.57
Epoch 65 - Batch (230/363) - Mini-batch Training loss: 0.2598 - Training Acc 1: 0.59
Epoch 65 - Batch (240/363) - Mini-batch Training loss: 0.2608 - Training Acc 1: 0.62
Epoch 65 - Batch (250/363) - Mini-batch Training loss: 0.2589 - Training Acc 1: 0.64
Epoch 65 - Batch (260/363) - Mini-batch Training loss: 0.2629 - Training Acc 1: 0.67
Epoch 65 - Batch (270/363) - Mini-batch Training loss: 0.2588 - Training Acc 1: 0.69
Epoch 65 - Batch (280/363) - Mini-batch Training loss: 0.2594 - Training Acc 1: 0.72
Epoch 65 - Batch (290/363) - Mini-batch Training loss: 0.2666 - Training Acc 1: 0.74
Epoch 65 - Batch (300/363) - Mini-batch Training loss: 0.2692 - Training Acc 1: 0.77
Epoch 65 - Batch (310/363) - Mini-batch Training loss: 0.2757 - Training Acc 1: 0.79
Epoch 65 - Batch (320/363) - Mini-batch Training loss: 0.2816 - Training Acc 1: 0.81
Epoch 65 - Batch (330/363) - Mini-batch Training loss: 0.2892 - Training Acc 1: 0.84
Epoch 65 - Batch (340/363) - Mini-batch Training loss: 0.2952 - Training Acc 1: 0.86
Epoch 65 - Batch (350/363) - Mini-batch Training loss: 0.2975 - Training Acc 1: 0.88
Epoch 65 - Batch (360/363) - Mini-batch Training loss: 0.2956 - Training Acc 1: 0.91
Epoch 65 - Full-batch Training loss: 0.2942 - Training Acc 1: 0.91
Validation set: Average loss: 0.6872, Accuracy: 291.0/363 (80%)

Epoch 66 - Batch (0/363) - Mini-batch Training loss: 0.0214 - Training Acc 1: 0.00
Epoch 66 - Batch (10/363) - Mini-batch Training loss: 0.3094 - Training Acc 1: 0.03
Epoch 66 - Batch (20/363) - Mini-batch Training loss: 0.2635 - Training Acc 1: 0.05
Epoch 66 - Batch (30/363) - Mini-batch Training loss: 0.2893 - Training Acc 1: 0.08
Epoch 66 - Batch (40/363) - Mini-batch Training loss: 0.2383 - Training Acc 1: 0.10
Epoch 66 - Batch (50/363) - Mini-batch Training loss: 0.2592 - Training Acc 1: 0.13
Epoch 66 - Batch (60/363) - Mini-batch Training loss: 0.2721 - Training Acc 1: 0.15
Epoch 66 - Batch (70/363) - Mini-batch Training loss: 0.2848 - Training Acc 1: 0.18
Epoch 66 - Batch (80/363) - Mini-batch Training loss: 0.2806 - Training Acc 1: 0.20
Epoch 66 - Batch (90/363) - Mini-batch Training loss: 0.2787 - Training Acc 1: 0.23
Epoch 66 - Batch (100/363) - Mini-batch Training loss: 0.2797 - Training Acc 1: 0.25
Epoch 66 - Batch (110/363) - Mini-batch Training loss: 0.2921 - Training Acc 1: 0.28
Epoch 66 - Batch (120/363) - Mini-batch Training loss: 0.2857 - Training Acc 1: 0.30
Epoch 66 - Batch (130/363) - Mini-batch Training loss: 0.2836 - Training Acc 1: 0.33
Epoch 66 - Batch (140/363) - Mini-batch Training loss: 0.2757 - Training Acc 1: 0.36
Epoch 66 - Batch (150/363) - Mini-batch Training loss: 0.2776 - Training Acc 1: 0.38
Epoch 66 - Batch (160/363) - Mini-batch Training loss: 0.2863 - Training Acc 1: 0.41
Epoch 66 - Batch (170/363) - Mini-batch Training loss: 0.2813 - Training Acc 1: 0.43
Epoch 66 - Batch (180/363) - Mini-batch Training loss: 0.2886 - Training Acc 1: 0.45
Epoch 66 - Batch (190/363) - Mini-batch Training loss: 0.2920 - Training Acc 1: 0.48
Epoch 66 - Batch (200/363) - Mini-batch Training loss: 0.3026 - Training Acc 1: 0.50
Epoch 66 - Batch (210/363) - Mini-batch Training loss: 0.3211 - Training Acc 1: 0.52
Epoch 66 - Batch (220/363) - Mini-batch Training loss: 0.3156 - Training Acc 1: 0.55
Epoch 66 - Batch (230/363) - Mini-batch Training loss: 0.3189 - Training Acc 1: 0.57
Epoch 66 - Batch (240/363) - Mini-batch Training loss: 0.3130 - Training Acc 1: 0.60
Epoch 66 - Batch (250/363) - Mini-batch Training loss: 0.3161 - Training Acc 1: 0.63
Epoch 66 - Batch (260/363) - Mini-batch Training loss: 0.3238 - Training Acc 1: 0.65
Epoch 66 - Batch (270/363) - Mini-batch Training loss: 0.3188 - Training Acc 1: 0.68
Epoch 66 - Batch (280/363) - Mini-batch Training loss: 0.3138 - Training Acc 1: 0.70
Epoch 66 - Batch (290/363) - Mini-batch Training loss: 0.3076 - Training Acc 1: 0.73
Epoch 66 - Batch (300/363) - Mini-batch Training loss: 0.3120 - Training Acc 1: 0.75
Epoch 66 - Batch (310/363) - Mini-batch Training loss: 0.3074 - Training Acc 1: 0.78
Epoch 66 - Batch (320/363) - Mini-batch Training loss: 0.3089 - Training Acc 1: 0.80
Epoch 66 - Batch (330/363) - Mini-batch Training loss: 0.3099 - Training Acc 1: 0.83
Epoch 66 - Batch (340/363) - Mini-batch Training loss: 0.3091 - Training Acc 1: 0.85
Epoch 66 - Batch (350/363) - Mini-batch Training loss: 0.3147 - Training Acc 1: 0.88
Epoch 66 - Batch (360/363) - Mini-batch Training loss: 0.3190 - Training Acc 1: 0.90
Epoch 66 - Full-batch Training loss: 0.3184 - Training Acc 1: 0.90
Validation set: Average loss: 0.6560, Accuracy: 293.0/363 (81%)

Epoch 67 - Batch (0/363) - Mini-batch Training loss: 0.4143 - Training Acc 1: 0.00
Epoch 67 - Batch (10/363) - Mini-batch Training loss: 0.2918 - Training Acc 1: 0.03
Epoch 67 - Batch (20/363) - Mini-batch Training loss: 0.2993 - Training Acc 1: 0.05
Epoch 67 - Batch (30/363) - Mini-batch Training loss: 0.3384 - Training Acc 1: 0.08
Epoch 67 - Batch (40/363) - Mini-batch Training loss: 0.3257 - Training Acc 1: 0.10
Epoch 67 - Batch (50/363) - Mini-batch Training loss: 0.3263 - Training Acc 1: 0.13
Epoch 67 - Batch (60/363) - Mini-batch Training loss: 0.3358 - Training Acc 1: 0.15
Epoch 67 - Batch (70/363) - Mini-batch Training loss: 0.3097 - Training Acc 1: 0.18
Epoch 67 - Batch (80/363) - Mini-batch Training loss: 0.3180 - Training Acc 1: 0.20
Epoch 67 - Batch (90/363) - Mini-batch Training loss: 0.3153 - Training Acc 1: 0.23
Epoch 67 - Batch (100/363) - Mini-batch Training loss: 0.3169 - Training Acc 1: 0.25
Epoch 67 - Batch (110/363) - Mini-batch Training loss: 0.3155 - Training Acc 1: 0.28
Epoch 67 - Batch (120/363) - Mini-batch Training loss: 0.2978 - Training Acc 1: 0.30
Epoch 67 - Batch (130/363) - Mini-batch Training loss: 0.2942 - Training Acc 1: 0.33
Epoch 67 - Batch (140/363) - Mini-batch Training loss: 0.3009 - Training Acc 1: 0.35
Epoch 67 - Batch (150/363) - Mini-batch Training loss: 0.3072 - Training Acc 1: 0.38
Epoch 67 - Batch (160/363) - Mini-batch Training loss: 0.3022 - Training Acc 1: 0.40
Epoch 67 - Batch (170/363) - Mini-batch Training loss: 0.2954 - Training Acc 1: 0.43
Epoch 67 - Batch (180/363) - Mini-batch Training loss: 0.2938 - Training Acc 1: 0.45
Epoch 67 - Batch (190/363) - Mini-batch Training loss: 0.2892 - Training Acc 1: 0.48
Epoch 67 - Batch (200/363) - Mini-batch Training loss: 0.2806 - Training Acc 1: 0.51
Epoch 67 - Batch (210/363) - Mini-batch Training loss: 0.2857 - Training Acc 1: 0.53
Epoch 67 - Batch (220/363) - Mini-batch Training loss: 0.2851 - Training Acc 1: 0.56
Epoch 67 - Batch (230/363) - Mini-batch Training loss: 0.2840 - Training Acc 1: 0.58
Epoch 67 - Batch (240/363) - Mini-batch Training loss: 0.2944 - Training Acc 1: 0.60
Epoch 67 - Batch (250/363) - Mini-batch Training loss: 0.2944 - Training Acc 1: 0.63
Epoch 67 - Batch (260/363) - Mini-batch Training loss: 0.3041 - Training Acc 1: 0.65
Epoch 67 - Batch (270/363) - Mini-batch Training loss: 0.3075 - Training Acc 1: 0.68
Epoch 67 - Batch (280/363) - Mini-batch Training loss: 0.3068 - Training Acc 1: 0.70
Epoch 67 - Batch (290/363) - Mini-batch Training loss: 0.3154 - Training Acc 1: 0.72
Epoch 67 - Batch (300/363) - Mini-batch Training loss: 0.3148 - Training Acc 1: 0.75
Epoch 67 - Batch (310/363) - Mini-batch Training loss: 0.3221 - Training Acc 1: 0.77
Epoch 67 - Batch (320/363) - Mini-batch Training loss: 0.3255 - Training Acc 1: 0.80
Epoch 67 - Batch (330/363) - Mini-batch Training loss: 0.3220 - Training Acc 1: 0.82
Epoch 67 - Batch (340/363) - Mini-batch Training loss: 0.3166 - Training Acc 1: 0.85
Epoch 67 - Batch (350/363) - Mini-batch Training loss: 0.3173 - Training Acc 1: 0.87
Epoch 67 - Batch (360/363) - Mini-batch Training loss: 0.3224 - Training Acc 1: 0.89
Epoch 67 - Full-batch Training loss: 0.3247 - Training Acc 1: 0.90
Validation set: Average loss: 0.6632, Accuracy: 293.0/363 (81%)

Epoch 68 - Batch (0/363) - Mini-batch Training loss: 0.9063 - Training Acc 1: 0.00
Epoch 68 - Batch (10/363) - Mini-batch Training loss: 0.3210 - Training Acc 1: 0.03
Epoch 68 - Batch (20/363) - Mini-batch Training loss: 0.3150 - Training Acc 1: 0.05
Epoch 68 - Batch (30/363) - Mini-batch Training loss: 0.2758 - Training Acc 1: 0.08
Epoch 68 - Batch (40/363) - Mini-batch Training loss: 0.3305 - Training Acc 1: 0.10
Epoch 68 - Batch (50/363) - Mini-batch Training loss: 0.3172 - Training Acc 1: 0.13
Epoch 68 - Batch (60/363) - Mini-batch Training loss: 0.3113 - Training Acc 1: 0.15
Epoch 68 - Batch (70/363) - Mini-batch Training loss: 0.2918 - Training Acc 1: 0.18
Epoch 68 - Batch (80/363) - Mini-batch Training loss: 0.3052 - Training Acc 1: 0.20
Epoch 68 - Batch (90/363) - Mini-batch Training loss: 0.3099 - Training Acc 1: 0.22
Epoch 68 - Batch (100/363) - Mini-batch Training loss: 0.3217 - Training Acc 1: 0.25
Epoch 68 - Batch (110/363) - Mini-batch Training loss: 0.3346 - Training Acc 1: 0.27
Epoch 68 - Batch (120/363) - Mini-batch Training loss: 0.3284 - Training Acc 1: 0.30
Epoch 68 - Batch (130/363) - Mini-batch Training loss: 0.3308 - Training Acc 1: 0.32
Epoch 68 - Batch (140/363) - Mini-batch Training loss: 0.3380 - Training Acc 1: 0.34
Epoch 68 - Batch (150/363) - Mini-batch Training loss: 0.3441 - Training Acc 1: 0.37
Epoch 68 - Batch (160/363) - Mini-batch Training loss: 0.3445 - Training Acc 1: 0.39
Epoch 68 - Batch (170/363) - Mini-batch Training loss: 0.3419 - Training Acc 1: 0.42
Epoch 68 - Batch (180/363) - Mini-batch Training loss: 0.3344 - Training Acc 1: 0.44
Epoch 68 - Batch (190/363) - Mini-batch Training loss: 0.3352 - Training Acc 1: 0.47
Epoch 68 - Batch (200/363) - Mini-batch Training loss: 0.3332 - Training Acc 1: 0.49
Epoch 68 - Batch (210/363) - Mini-batch Training loss: 0.3327 - Training Acc 1: 0.52
Epoch 68 - Batch (220/363) - Mini-batch Training loss: 0.3342 - Training Acc 1: 0.54
Epoch 68 - Batch (230/363) - Mini-batch Training loss: 0.3322 - Training Acc 1: 0.56
Epoch 68 - Batch (240/363) - Mini-batch Training loss: 0.3297 - Training Acc 1: 0.59
Epoch 68 - Batch (250/363) - Mini-batch Training loss: 0.3397 - Training Acc 1: 0.61
Epoch 68 - Batch (260/363) - Mini-batch Training loss: 0.3409 - Training Acc 1: 0.63
Epoch 68 - Batch (270/363) - Mini-batch Training loss: 0.3351 - Training Acc 1: 0.66
Epoch 68 - Batch (280/363) - Mini-batch Training loss: 0.3289 - Training Acc 1: 0.69
Epoch 68 - Batch (290/363) - Mini-batch Training loss: 0.3316 - Training Acc 1: 0.71
Epoch 68 - Batch (300/363) - Mini-batch Training loss: 0.3316 - Training Acc 1: 0.73
Epoch 68 - Batch (310/363) - Mini-batch Training loss: 0.3314 - Training Acc 1: 0.76
Epoch 68 - Batch (320/363) - Mini-batch Training loss: 0.3292 - Training Acc 1: 0.78
Epoch 68 - Batch (330/363) - Mini-batch Training loss: 0.3263 - Training Acc 1: 0.81
Epoch 68 - Batch (340/363) - Mini-batch Training loss: 0.3258 - Training Acc 1: 0.83
Epoch 68 - Batch (350/363) - Mini-batch Training loss: 0.3316 - Training Acc 1: 0.86
Epoch 68 - Batch (360/363) - Mini-batch Training loss: 0.3259 - Training Acc 1: 0.88
Epoch 68 - Full-batch Training loss: 0.3245 - Training Acc 1: 0.89
Validation set: Average loss: 0.6963, Accuracy: 294.0/363 (81%)

Epoch 69 - Batch (0/363) - Mini-batch Training loss: 0.0944 - Training Acc 1: 0.00
Epoch 69 - Batch (10/363) - Mini-batch Training loss: 0.1677 - Training Acc 1: 0.03
Epoch 69 - Batch (20/363) - Mini-batch Training loss: 0.3350 - Training Acc 1: 0.05
Epoch 69 - Batch (30/363) - Mini-batch Training loss: 0.3945 - Training Acc 1: 0.07
Epoch 69 - Batch (40/363) - Mini-batch Training loss: 0.5285 - Training Acc 1: 0.09
Epoch 69 - Batch (50/363) - Mini-batch Training loss: 0.5857 - Training Acc 1: 0.11
Epoch 69 - Batch (60/363) - Mini-batch Training loss: 0.6004 - Training Acc 1: 0.14
Epoch 69 - Batch (70/363) - Mini-batch Training loss: 0.5616 - Training Acc 1: 0.16
Epoch 69 - Batch (80/363) - Mini-batch Training loss: 0.5190 - Training Acc 1: 0.19
Epoch 69 - Batch (90/363) - Mini-batch Training loss: 0.4794 - Training Acc 1: 0.21
Epoch 69 - Batch (100/363) - Mini-batch Training loss: 0.4653 - Training Acc 1: 0.24
Epoch 69 - Batch (110/363) - Mini-batch Training loss: 0.4526 - Training Acc 1: 0.26
Epoch 69 - Batch (120/363) - Mini-batch Training loss: 0.4486 - Training Acc 1: 0.29
Epoch 69 - Batch (130/363) - Mini-batch Training loss: 0.4478 - Training Acc 1: 0.31
Epoch 69 - Batch (140/363) - Mini-batch Training loss: 0.4293 - Training Acc 1: 0.34
Epoch 69 - Batch (150/363) - Mini-batch Training loss: 0.4162 - Training Acc 1: 0.36
Epoch 69 - Batch (160/363) - Mini-batch Training loss: 0.4034 - Training Acc 1: 0.39
Epoch 69 - Batch (170/363) - Mini-batch Training loss: 0.3962 - Training Acc 1: 0.41
Epoch 69 - Batch (180/363) - Mini-batch Training loss: 0.3846 - Training Acc 1: 0.44
Epoch 69 - Batch (190/363) - Mini-batch Training loss: 0.3884 - Training Acc 1: 0.46
Epoch 69 - Batch (200/363) - Mini-batch Training loss: 0.3781 - Training Acc 1: 0.49
Epoch 69 - Batch (210/363) - Mini-batch Training loss: 0.3764 - Training Acc 1: 0.51
Epoch 69 - Batch (220/363) - Mini-batch Training loss: 0.3651 - Training Acc 1: 0.54
Epoch 69 - Batch (230/363) - Mini-batch Training loss: 0.3689 - Training Acc 1: 0.56
Epoch 69 - Batch (240/363) - Mini-batch Training loss: 0.3650 - Training Acc 1: 0.59
Epoch 69 - Batch (250/363) - Mini-batch Training loss: 0.3654 - Training Acc 1: 0.61
Epoch 69 - Batch (260/363) - Mini-batch Training loss: 0.3659 - Training Acc 1: 0.64
Epoch 69 - Batch (270/363) - Mini-batch Training loss: 0.3654 - Training Acc 1: 0.66
Epoch 69 - Batch (280/363) - Mini-batch Training loss: 0.3654 - Training Acc 1: 0.69
Epoch 69 - Batch (290/363) - Mini-batch Training loss: 0.3612 - Training Acc 1: 0.71
Epoch 69 - Batch (300/363) - Mini-batch Training loss: 0.3568 - Training Acc 1: 0.74
Epoch 69 - Batch (310/363) - Mini-batch Training loss: 0.3512 - Training Acc 1: 0.76
Epoch 69 - Batch (320/363) - Mini-batch Training loss: 0.3552 - Training Acc 1: 0.79
Epoch 69 - Batch (330/363) - Mini-batch Training loss: 0.3575 - Training Acc 1: 0.81
Epoch 69 - Batch (340/363) - Mini-batch Training loss: 0.3566 - Training Acc 1: 0.83
Epoch 69 - Batch (350/363) - Mini-batch Training loss: 0.3540 - Training Acc 1: 0.86
Epoch 69 - Batch (360/363) - Mini-batch Training loss: 0.3495 - Training Acc 1: 0.88
Epoch 69 - Full-batch Training loss: 0.3482 - Training Acc 1: 0.89
Validation set: Average loss: 0.6540, Accuracy: 292.0/363 (80%)

Epoch 70 - Batch (0/363) - Mini-batch Training loss: 0.0967 - Training Acc 1: 0.00
Epoch 70 - Batch (10/363) - Mini-batch Training loss: 0.1516 - Training Acc 1: 0.03
Epoch 70 - Batch (20/363) - Mini-batch Training loss: 0.2633 - Training Acc 1: 0.05
Epoch 70 - Batch (30/363) - Mini-batch Training loss: 0.2619 - Training Acc 1: 0.08
Epoch 70 - Batch (40/363) - Mini-batch Training loss: 0.2639 - Training Acc 1: 0.10
Epoch 70 - Batch (50/363) - Mini-batch Training loss: 0.2603 - Training Acc 1: 0.13
Epoch 70 - Batch (60/363) - Mini-batch Training loss: 0.2617 - Training Acc 1: 0.15
Epoch 70 - Batch (70/363) - Mini-batch Training loss: 0.2733 - Training Acc 1: 0.18
Epoch 70 - Batch (80/363) - Mini-batch Training loss: 0.2795 - Training Acc 1: 0.20
Epoch 70 - Batch (90/363) - Mini-batch Training loss: 0.2637 - Training Acc 1: 0.23
Epoch 70 - Batch (100/363) - Mini-batch Training loss: 0.2613 - Training Acc 1: 0.25
Epoch 70 - Batch (110/363) - Mini-batch Training loss: 0.2688 - Training Acc 1: 0.28
Epoch 70 - Batch (120/363) - Mini-batch Training loss: 0.2739 - Training Acc 1: 0.30
Epoch 70 - Batch (130/363) - Mini-batch Training loss: 0.2835 - Training Acc 1: 0.33
Epoch 70 - Batch (140/363) - Mini-batch Training loss: 0.2908 - Training Acc 1: 0.35
Epoch 70 - Batch (150/363) - Mini-batch Training loss: 0.2904 - Training Acc 1: 0.38
Epoch 70 - Batch (160/363) - Mini-batch Training loss: 0.2794 - Training Acc 1: 0.40
Epoch 70 - Batch (170/363) - Mini-batch Training loss: 0.2757 - Training Acc 1: 0.43
Epoch 70 - Batch (180/363) - Mini-batch Training loss: 0.2728 - Training Acc 1: 0.45
Epoch 70 - Batch (190/363) - Mini-batch Training loss: 0.2695 - Training Acc 1: 0.48
Epoch 70 - Batch (200/363) - Mini-batch Training loss: 0.2768 - Training Acc 1: 0.50
Epoch 70 - Batch (210/363) - Mini-batch Training loss: 0.2740 - Training Acc 1: 0.53
Epoch 70 - Batch (220/363) - Mini-batch Training loss: 0.2737 - Training Acc 1: 0.55
Epoch 70 - Batch (230/363) - Mini-batch Training loss: 0.2854 - Training Acc 1: 0.58
Epoch 70 - Batch (240/363) - Mini-batch Training loss: 0.2913 - Training Acc 1: 0.60
Epoch 70 - Batch (250/363) - Mini-batch Training loss: 0.2981 - Training Acc 1: 0.62
Epoch 70 - Batch (260/363) - Mini-batch Training loss: 0.3067 - Training Acc 1: 0.65
Epoch 70 - Batch (270/363) - Mini-batch Training loss: 0.2993 - Training Acc 1: 0.67
Epoch 70 - Batch (280/363) - Mini-batch Training loss: 0.2941 - Training Acc 1: 0.70
Epoch 70 - Batch (290/363) - Mini-batch Training loss: 0.2929 - Training Acc 1: 0.73
Epoch 70 - Batch (300/363) - Mini-batch Training loss: 0.2944 - Training Acc 1: 0.75
Epoch 70 - Batch (310/363) - Mini-batch Training loss: 0.2926 - Training Acc 1: 0.78
Epoch 70 - Batch (320/363) - Mini-batch Training loss: 0.2903 - Training Acc 1: 0.80
Epoch 70 - Batch (330/363) - Mini-batch Training loss: 0.2935 - Training Acc 1: 0.82
Epoch 70 - Batch (340/363) - Mini-batch Training loss: 0.2945 - Training Acc 1: 0.85
Epoch 70 - Batch (350/363) - Mini-batch Training loss: 0.2923 - Training Acc 1: 0.88
Epoch 70 - Batch (360/363) - Mini-batch Training loss: 0.2864 - Training Acc 1: 0.90
Epoch 70 - Full-batch Training loss: 0.2872 - Training Acc 1: 0.90
Validation set: Average loss: 0.6538, Accuracy: 298.0/363 (82%)

Epoch 71 - Batch (0/363) - Mini-batch Training loss: 0.0685 - Training Acc 1: 0.00
Epoch 71 - Batch (10/363) - Mini-batch Training loss: 0.1652 - Training Acc 1: 0.03
Epoch 71 - Batch (20/363) - Mini-batch Training loss: 0.1793 - Training Acc 1: 0.06
Epoch 71 - Batch (30/363) - Mini-batch Training loss: 0.2288 - Training Acc 1: 0.08
Epoch 71 - Batch (40/363) - Mini-batch Training loss: 0.2474 - Training Acc 1: 0.10
Epoch 71 - Batch (50/363) - Mini-batch Training loss: 0.3294 - Training Acc 1: 0.13
Epoch 71 - Batch (60/363) - Mini-batch Training loss: 0.3273 - Training Acc 1: 0.15
Epoch 71 - Batch (70/363) - Mini-batch Training loss: 0.3059 - Training Acc 1: 0.18
Epoch 71 - Batch (80/363) - Mini-batch Training loss: 0.3014 - Training Acc 1: 0.20
Epoch 71 - Batch (90/363) - Mini-batch Training loss: 0.2870 - Training Acc 1: 0.23
Epoch 71 - Batch (100/363) - Mini-batch Training loss: 0.2791 - Training Acc 1: 0.26
Epoch 71 - Batch (110/363) - Mini-batch Training loss: 0.2813 - Training Acc 1: 0.28
Epoch 71 - Batch (120/363) - Mini-batch Training loss: 0.2824 - Training Acc 1: 0.31
Epoch 71 - Batch (130/363) - Mini-batch Training loss: 0.2750 - Training Acc 1: 0.33
Epoch 71 - Batch (140/363) - Mini-batch Training loss: 0.2697 - Training Acc 1: 0.36
Epoch 71 - Batch (150/363) - Mini-batch Training loss: 0.2658 - Training Acc 1: 0.39
Epoch 71 - Batch (160/363) - Mini-batch Training loss: 0.2582 - Training Acc 1: 0.41
Epoch 71 - Batch (170/363) - Mini-batch Training loss: 0.2564 - Training Acc 1: 0.44
Epoch 71 - Batch (180/363) - Mini-batch Training loss: 0.2613 - Training Acc 1: 0.46
Epoch 71 - Batch (190/363) - Mini-batch Training loss: 0.2560 - Training Acc 1: 0.49
Epoch 71 - Batch (200/363) - Mini-batch Training loss: 0.2588 - Training Acc 1: 0.52
Epoch 71 - Batch (210/363) - Mini-batch Training loss: 0.2671 - Training Acc 1: 0.54
Epoch 71 - Batch (220/363) - Mini-batch Training loss: 0.2718 - Training Acc 1: 0.56
Epoch 71 - Batch (230/363) - Mini-batch Training loss: 0.2717 - Training Acc 1: 0.59
Epoch 71 - Batch (240/363) - Mini-batch Training loss: 0.2778 - Training Acc 1: 0.61
Epoch 71 - Batch (250/363) - Mini-batch Training loss: 0.2720 - Training Acc 1: 0.64
Epoch 71 - Batch (260/363) - Mini-batch Training loss: 0.2713 - Training Acc 1: 0.67
Epoch 71 - Batch (270/363) - Mini-batch Training loss: 0.2759 - Training Acc 1: 0.69
Epoch 71 - Batch (280/363) - Mini-batch Training loss: 0.2765 - Training Acc 1: 0.72
Epoch 71 - Batch (290/363) - Mini-batch Training loss: 0.2734 - Training Acc 1: 0.74
Epoch 71 - Batch (300/363) - Mini-batch Training loss: 0.2781 - Training Acc 1: 0.77
Epoch 71 - Batch (310/363) - Mini-batch Training loss: 0.2808 - Training Acc 1: 0.79
Epoch 71 - Batch (320/363) - Mini-batch Training loss: 0.2789 - Training Acc 1: 0.82
Epoch 71 - Batch (330/363) - Mini-batch Training loss: 0.2759 - Training Acc 1: 0.84
Epoch 71 - Batch (340/363) - Mini-batch Training loss: 0.2776 - Training Acc 1: 0.87
Epoch 71 - Batch (350/363) - Mini-batch Training loss: 0.2800 - Training Acc 1: 0.89
Epoch 71 - Batch (360/363) - Mini-batch Training loss: 0.2875 - Training Acc 1: 0.92
Epoch 71 - Full-batch Training loss: 0.2871 - Training Acc 1: 0.92
Validation set: Average loss: 0.7497, Accuracy: 296.0/363 (82%)

Epoch 72 - Batch (0/363) - Mini-batch Training loss: 0.0559 - Training Acc 1: 0.00
Epoch 72 - Batch (10/363) - Mini-batch Training loss: 0.1834 - Training Acc 1: 0.03
Epoch 72 - Batch (20/363) - Mini-batch Training loss: 0.1821 - Training Acc 1: 0.06
Epoch 72 - Batch (30/363) - Mini-batch Training loss: 0.1855 - Training Acc 1: 0.08
Epoch 72 - Batch (40/363) - Mini-batch Training loss: 0.1997 - Training Acc 1: 0.11
Epoch 72 - Batch (50/363) - Mini-batch Training loss: 0.2064 - Training Acc 1: 0.13
Epoch 72 - Batch (60/363) - Mini-batch Training loss: 0.2246 - Training Acc 1: 0.16
Epoch 72 - Batch (70/363) - Mini-batch Training loss: 0.2150 - Training Acc 1: 0.18
Epoch 72 - Batch (80/363) - Mini-batch Training loss: 0.2347 - Training Acc 1: 0.21
Epoch 72 - Batch (90/363) - Mini-batch Training loss: 0.2515 - Training Acc 1: 0.23
Epoch 72 - Batch (100/363) - Mini-batch Training loss: 0.2589 - Training Acc 1: 0.26
Epoch 72 - Batch (110/363) - Mini-batch Training loss: 0.2490 - Training Acc 1: 0.28
Epoch 72 - Batch (120/363) - Mini-batch Training loss: 0.2488 - Training Acc 1: 0.31
Epoch 72 - Batch (130/363) - Mini-batch Training loss: 0.2616 - Training Acc 1: 0.33
Epoch 72 - Batch (140/363) - Mini-batch Training loss: 0.2558 - Training Acc 1: 0.36
Epoch 72 - Batch (150/363) - Mini-batch Training loss: 0.2604 - Training Acc 1: 0.38
Epoch 72 - Batch (160/363) - Mini-batch Training loss: 0.2569 - Training Acc 1: 0.41
Epoch 72 - Batch (170/363) - Mini-batch Training loss: 0.2631 - Training Acc 1: 0.43
Epoch 72 - Batch (180/363) - Mini-batch Training loss: 0.2585 - Training Acc 1: 0.46
Epoch 72 - Batch (190/363) - Mini-batch Training loss: 0.2635 - Training Acc 1: 0.48
Epoch 72 - Batch (200/363) - Mini-batch Training loss: 0.2636 - Training Acc 1: 0.50
Epoch 72 - Batch (210/363) - Mini-batch Training loss: 0.2573 - Training Acc 1: 0.53
Epoch 72 - Batch (220/363) - Mini-batch Training loss: 0.2556 - Training Acc 1: 0.56
Epoch 72 - Batch (230/363) - Mini-batch Training loss: 0.2601 - Training Acc 1: 0.58
Epoch 72 - Batch (240/363) - Mini-batch Training loss: 0.2627 - Training Acc 1: 0.61
Epoch 72 - Batch (250/363) - Mini-batch Training loss: 0.2614 - Training Acc 1: 0.63
Epoch 72 - Batch (260/363) - Mini-batch Training loss: 0.2638 - Training Acc 1: 0.66
Epoch 72 - Batch (270/363) - Mini-batch Training loss: 0.2610 - Training Acc 1: 0.68
Epoch 72 - Batch (280/363) - Mini-batch Training loss: 0.2681 - Training Acc 1: 0.71
Epoch 72 - Batch (290/363) - Mini-batch Training loss: 0.2726 - Training Acc 1: 0.73
Epoch 72 - Batch (300/363) - Mini-batch Training loss: 0.2782 - Training Acc 1: 0.76
Epoch 72 - Batch (310/363) - Mini-batch Training loss: 0.2776 - Training Acc 1: 0.78
Epoch 72 - Batch (320/363) - Mini-batch Training loss: 0.2846 - Training Acc 1: 0.81
Epoch 72 - Batch (330/363) - Mini-batch Training loss: 0.2893 - Training Acc 1: 0.83
Epoch 72 - Batch (340/363) - Mini-batch Training loss: 0.2932 - Training Acc 1: 0.85
Epoch 72 - Batch (350/363) - Mini-batch Training loss: 0.2974 - Training Acc 1: 0.88
Epoch 72 - Batch (360/363) - Mini-batch Training loss: 0.2968 - Training Acc 1: 0.90
Epoch 72 - Full-batch Training loss: 0.2960 - Training Acc 1: 0.91
Validation set: Average loss: 0.7127, Accuracy: 290.0/363 (80%)

Epoch 73 - Batch (0/363) - Mini-batch Training loss: 0.1348 - Training Acc 1: 0.00
Epoch 73 - Batch (10/363) - Mini-batch Training loss: 0.3578 - Training Acc 1: 0.03
Epoch 73 - Batch (20/363) - Mini-batch Training loss: 0.3297 - Training Acc 1: 0.05
Epoch 73 - Batch (30/363) - Mini-batch Training loss: 0.2894 - Training Acc 1: 0.08
Epoch 73 - Batch (40/363) - Mini-batch Training loss: 0.2728 - Training Acc 1: 0.10
Epoch 73 - Batch (50/363) - Mini-batch Training loss: 0.2672 - Training Acc 1: 0.13
Epoch 73 - Batch (60/363) - Mini-batch Training loss: 0.2842 - Training Acc 1: 0.15
Epoch 73 - Batch (70/363) - Mini-batch Training loss: 0.2916 - Training Acc 1: 0.18
Epoch 73 - Batch (80/363) - Mini-batch Training loss: 0.2872 - Training Acc 1: 0.20
Epoch 73 - Batch (90/363) - Mini-batch Training loss: 0.2847 - Training Acc 1: 0.23
Epoch 73 - Batch (100/363) - Mini-batch Training loss: 0.2906 - Training Acc 1: 0.25
Epoch 73 - Batch (110/363) - Mini-batch Training loss: 0.2891 - Training Acc 1: 0.28
Epoch 73 - Batch (120/363) - Mini-batch Training loss: 0.2768 - Training Acc 1: 0.31
Epoch 73 - Batch (130/363) - Mini-batch Training loss: 0.2636 - Training Acc 1: 0.33
Epoch 73 - Batch (140/363) - Mini-batch Training loss: 0.2760 - Training Acc 1: 0.35
Epoch 73 - Batch (150/363) - Mini-batch Training loss: 0.2691 - Training Acc 1: 0.38
Epoch 73 - Batch (160/363) - Mini-batch Training loss: 0.2633 - Training Acc 1: 0.41
Epoch 73 - Batch (170/363) - Mini-batch Training loss: 0.2554 - Training Acc 1: 0.43
Epoch 73 - Batch (180/363) - Mini-batch Training loss: 0.2556 - Training Acc 1: 0.46
Epoch 73 - Batch (190/363) - Mini-batch Training loss: 0.2620 - Training Acc 1: 0.48
Epoch 73 - Batch (200/363) - Mini-batch Training loss: 0.2641 - Training Acc 1: 0.51
Epoch 73 - Batch (210/363) - Mini-batch Training loss: 0.2731 - Training Acc 1: 0.53
Epoch 73 - Batch (220/363) - Mini-batch Training loss: 0.2731 - Training Acc 1: 0.56
Epoch 73 - Batch (230/363) - Mini-batch Training loss: 0.2721 - Training Acc 1: 0.58
Epoch 73 - Batch (240/363) - Mini-batch Training loss: 0.2711 - Training Acc 1: 0.61
Epoch 73 - Batch (250/363) - Mini-batch Training loss: 0.2685 - Training Acc 1: 0.64
Epoch 73 - Batch (260/363) - Mini-batch Training loss: 0.2672 - Training Acc 1: 0.66
Epoch 73 - Batch (270/363) - Mini-batch Training loss: 0.2747 - Training Acc 1: 0.68
Epoch 73 - Batch (280/363) - Mini-batch Training loss: 0.2755 - Training Acc 1: 0.71
Epoch 73 - Batch (290/363) - Mini-batch Training loss: 0.2785 - Training Acc 1: 0.73
Epoch 73 - Batch (300/363) - Mini-batch Training loss: 0.2786 - Training Acc 1: 0.76
Epoch 73 - Batch (310/363) - Mini-batch Training loss: 0.2798 - Training Acc 1: 0.78
Epoch 73 - Batch (320/363) - Mini-batch Training loss: 0.2812 - Training Acc 1: 0.81
Epoch 73 - Batch (330/363) - Mini-batch Training loss: 0.2772 - Training Acc 1: 0.83
Epoch 73 - Batch (340/363) - Mini-batch Training loss: 0.2808 - Training Acc 1: 0.86
Epoch 73 - Batch (350/363) - Mini-batch Training loss: 0.2785 - Training Acc 1: 0.88
Epoch 73 - Batch (360/363) - Mini-batch Training loss: 0.2827 - Training Acc 1: 0.91
Epoch 73 - Full-batch Training loss: 0.2815 - Training Acc 1: 0.91
Validation set: Average loss: 0.8240, Accuracy: 287.0/363 (79%)

Epoch 74 - Batch (0/363) - Mini-batch Training loss: 0.1906 - Training Acc 1: 0.00
Epoch 74 - Batch (10/363) - Mini-batch Training loss: 0.2755 - Training Acc 1: 0.03
Epoch 74 - Batch (20/363) - Mini-batch Training loss: 0.3639 - Training Acc 1: 0.05
Epoch 74 - Batch (30/363) - Mini-batch Training loss: 0.3153 - Training Acc 1: 0.08
Epoch 74 - Batch (40/363) - Mini-batch Training loss: 0.3012 - Training Acc 1: 0.10
Epoch 74 - Batch (50/363) - Mini-batch Training loss: 0.2983 - Training Acc 1: 0.13
Epoch 74 - Batch (60/363) - Mini-batch Training loss: 0.2864 - Training Acc 1: 0.16
Epoch 74 - Batch (70/363) - Mini-batch Training loss: 0.2854 - Training Acc 1: 0.18
Epoch 74 - Batch (80/363) - Mini-batch Training loss: 0.3090 - Training Acc 1: 0.20
Epoch 74 - Batch (90/363) - Mini-batch Training loss: 0.2981 - Training Acc 1: 0.23
Epoch 74 - Batch (100/363) - Mini-batch Training loss: 0.2994 - Training Acc 1: 0.25
Epoch 74 - Batch (110/363) - Mini-batch Training loss: 0.2876 - Training Acc 1: 0.28
Epoch 74 - Batch (120/363) - Mini-batch Training loss: 0.3009 - Training Acc 1: 0.30
Epoch 74 - Batch (130/363) - Mini-batch Training loss: 0.2908 - Training Acc 1: 0.33
Epoch 74 - Batch (140/363) - Mini-batch Training loss: 0.2959 - Training Acc 1: 0.35
Epoch 74 - Batch (150/363) - Mini-batch Training loss: 0.3009 - Training Acc 1: 0.38
Epoch 74 - Batch (160/363) - Mini-batch Training loss: 0.3096 - Training Acc 1: 0.40
Epoch 74 - Batch (170/363) - Mini-batch Training loss: 0.2978 - Training Acc 1: 0.43
Epoch 74 - Batch (180/363) - Mini-batch Training loss: 0.3127 - Training Acc 1: 0.45
Epoch 74 - Batch (190/363) - Mini-batch Training loss: 0.3133 - Training Acc 1: 0.47
Epoch 74 - Batch (200/363) - Mini-batch Training loss: 0.3140 - Training Acc 1: 0.50
Epoch 74 - Batch (210/363) - Mini-batch Training loss: 0.3115 - Training Acc 1: 0.53
Epoch 74 - Batch (220/363) - Mini-batch Training loss: 0.3161 - Training Acc 1: 0.55
Epoch 74 - Batch (230/363) - Mini-batch Training loss: 0.3110 - Training Acc 1: 0.58
Epoch 74 - Batch (240/363) - Mini-batch Training loss: 0.3023 - Training Acc 1: 0.60
Epoch 74 - Batch (250/363) - Mini-batch Training loss: 0.3077 - Training Acc 1: 0.63
Epoch 74 - Batch (260/363) - Mini-batch Training loss: 0.3034 - Training Acc 1: 0.65
Epoch 74 - Batch (270/363) - Mini-batch Training loss: 0.2985 - Training Acc 1: 0.68
Epoch 74 - Batch (280/363) - Mini-batch Training loss: 0.2936 - Training Acc 1: 0.71
Epoch 74 - Batch (290/363) - Mini-batch Training loss: 0.2950 - Training Acc 1: 0.73
Epoch 74 - Batch (300/363) - Mini-batch Training loss: 0.2927 - Training Acc 1: 0.76
Epoch 74 - Batch (310/363) - Mini-batch Training loss: 0.2943 - Training Acc 1: 0.78
Epoch 74 - Batch (320/363) - Mini-batch Training loss: 0.2949 - Training Acc 1: 0.81
Epoch 74 - Batch (330/363) - Mini-batch Training loss: 0.2954 - Training Acc 1: 0.83
Epoch 74 - Batch (340/363) - Mini-batch Training loss: 0.2981 - Training Acc 1: 0.86
Epoch 74 - Batch (350/363) - Mini-batch Training loss: 0.3046 - Training Acc 1: 0.88
Epoch 74 - Batch (360/363) - Mini-batch Training loss: 0.3074 - Training Acc 1: 0.90
Epoch 74 - Full-batch Training loss: 0.3075 - Training Acc 1: 0.91
Validation set: Average loss: 0.8266, Accuracy: 285.0/363 (79%)

Epoch 75 - Batch (0/363) - Mini-batch Training loss: 0.2778 - Training Acc 1: 0.00
Epoch 75 - Batch (10/363) - Mini-batch Training loss: 0.2271 - Training Acc 1: 0.03
Epoch 75 - Batch (20/363) - Mini-batch Training loss: 0.3645 - Training Acc 1: 0.05
Epoch 75 - Batch (30/363) - Mini-batch Training loss: 0.4315 - Training Acc 1: 0.08
Epoch 75 - Batch (40/363) - Mini-batch Training loss: 0.4656 - Training Acc 1: 0.10
Epoch 75 - Batch (50/363) - Mini-batch Training loss: 0.4363 - Training Acc 1: 0.12
Epoch 75 - Batch (60/363) - Mini-batch Training loss: 0.4081 - Training Acc 1: 0.15
Epoch 75 - Batch (70/363) - Mini-batch Training loss: 0.4020 - Training Acc 1: 0.17
Epoch 75 - Batch (80/363) - Mini-batch Training loss: 0.3718 - Training Acc 1: 0.20
Epoch 75 - Batch (90/363) - Mini-batch Training loss: 0.3643 - Training Acc 1: 0.22
Epoch 75 - Batch (100/363) - Mini-batch Training loss: 0.3630 - Training Acc 1: 0.25
Epoch 75 - Batch (110/363) - Mini-batch Training loss: 0.3479 - Training Acc 1: 0.27
Epoch 75 - Batch (120/363) - Mini-batch Training loss: 0.3393 - Training Acc 1: 0.30
Epoch 75 - Batch (130/363) - Mini-batch Training loss: 0.3321 - Training Acc 1: 0.33
Epoch 75 - Batch (140/363) - Mini-batch Training loss: 0.3236 - Training Acc 1: 0.35
Epoch 75 - Batch (150/363) - Mini-batch Training loss: 0.3096 - Training Acc 1: 0.38
Epoch 75 - Batch (160/363) - Mini-batch Training loss: 0.3077 - Training Acc 1: 0.40
Epoch 75 - Batch (170/363) - Mini-batch Training loss: 0.3029 - Training Acc 1: 0.43
Epoch 75 - Batch (180/363) - Mini-batch Training loss: 0.2896 - Training Acc 1: 0.45
Epoch 75 - Batch (190/363) - Mini-batch Training loss: 0.2943 - Training Acc 1: 0.48
Epoch 75 - Batch (200/363) - Mini-batch Training loss: 0.2983 - Training Acc 1: 0.50
Epoch 75 - Batch (210/363) - Mini-batch Training loss: 0.2888 - Training Acc 1: 0.53
Epoch 75 - Batch (220/363) - Mini-batch Training loss: 0.2860 - Training Acc 1: 0.56
Epoch 75 - Batch (230/363) - Mini-batch Training loss: 0.2821 - Training Acc 1: 0.58
Epoch 75 - Batch (240/363) - Mini-batch Training loss: 0.2871 - Training Acc 1: 0.61
Epoch 75 - Batch (250/363) - Mini-batch Training loss: 0.2863 - Training Acc 1: 0.63
Epoch 75 - Batch (260/363) - Mini-batch Training loss: 0.2800 - Training Acc 1: 0.66
Epoch 75 - Batch (270/363) - Mini-batch Training loss: 0.2748 - Training Acc 1: 0.69
Epoch 75 - Batch (280/363) - Mini-batch Training loss: 0.2749 - Training Acc 1: 0.71
Epoch 75 - Batch (290/363) - Mini-batch Training loss: 0.2828 - Training Acc 1: 0.73
Epoch 75 - Batch (300/363) - Mini-batch Training loss: 0.2929 - Training Acc 1: 0.75
Epoch 75 - Batch (310/363) - Mini-batch Training loss: 0.2903 - Training Acc 1: 0.78
Epoch 75 - Batch (320/363) - Mini-batch Training loss: 0.2838 - Training Acc 1: 0.81
Epoch 75 - Batch (330/363) - Mini-batch Training loss: 0.2815 - Training Acc 1: 0.83
Epoch 75 - Batch (340/363) - Mini-batch Training loss: 0.2850 - Training Acc 1: 0.85
Epoch 75 - Batch (350/363) - Mini-batch Training loss: 0.2870 - Training Acc 1: 0.88
Epoch 75 - Batch (360/363) - Mini-batch Training loss: 0.2917 - Training Acc 1: 0.90
Epoch 75 - Full-batch Training loss: 0.2903 - Training Acc 1: 0.91
Validation set: Average loss: 0.7132, Accuracy: 301.0/363 (83%)

Epoch 76 - Batch (0/363) - Mini-batch Training loss: 0.0824 - Training Acc 1: 0.00
Epoch 76 - Batch (10/363) - Mini-batch Training loss: 0.4475 - Training Acc 1: 0.03
Epoch 76 - Batch (20/363) - Mini-batch Training loss: 0.3368 - Training Acc 1: 0.05
Epoch 76 - Batch (30/363) - Mini-batch Training loss: 0.3602 - Training Acc 1: 0.08
Epoch 76 - Batch (40/363) - Mini-batch Training loss: 0.3367 - Training Acc 1: 0.10
Epoch 76 - Batch (50/363) - Mini-batch Training loss: 0.3928 - Training Acc 1: 0.12
Epoch 76 - Batch (60/363) - Mini-batch Training loss: 0.3758 - Training Acc 1: 0.15
Epoch 76 - Batch (70/363) - Mini-batch Training loss: 0.3612 - Training Acc 1: 0.17
Epoch 76 - Batch (80/363) - Mini-batch Training loss: 0.3362 - Training Acc 1: 0.20
Epoch 76 - Batch (90/363) - Mini-batch Training loss: 0.3140 - Training Acc 1: 0.22
Epoch 76 - Batch (100/363) - Mini-batch Training loss: 0.3081 - Training Acc 1: 0.25
Epoch 76 - Batch (110/363) - Mini-batch Training loss: 0.2999 - Training Acc 1: 0.27
Epoch 76 - Batch (120/363) - Mini-batch Training loss: 0.3101 - Training Acc 1: 0.30
Epoch 76 - Batch (130/363) - Mini-batch Training loss: 0.3039 - Training Acc 1: 0.32
Epoch 76 - Batch (140/363) - Mini-batch Training loss: 0.2984 - Training Acc 1: 0.35
Epoch 76 - Batch (150/363) - Mini-batch Training loss: 0.3071 - Training Acc 1: 0.37
Epoch 76 - Batch (160/363) - Mini-batch Training loss: 0.2955 - Training Acc 1: 0.40
Epoch 76 - Batch (170/363) - Mini-batch Training loss: 0.2979 - Training Acc 1: 0.42
Epoch 76 - Batch (180/363) - Mini-batch Training loss: 0.2951 - Training Acc 1: 0.45
Epoch 76 - Batch (190/363) - Mini-batch Training loss: 0.2933 - Training Acc 1: 0.47
Epoch 76 - Batch (200/363) - Mini-batch Training loss: 0.2921 - Training Acc 1: 0.50
Epoch 76 - Batch (210/363) - Mini-batch Training loss: 0.2922 - Training Acc 1: 0.52
Epoch 76 - Batch (220/363) - Mini-batch Training loss: 0.2955 - Training Acc 1: 0.55
Epoch 76 - Batch (230/363) - Mini-batch Training loss: 0.2902 - Training Acc 1: 0.57
Epoch 76 - Batch (240/363) - Mini-batch Training loss: 0.2931 - Training Acc 1: 0.60
Epoch 76 - Batch (250/363) - Mini-batch Training loss: 0.2934 - Training Acc 1: 0.62
Epoch 76 - Batch (260/363) - Mini-batch Training loss: 0.2958 - Training Acc 1: 0.65
Epoch 76 - Batch (270/363) - Mini-batch Training loss: 0.2985 - Training Acc 1: 0.67
Epoch 76 - Batch (280/363) - Mini-batch Training loss: 0.2948 - Training Acc 1: 0.70
Epoch 76 - Batch (290/363) - Mini-batch Training loss: 0.2947 - Training Acc 1: 0.72
Epoch 76 - Batch (300/363) - Mini-batch Training loss: 0.3024 - Training Acc 1: 0.75
Epoch 76 - Batch (310/363) - Mini-batch Training loss: 0.2978 - Training Acc 1: 0.77
Epoch 76 - Batch (320/363) - Mini-batch Training loss: 0.2983 - Training Acc 1: 0.80
Epoch 76 - Batch (330/363) - Mini-batch Training loss: 0.3013 - Training Acc 1: 0.82
Epoch 76 - Batch (340/363) - Mini-batch Training loss: 0.3002 - Training Acc 1: 0.85
Epoch 76 - Batch (350/363) - Mini-batch Training loss: 0.2948 - Training Acc 1: 0.87
Epoch 76 - Batch (360/363) - Mini-batch Training loss: 0.2944 - Training Acc 1: 0.90
Epoch 76 - Full-batch Training loss: 0.3011 - Training Acc 1: 0.90
Validation set: Average loss: 0.6535, Accuracy: 293.0/363 (81%)

Epoch 77 - Batch (0/363) - Mini-batch Training loss: 0.2488 - Training Acc 1: 0.00
Epoch 77 - Batch (10/363) - Mini-batch Training loss: 1.1163 - Training Acc 1: 0.02
Epoch 77 - Batch (20/363) - Mini-batch Training loss: 0.9395 - Training Acc 1: 0.04
Epoch 77 - Batch (30/363) - Mini-batch Training loss: 0.9030 - Training Acc 1: 0.06
Epoch 77 - Batch (40/363) - Mini-batch Training loss: 0.7804 - Training Acc 1: 0.08
Epoch 77 - Batch (50/363) - Mini-batch Training loss: 0.6922 - Training Acc 1: 0.11
Epoch 77 - Batch (60/363) - Mini-batch Training loss: 0.6258 - Training Acc 1: 0.13
Epoch 77 - Batch (70/363) - Mini-batch Training loss: 0.5700 - Training Acc 1: 0.16
Epoch 77 - Batch (80/363) - Mini-batch Training loss: 0.5206 - Training Acc 1: 0.18
Epoch 77 - Batch (90/363) - Mini-batch Training loss: 0.4891 - Training Acc 1: 0.21
Epoch 77 - Batch (100/363) - Mini-batch Training loss: 0.4822 - Training Acc 1: 0.23
Epoch 77 - Batch (110/363) - Mini-batch Training loss: 0.4589 - Training Acc 1: 0.26
Epoch 77 - Batch (120/363) - Mini-batch Training loss: 0.4365 - Training Acc 1: 0.28
Epoch 77 - Batch (130/363) - Mini-batch Training loss: 0.4363 - Training Acc 1: 0.31
Epoch 77 - Batch (140/363) - Mini-batch Training loss: 0.4235 - Training Acc 1: 0.33
Epoch 77 - Batch (150/363) - Mini-batch Training loss: 0.4148 - Training Acc 1: 0.36
Epoch 77 - Batch (160/363) - Mini-batch Training loss: 0.4027 - Training Acc 1: 0.38
Epoch 77 - Batch (170/363) - Mini-batch Training loss: 0.3945 - Training Acc 1: 0.41
Epoch 77 - Batch (180/363) - Mini-batch Training loss: 0.3832 - Training Acc 1: 0.43
Epoch 77 - Batch (190/363) - Mini-batch Training loss: 0.3721 - Training Acc 1: 0.46
Epoch 77 - Batch (200/363) - Mini-batch Training loss: 0.3602 - Training Acc 1: 0.49
Epoch 77 - Batch (210/363) - Mini-batch Training loss: 0.3501 - Training Acc 1: 0.51
Epoch 77 - Batch (220/363) - Mini-batch Training loss: 0.3398 - Training Acc 1: 0.54
Epoch 77 - Batch (230/363) - Mini-batch Training loss: 0.3407 - Training Acc 1: 0.56
Epoch 77 - Batch (240/363) - Mini-batch Training loss: 0.3385 - Training Acc 1: 0.59
Epoch 77 - Batch (250/363) - Mini-batch Training loss: 0.3381 - Training Acc 1: 0.61
Epoch 77 - Batch (260/363) - Mini-batch Training loss: 0.3351 - Training Acc 1: 0.64
Epoch 77 - Batch (270/363) - Mini-batch Training loss: 0.3322 - Training Acc 1: 0.66
Epoch 77 - Batch (280/363) - Mini-batch Training loss: 0.3303 - Training Acc 1: 0.69
Epoch 77 - Batch (290/363) - Mini-batch Training loss: 0.3282 - Training Acc 1: 0.71
Epoch 77 - Batch (300/363) - Mini-batch Training loss: 0.3288 - Training Acc 1: 0.73
Epoch 77 - Batch (310/363) - Mini-batch Training loss: 0.3305 - Training Acc 1: 0.76
Epoch 77 - Batch (320/363) - Mini-batch Training loss: 0.3336 - Training Acc 1: 0.78
Epoch 77 - Batch (330/363) - Mini-batch Training loss: 0.3376 - Training Acc 1: 0.81
Epoch 77 - Batch (340/363) - Mini-batch Training loss: 0.3352 - Training Acc 1: 0.83
Epoch 77 - Batch (350/363) - Mini-batch Training loss: 0.3398 - Training Acc 1: 0.85
Epoch 77 - Batch (360/363) - Mini-batch Training loss: 0.3418 - Training Acc 1: 0.88
Epoch 77 - Full-batch Training loss: 0.3408 - Training Acc 1: 0.88
Validation set: Average loss: 0.7192, Accuracy: 301.0/363 (83%)

Epoch 78 - Batch (0/363) - Mini-batch Training loss: 0.0852 - Training Acc 1: 0.00
Epoch 78 - Batch (10/363) - Mini-batch Training loss: 0.1863 - Training Acc 1: 0.03
Epoch 78 - Batch (20/363) - Mini-batch Training loss: 0.1943 - Training Acc 1: 0.06
Epoch 78 - Batch (30/363) - Mini-batch Training loss: 0.1776 - Training Acc 1: 0.08
Epoch 78 - Batch (40/363) - Mini-batch Training loss: 0.1754 - Training Acc 1: 0.11
Epoch 78 - Batch (50/363) - Mini-batch Training loss: 0.2321 - Training Acc 1: 0.13
Epoch 78 - Batch (60/363) - Mini-batch Training loss: 0.2509 - Training Acc 1: 0.16
Epoch 78 - Batch (70/363) - Mini-batch Training loss: 0.2470 - Training Acc 1: 0.18
Epoch 78 - Batch (80/363) - Mini-batch Training loss: 0.2518 - Training Acc 1: 0.21
Epoch 78 - Batch (90/363) - Mini-batch Training loss: 0.2517 - Training Acc 1: 0.23
Epoch 78 - Batch (100/363) - Mini-batch Training loss: 0.2521 - Training Acc 1: 0.26
Epoch 78 - Batch (110/363) - Mini-batch Training loss: 0.2443 - Training Acc 1: 0.28
Epoch 78 - Batch (120/363) - Mini-batch Training loss: 0.2592 - Training Acc 1: 0.31
Epoch 78 - Batch (130/363) - Mini-batch Training loss: 0.2558 - Training Acc 1: 0.33
Epoch 78 - Batch (140/363) - Mini-batch Training loss: 0.2549 - Training Acc 1: 0.36
Epoch 78 - Batch (150/363) - Mini-batch Training loss: 0.2479 - Training Acc 1: 0.38
Epoch 78 - Batch (160/363) - Mini-batch Training loss: 0.2561 - Training Acc 1: 0.41
Epoch 78 - Batch (170/363) - Mini-batch Training loss: 0.2535 - Training Acc 1: 0.43
Epoch 78 - Batch (180/363) - Mini-batch Training loss: 0.2668 - Training Acc 1: 0.46
Epoch 78 - Batch (190/363) - Mini-batch Training loss: 0.2659 - Training Acc 1: 0.48
Epoch 78 - Batch (200/363) - Mini-batch Training loss: 0.2635 - Training Acc 1: 0.51
Epoch 78 - Batch (210/363) - Mini-batch Training loss: 0.2767 - Training Acc 1: 0.53
Epoch 78 - Batch (220/363) - Mini-batch Training loss: 0.2861 - Training Acc 1: 0.55
Epoch 78 - Batch (230/363) - Mini-batch Training loss: 0.2906 - Training Acc 1: 0.58
Epoch 78 - Batch (240/363) - Mini-batch Training loss: 0.2854 - Training Acc 1: 0.60
Epoch 78 - Batch (250/363) - Mini-batch Training loss: 0.2844 - Training Acc 1: 0.63
Epoch 78 - Batch (260/363) - Mini-batch Training loss: 0.2834 - Training Acc 1: 0.65
Epoch 78 - Batch (270/363) - Mini-batch Training loss: 0.2796 - Training Acc 1: 0.68
Epoch 78 - Batch (280/363) - Mini-batch Training loss: 0.2819 - Training Acc 1: 0.70
Epoch 78 - Batch (290/363) - Mini-batch Training loss: 0.2795 - Training Acc 1: 0.73
Epoch 78 - Batch (300/363) - Mini-batch Training loss: 0.2846 - Training Acc 1: 0.75
Epoch 78 - Batch (310/363) - Mini-batch Training loss: 0.2888 - Training Acc 1: 0.78
Epoch 78 - Batch (320/363) - Mini-batch Training loss: 0.2889 - Training Acc 1: 0.80
Epoch 78 - Batch (330/363) - Mini-batch Training loss: 0.2923 - Training Acc 1: 0.82
Epoch 78 - Batch (340/363) - Mini-batch Training loss: 0.2904 - Training Acc 1: 0.85
Epoch 78 - Batch (350/363) - Mini-batch Training loss: 0.2953 - Training Acc 1: 0.87
Epoch 78 - Batch (360/363) - Mini-batch Training loss: 0.2964 - Training Acc 1: 0.90
Epoch 78 - Full-batch Training loss: 0.2950 - Training Acc 1: 0.90
Validation set: Average loss: 0.7812, Accuracy: 292.0/363 (80%)

Epoch 79 - Batch (0/363) - Mini-batch Training loss: 0.1774 - Training Acc 1: 0.00
Epoch 79 - Batch (10/363) - Mini-batch Training loss: 0.3324 - Training Acc 1: 0.03
Epoch 79 - Batch (20/363) - Mini-batch Training loss: 0.2277 - Training Acc 1: 0.05
Epoch 79 - Batch (30/363) - Mini-batch Training loss: 0.2355 - Training Acc 1: 0.08
Epoch 79 - Batch (40/363) - Mini-batch Training loss: 0.2327 - Training Acc 1: 0.10
Epoch 79 - Batch (50/363) - Mini-batch Training loss: 0.2562 - Training Acc 1: 0.13
Epoch 79 - Batch (60/363) - Mini-batch Training loss: 0.2373 - Training Acc 1: 0.16
Epoch 79 - Batch (70/363) - Mini-batch Training loss: 0.2419 - Training Acc 1: 0.18
Epoch 79 - Batch (80/363) - Mini-batch Training loss: 0.2326 - Training Acc 1: 0.21
Epoch 79 - Batch (90/363) - Mini-batch Training loss: 0.2255 - Training Acc 1: 0.23
Epoch 79 - Batch (100/363) - Mini-batch Training loss: 0.2310 - Training Acc 1: 0.26
Epoch 79 - Batch (110/363) - Mini-batch Training loss: 0.2259 - Training Acc 1: 0.29
Epoch 79 - Batch (120/363) - Mini-batch Training loss: 0.2464 - Training Acc 1: 0.31
Epoch 79 - Batch (130/363) - Mini-batch Training loss: 0.2455 - Training Acc 1: 0.33
Epoch 79 - Batch (140/363) - Mini-batch Training loss: 0.2453 - Training Acc 1: 0.36
Epoch 79 - Batch (150/363) - Mini-batch Training loss: 0.2512 - Training Acc 1: 0.38
Epoch 79 - Batch (160/363) - Mini-batch Training loss: 0.2539 - Training Acc 1: 0.41
Epoch 79 - Batch (170/363) - Mini-batch Training loss: 0.2642 - Training Acc 1: 0.43
Epoch 79 - Batch (180/363) - Mini-batch Training loss: 0.2580 - Training Acc 1: 0.46
Epoch 79 - Batch (190/363) - Mini-batch Training loss: 0.2637 - Training Acc 1: 0.48
Epoch 79 - Batch (200/363) - Mini-batch Training loss: 0.2589 - Training Acc 1: 0.51
Epoch 79 - Batch (210/363) - Mini-batch Training loss: 0.2563 - Training Acc 1: 0.54
Epoch 79 - Batch (220/363) - Mini-batch Training loss: 0.2557 - Training Acc 1: 0.56
Epoch 79 - Batch (230/363) - Mini-batch Training loss: 0.2588 - Training Acc 1: 0.59
Epoch 79 - Batch (240/363) - Mini-batch Training loss: 0.2605 - Training Acc 1: 0.61
Epoch 79 - Batch (250/363) - Mini-batch Training loss: 0.2578 - Training Acc 1: 0.64
Epoch 79 - Batch (260/363) - Mini-batch Training loss: 0.2548 - Training Acc 1: 0.66
Epoch 79 - Batch (270/363) - Mini-batch Training loss: 0.2560 - Training Acc 1: 0.69
Epoch 79 - Batch (280/363) - Mini-batch Training loss: 0.2613 - Training Acc 1: 0.71
Epoch 79 - Batch (290/363) - Mini-batch Training loss: 0.2618 - Training Acc 1: 0.73
Epoch 79 - Batch (300/363) - Mini-batch Training loss: 0.2628 - Training Acc 1: 0.76
Epoch 79 - Batch (310/363) - Mini-batch Training loss: 0.2602 - Training Acc 1: 0.79
Epoch 79 - Batch (320/363) - Mini-batch Training loss: 0.2613 - Training Acc 1: 0.81
Epoch 79 - Batch (330/363) - Mini-batch Training loss: 0.2635 - Training Acc 1: 0.84
Epoch 79 - Batch (340/363) - Mini-batch Training loss: 0.2617 - Training Acc 1: 0.86
Epoch 79 - Batch (350/363) - Mini-batch Training loss: 0.2614 - Training Acc 1: 0.89
Epoch 79 - Batch (360/363) - Mini-batch Training loss: 0.2601 - Training Acc 1: 0.91
Epoch 79 - Full-batch Training loss: 0.2594 - Training Acc 1: 0.92
Validation set: Average loss: 0.7046, Accuracy: 295.0/363 (81%)

Epoch 80 - Batch (0/363) - Mini-batch Training loss: 0.6474 - Training Acc 1: 0.00
Epoch 80 - Batch (10/363) - Mini-batch Training loss: 0.3861 - Training Acc 1: 0.03
Epoch 80 - Batch (20/363) - Mini-batch Training loss: 0.3256 - Training Acc 1: 0.05
Epoch 80 - Batch (30/363) - Mini-batch Training loss: 0.2894 - Training Acc 1: 0.08
Epoch 80 - Batch (40/363) - Mini-batch Training loss: 0.2934 - Training Acc 1: 0.10
Epoch 80 - Batch (50/363) - Mini-batch Training loss: 0.2964 - Training Acc 1: 0.12
Epoch 80 - Batch (60/363) - Mini-batch Training loss: 0.3060 - Training Acc 1: 0.15
Epoch 80 - Batch (70/363) - Mini-batch Training loss: 0.2887 - Training Acc 1: 0.18
Epoch 80 - Batch (80/363) - Mini-batch Training loss: 0.2936 - Training Acc 1: 0.20
Epoch 80 - Batch (90/363) - Mini-batch Training loss: 0.2902 - Training Acc 1: 0.22
Epoch 80 - Batch (100/363) - Mini-batch Training loss: 0.3020 - Training Acc 1: 0.25
Epoch 80 - Batch (110/363) - Mini-batch Training loss: 0.3036 - Training Acc 1: 0.27
Epoch 80 - Batch (120/363) - Mini-batch Training loss: 0.3209 - Training Acc 1: 0.30
Epoch 80 - Batch (130/363) - Mini-batch Training loss: 0.3346 - Training Acc 1: 0.32
Epoch 80 - Batch (140/363) - Mini-batch Training loss: 0.3215 - Training Acc 1: 0.34
Epoch 80 - Batch (150/363) - Mini-batch Training loss: 0.3138 - Training Acc 1: 0.37
Epoch 80 - Batch (160/363) - Mini-batch Training loss: 0.3036 - Training Acc 1: 0.40
Epoch 80 - Batch (170/363) - Mini-batch Training loss: 0.2931 - Training Acc 1: 0.42
Epoch 80 - Batch (180/363) - Mini-batch Training loss: 0.2958 - Training Acc 1: 0.45
Epoch 80 - Batch (190/363) - Mini-batch Training loss: 0.3032 - Training Acc 1: 0.47
Epoch 80 - Batch (200/363) - Mini-batch Training loss: 0.3003 - Training Acc 1: 0.50
Epoch 80 - Batch (210/363) - Mini-batch Training loss: 0.2901 - Training Acc 1: 0.53
Epoch 80 - Batch (220/363) - Mini-batch Training loss: 0.2938 - Training Acc 1: 0.55
Epoch 80 - Batch (230/363) - Mini-batch Training loss: 0.2922 - Training Acc 1: 0.58
Epoch 80 - Batch (240/363) - Mini-batch Training loss: 0.2983 - Training Acc 1: 0.60
Epoch 80 - Batch (250/363) - Mini-batch Training loss: 0.3055 - Training Acc 1: 0.62
Epoch 80 - Batch (260/363) - Mini-batch Training loss: 0.2986 - Training Acc 1: 0.65
Epoch 80 - Batch (270/363) - Mini-batch Training loss: 0.2927 - Training Acc 1: 0.68
Epoch 80 - Batch (280/363) - Mini-batch Training loss: 0.2909 - Training Acc 1: 0.70
Epoch 80 - Batch (290/363) - Mini-batch Training loss: 0.2863 - Training Acc 1: 0.73
Epoch 80 - Batch (300/363) - Mini-batch Training loss: 0.2869 - Training Acc 1: 0.75
Epoch 80 - Batch (310/363) - Mini-batch Training loss: 0.2902 - Training Acc 1: 0.78
Epoch 80 - Batch (320/363) - Mini-batch Training loss: 0.2860 - Training Acc 1: 0.80
Epoch 80 - Batch (330/363) - Mini-batch Training loss: 0.2845 - Training Acc 1: 0.83
Epoch 80 - Batch (340/363) - Mini-batch Training loss: 0.2798 - Training Acc 1: 0.86
Epoch 80 - Batch (350/363) - Mini-batch Training loss: 0.2761 - Training Acc 1: 0.88
Epoch 80 - Batch (360/363) - Mini-batch Training loss: 0.2744 - Training Acc 1: 0.91
Epoch 80 - Full-batch Training loss: 0.2737 - Training Acc 1: 0.91
Validation set: Average loss: 0.6542, Accuracy: 301.0/363 (83%)

Epoch 81 - Batch (0/363) - Mini-batch Training loss: 0.2373 - Training Acc 1: 0.00
Epoch 81 - Batch (10/363) - Mini-batch Training loss: 0.1472 - Training Acc 1: 0.03
Epoch 81 - Batch (20/363) - Mini-batch Training loss: 0.1376 - Training Acc 1: 0.06
Epoch 81 - Batch (30/363) - Mini-batch Training loss: 0.1113 - Training Acc 1: 0.08
Epoch 81 - Batch (40/363) - Mini-batch Training loss: 0.1546 - Training Acc 1: 0.11
Epoch 81 - Batch (50/363) - Mini-batch Training loss: 0.1761 - Training Acc 1: 0.13
Epoch 81 - Batch (60/363) - Mini-batch Training loss: 0.1757 - Training Acc 1: 0.16
Epoch 81 - Batch (70/363) - Mini-batch Training loss: 0.1810 - Training Acc 1: 0.19
Epoch 81 - Batch (80/363) - Mini-batch Training loss: 0.1713 - Training Acc 1: 0.21
Epoch 81 - Batch (90/363) - Mini-batch Training loss: 0.2016 - Training Acc 1: 0.24
Epoch 81 - Batch (100/363) - Mini-batch Training loss: 0.2108 - Training Acc 1: 0.26
Epoch 81 - Batch (110/363) - Mini-batch Training loss: 0.2001 - Training Acc 1: 0.29
Epoch 81 - Batch (120/363) - Mini-batch Training loss: 0.2012 - Training Acc 1: 0.31
Epoch 81 - Batch (130/363) - Mini-batch Training loss: 0.2213 - Training Acc 1: 0.34
Epoch 81 - Batch (140/363) - Mini-batch Training loss: 0.2245 - Training Acc 1: 0.36
Epoch 81 - Batch (150/363) - Mini-batch Training loss: 0.2189 - Training Acc 1: 0.39
Epoch 81 - Batch (160/363) - Mini-batch Training loss: 0.2219 - Training Acc 1: 0.41
Epoch 81 - Batch (170/363) - Mini-batch Training loss: 0.2237 - Training Acc 1: 0.44
Epoch 81 - Batch (180/363) - Mini-batch Training loss: 0.2262 - Training Acc 1: 0.47
Epoch 81 - Batch (190/363) - Mini-batch Training loss: 0.2303 - Training Acc 1: 0.49
Epoch 81 - Batch (200/363) - Mini-batch Training loss: 0.2359 - Training Acc 1: 0.52
Epoch 81 - Batch (210/363) - Mini-batch Training loss: 0.2376 - Training Acc 1: 0.54
Epoch 81 - Batch (220/363) - Mini-batch Training loss: 0.2526 - Training Acc 1: 0.56
Epoch 81 - Batch (230/363) - Mini-batch Training loss: 0.2489 - Training Acc 1: 0.59
Epoch 81 - Batch (240/363) - Mini-batch Training loss: 0.2655 - Training Acc 1: 0.61
Epoch 81 - Batch (250/363) - Mini-batch Training loss: 0.2644 - Training Acc 1: 0.64
Epoch 81 - Batch (260/363) - Mini-batch Training loss: 0.2666 - Training Acc 1: 0.66
Epoch 81 - Batch (270/363) - Mini-batch Training loss: 0.2677 - Training Acc 1: 0.69
Epoch 81 - Batch (280/363) - Mini-batch Training loss: 0.2728 - Training Acc 1: 0.71
Epoch 81 - Batch (290/363) - Mini-batch Training loss: 0.2688 - Training Acc 1: 0.74
Epoch 81 - Batch (300/363) - Mini-batch Training loss: 0.2654 - Training Acc 1: 0.76
Epoch 81 - Batch (310/363) - Mini-batch Training loss: 0.2646 - Training Acc 1: 0.79
Epoch 81 - Batch (320/363) - Mini-batch Training loss: 0.2660 - Training Acc 1: 0.81
Epoch 81 - Batch (330/363) - Mini-batch Training loss: 0.2654 - Training Acc 1: 0.84
Epoch 81 - Batch (340/363) - Mini-batch Training loss: 0.2611 - Training Acc 1: 0.87
Epoch 81 - Batch (350/363) - Mini-batch Training loss: 0.2611 - Training Acc 1: 0.89
Epoch 81 - Batch (360/363) - Mini-batch Training loss: 0.2624 - Training Acc 1: 0.92
Epoch 81 - Full-batch Training loss: 0.2614 - Training Acc 1: 0.92
Validation set: Average loss: 0.6690, Accuracy: 301.0/363 (83%)

Epoch 82 - Batch (0/363) - Mini-batch Training loss: 0.8662 - Training Acc 1: 0.00
Epoch 82 - Batch (10/363) - Mini-batch Training loss: 0.2695 - Training Acc 1: 0.03
Epoch 82 - Batch (20/363) - Mini-batch Training loss: 0.2863 - Training Acc 1: 0.05
Epoch 82 - Batch (30/363) - Mini-batch Training loss: 0.3236 - Training Acc 1: 0.08
Epoch 82 - Batch (40/363) - Mini-batch Training loss: 0.2857 - Training Acc 1: 0.10
Epoch 82 - Batch (50/363) - Mini-batch Training loss: 0.2988 - Training Acc 1: 0.13
Epoch 82 - Batch (60/363) - Mini-batch Training loss: 0.2692 - Training Acc 1: 0.15
Epoch 82 - Batch (70/363) - Mini-batch Training loss: 0.2813 - Training Acc 1: 0.18
Epoch 82 - Batch (80/363) - Mini-batch Training loss: 0.2788 - Training Acc 1: 0.20
Epoch 82 - Batch (90/363) - Mini-batch Training loss: 0.2922 - Training Acc 1: 0.23
Epoch 82 - Batch (100/363) - Mini-batch Training loss: 0.2899 - Training Acc 1: 0.26
Epoch 82 - Batch (110/363) - Mini-batch Training loss: 0.2833 - Training Acc 1: 0.28
Epoch 82 - Batch (120/363) - Mini-batch Training loss: 0.2854 - Training Acc 1: 0.30
Epoch 82 - Batch (130/363) - Mini-batch Training loss: 0.3354 - Training Acc 1: 0.32
Epoch 82 - Batch (140/363) - Mini-batch Training loss: 0.3611 - Training Acc 1: 0.34
Epoch 82 - Batch (150/363) - Mini-batch Training loss: 0.3621 - Training Acc 1: 0.37
Epoch 82 - Batch (160/363) - Mini-batch Training loss: 0.3569 - Training Acc 1: 0.39
Epoch 82 - Batch (170/363) - Mini-batch Training loss: 0.3656 - Training Acc 1: 0.41
Epoch 82 - Batch (180/363) - Mini-batch Training loss: 0.3527 - Training Acc 1: 0.44
Epoch 82 - Batch (190/363) - Mini-batch Training loss: 0.3448 - Training Acc 1: 0.47
Epoch 82 - Batch (200/363) - Mini-batch Training loss: 0.3367 - Training Acc 1: 0.49
Epoch 82 - Batch (210/363) - Mini-batch Training loss: 0.3304 - Training Acc 1: 0.52
Epoch 82 - Batch (220/363) - Mini-batch Training loss: 0.3264 - Training Acc 1: 0.55
Epoch 82 - Batch (230/363) - Mini-batch Training loss: 0.3188 - Training Acc 1: 0.57
Epoch 82 - Batch (240/363) - Mini-batch Training loss: 0.3129 - Training Acc 1: 0.60
Epoch 82 - Batch (250/363) - Mini-batch Training loss: 0.3052 - Training Acc 1: 0.63
Epoch 82 - Batch (260/363) - Mini-batch Training loss: 0.3089 - Training Acc 1: 0.65
Epoch 82 - Batch (270/363) - Mini-batch Training loss: 0.3078 - Training Acc 1: 0.68
Epoch 82 - Batch (280/363) - Mini-batch Training loss: 0.3027 - Training Acc 1: 0.70
Epoch 82 - Batch (290/363) - Mini-batch Training loss: 0.2960 - Training Acc 1: 0.73
Epoch 82 - Batch (300/363) - Mini-batch Training loss: 0.2902 - Training Acc 1: 0.76
Epoch 82 - Batch (310/363) - Mini-batch Training loss: 0.2874 - Training Acc 1: 0.78
Epoch 82 - Batch (320/363) - Mini-batch Training loss: 0.2836 - Training Acc 1: 0.81
Epoch 82 - Batch (330/363) - Mini-batch Training loss: 0.2866 - Training Acc 1: 0.83
Epoch 82 - Batch (340/363) - Mini-batch Training loss: 0.2849 - Training Acc 1: 0.86
Epoch 82 - Batch (350/363) - Mini-batch Training loss: 0.2862 - Training Acc 1: 0.88
Epoch 82 - Batch (360/363) - Mini-batch Training loss: 0.2859 - Training Acc 1: 0.91
Epoch 82 - Full-batch Training loss: 0.2850 - Training Acc 1: 0.91
Validation set: Average loss: 0.6887, Accuracy: 294.0/363 (81%)

Epoch 83 - Batch (0/363) - Mini-batch Training loss: 0.0224 - Training Acc 1: 0.00
Epoch 83 - Batch (10/363) - Mini-batch Training loss: 0.2355 - Training Acc 1: 0.03
Epoch 83 - Batch (20/363) - Mini-batch Training loss: 0.2328 - Training Acc 1: 0.05
Epoch 83 - Batch (30/363) - Mini-batch Training loss: 0.1825 - Training Acc 1: 0.08
Epoch 83 - Batch (40/363) - Mini-batch Training loss: 0.2248 - Training Acc 1: 0.11
Epoch 83 - Batch (50/363) - Mini-batch Training loss: 0.2293 - Training Acc 1: 0.13
Epoch 83 - Batch (60/363) - Mini-batch Training loss: 0.2418 - Training Acc 1: 0.16
Epoch 83 - Batch (70/363) - Mini-batch Training loss: 0.2421 - Training Acc 1: 0.18
Epoch 83 - Batch (80/363) - Mini-batch Training loss: 0.2761 - Training Acc 1: 0.21
Epoch 83 - Batch (90/363) - Mini-batch Training loss: 0.2571 - Training Acc 1: 0.23
Epoch 83 - Batch (100/363) - Mini-batch Training loss: 0.2530 - Training Acc 1: 0.26
Epoch 83 - Batch (110/363) - Mini-batch Training loss: 0.2403 - Training Acc 1: 0.29
Epoch 83 - Batch (120/363) - Mini-batch Training loss: 0.2333 - Training Acc 1: 0.31
Epoch 83 - Batch (130/363) - Mini-batch Training loss: 0.2316 - Training Acc 1: 0.34
Epoch 83 - Batch (140/363) - Mini-batch Training loss: 0.2519 - Training Acc 1: 0.36
Epoch 83 - Batch (150/363) - Mini-batch Training loss: 0.2491 - Training Acc 1: 0.39
Epoch 83 - Batch (160/363) - Mini-batch Training loss: 0.2505 - Training Acc 1: 0.41
Epoch 83 - Batch (170/363) - Mini-batch Training loss: 0.2513 - Training Acc 1: 0.44
Epoch 83 - Batch (180/363) - Mini-batch Training loss: 0.2547 - Training Acc 1: 0.46
Epoch 83 - Batch (190/363) - Mini-batch Training loss: 0.2470 - Training Acc 1: 0.49
Epoch 83 - Batch (200/363) - Mini-batch Training loss: 0.2540 - Training Acc 1: 0.51
Epoch 83 - Batch (210/363) - Mini-batch Training loss: 0.2528 - Training Acc 1: 0.54
Epoch 83 - Batch (220/363) - Mini-batch Training loss: 0.2469 - Training Acc 1: 0.57
Epoch 83 - Batch (230/363) - Mini-batch Training loss: 0.2485 - Training Acc 1: 0.59
Epoch 83 - Batch (240/363) - Mini-batch Training loss: 0.2474 - Training Acc 1: 0.62
Epoch 83 - Batch (250/363) - Mini-batch Training loss: 0.2549 - Training Acc 1: 0.64
Epoch 83 - Batch (260/363) - Mini-batch Training loss: 0.2595 - Training Acc 1: 0.67
Epoch 83 - Batch (270/363) - Mini-batch Training loss: 0.2633 - Training Acc 1: 0.69
Epoch 83 - Batch (280/363) - Mini-batch Training loss: 0.2748 - Training Acc 1: 0.71
Epoch 83 - Batch (290/363) - Mini-batch Training loss: 0.2816 - Training Acc 1: 0.74
Epoch 83 - Batch (300/363) - Mini-batch Training loss: 0.2836 - Training Acc 1: 0.76
Epoch 83 - Batch (310/363) - Mini-batch Training loss: 0.2814 - Training Acc 1: 0.79
Epoch 83 - Batch (320/363) - Mini-batch Training loss: 0.2887 - Training Acc 1: 0.81
Epoch 83 - Batch (330/363) - Mini-batch Training loss: 0.2871 - Training Acc 1: 0.84
Epoch 83 - Batch (340/363) - Mini-batch Training loss: 0.2853 - Training Acc 1: 0.86
Epoch 83 - Batch (350/363) - Mini-batch Training loss: 0.2835 - Training Acc 1: 0.89
Epoch 83 - Batch (360/363) - Mini-batch Training loss: 0.2841 - Training Acc 1: 0.91
Epoch 83 - Full-batch Training loss: 0.2836 - Training Acc 1: 0.92
Validation set: Average loss: 0.6537, Accuracy: 299.0/363 (82%)

Epoch 84 - Batch (0/363) - Mini-batch Training loss: 0.2161 - Training Acc 1: 0.00
Epoch 84 - Batch (10/363) - Mini-batch Training loss: 0.3161 - Training Acc 1: 0.03
Epoch 84 - Batch (20/363) - Mini-batch Training loss: 0.2486 - Training Acc 1: 0.05
Epoch 84 - Batch (30/363) - Mini-batch Training loss: 0.2717 - Training Acc 1: 0.08
Epoch 84 - Batch (40/363) - Mini-batch Training loss: 0.2711 - Training Acc 1: 0.10
Epoch 84 - Batch (50/363) - Mini-batch Training loss: 0.2610 - Training Acc 1: 0.13
Epoch 84 - Batch (60/363) - Mini-batch Training loss: 0.2688 - Training Acc 1: 0.15
Epoch 84 - Batch (70/363) - Mini-batch Training loss: 0.2838 - Training Acc 1: 0.18
Epoch 84 - Batch (80/363) - Mini-batch Training loss: 0.2614 - Training Acc 1: 0.20
Epoch 84 - Batch (90/363) - Mini-batch Training loss: 0.2526 - Training Acc 1: 0.23
Epoch 84 - Batch (100/363) - Mini-batch Training loss: 0.2498 - Training Acc 1: 0.26
Epoch 84 - Batch (110/363) - Mini-batch Training loss: 0.2407 - Training Acc 1: 0.28
Epoch 84 - Batch (120/363) - Mini-batch Training loss: 0.2748 - Training Acc 1: 0.30
Epoch 84 - Batch (130/363) - Mini-batch Training loss: 0.2762 - Training Acc 1: 0.33
Epoch 84 - Batch (140/363) - Mini-batch Training loss: 0.2725 - Training Acc 1: 0.35
Epoch 84 - Batch (150/363) - Mini-batch Training loss: 0.2656 - Training Acc 1: 0.38
Epoch 84 - Batch (160/363) - Mini-batch Training loss: 0.2609 - Training Acc 1: 0.41
Epoch 84 - Batch (170/363) - Mini-batch Training loss: 0.2609 - Training Acc 1: 0.43
Epoch 84 - Batch (180/363) - Mini-batch Training loss: 0.2598 - Training Acc 1: 0.46
Epoch 84 - Batch (190/363) - Mini-batch Training loss: 0.2526 - Training Acc 1: 0.48
Epoch 84 - Batch (200/363) - Mini-batch Training loss: 0.2509 - Training Acc 1: 0.51
Epoch 84 - Batch (210/363) - Mini-batch Training loss: 0.2516 - Training Acc 1: 0.54
Epoch 84 - Batch (220/363) - Mini-batch Training loss: 0.2541 - Training Acc 1: 0.56
Epoch 84 - Batch (230/363) - Mini-batch Training loss: 0.2526 - Training Acc 1: 0.59
Epoch 84 - Batch (240/363) - Mini-batch Training loss: 0.2562 - Training Acc 1: 0.61
Epoch 84 - Batch (250/363) - Mini-batch Training loss: 0.2581 - Training Acc 1: 0.63
Epoch 84 - Batch (260/363) - Mini-batch Training loss: 0.2587 - Training Acc 1: 0.66
Epoch 84 - Batch (270/363) - Mini-batch Training loss: 0.2541 - Training Acc 1: 0.69
Epoch 84 - Batch (280/363) - Mini-batch Training loss: 0.2517 - Training Acc 1: 0.71
Epoch 84 - Batch (290/363) - Mini-batch Training loss: 0.2511 - Training Acc 1: 0.74
Epoch 84 - Batch (300/363) - Mini-batch Training loss: 0.2454 - Training Acc 1: 0.76
Epoch 84 - Batch (310/363) - Mini-batch Training loss: 0.2425 - Training Acc 1: 0.79
Epoch 84 - Batch (320/363) - Mini-batch Training loss: 0.2448 - Training Acc 1: 0.81
Epoch 84 - Batch (330/363) - Mini-batch Training loss: 0.2442 - Training Acc 1: 0.84
Epoch 84 - Batch (340/363) - Mini-batch Training loss: 0.2421 - Training Acc 1: 0.87
Epoch 84 - Batch (350/363) - Mini-batch Training loss: 0.2412 - Training Acc 1: 0.89
Epoch 84 - Batch (360/363) - Mini-batch Training loss: 0.2412 - Training Acc 1: 0.92
Epoch 84 - Full-batch Training loss: 0.2412 - Training Acc 1: 0.92
Validation set: Average loss: 0.6410, Accuracy: 303.0/363 (83%)

Epoch 85 - Batch (0/363) - Mini-batch Training loss: 0.1090 - Training Acc 1: 0.00
Epoch 85 - Batch (10/363) - Mini-batch Training loss: 0.1806 - Training Acc 1: 0.03
Epoch 85 - Batch (20/363) - Mini-batch Training loss: 0.2285 - Training Acc 1: 0.05
Epoch 85 - Batch (30/363) - Mini-batch Training loss: 0.2292 - Training Acc 1: 0.08
Epoch 85 - Batch (40/363) - Mini-batch Training loss: 0.2003 - Training Acc 1: 0.11
Epoch 85 - Batch (50/363) - Mini-batch Training loss: 0.2243 - Training Acc 1: 0.13
Epoch 85 - Batch (60/363) - Mini-batch Training loss: 0.2083 - Training Acc 1: 0.16
Epoch 85 - Batch (70/363) - Mini-batch Training loss: 0.2193 - Training Acc 1: 0.18
Epoch 85 - Batch (80/363) - Mini-batch Training loss: 0.2172 - Training Acc 1: 0.21
Epoch 85 - Batch (90/363) - Mini-batch Training loss: 0.2248 - Training Acc 1: 0.23
Epoch 85 - Batch (100/363) - Mini-batch Training loss: 0.2295 - Training Acc 1: 0.26
Epoch 85 - Batch (110/363) - Mini-batch Training loss: 0.2616 - Training Acc 1: 0.28
Epoch 85 - Batch (120/363) - Mini-batch Training loss: 0.2621 - Training Acc 1: 0.30
Epoch 85 - Batch (130/363) - Mini-batch Training loss: 0.2540 - Training Acc 1: 0.33
Epoch 85 - Batch (140/363) - Mini-batch Training loss: 0.2505 - Training Acc 1: 0.36
Epoch 85 - Batch (150/363) - Mini-batch Training loss: 0.2457 - Training Acc 1: 0.38
Epoch 85 - Batch (160/363) - Mini-batch Training loss: 0.2602 - Training Acc 1: 0.41
Epoch 85 - Batch (170/363) - Mini-batch Training loss: 0.2699 - Training Acc 1: 0.43
Epoch 85 - Batch (180/363) - Mini-batch Training loss: 0.2680 - Training Acc 1: 0.46
Epoch 85 - Batch (190/363) - Mini-batch Training loss: 0.2585 - Training Acc 1: 0.49
Epoch 85 - Batch (200/363) - Mini-batch Training loss: 0.2596 - Training Acc 1: 0.51
Epoch 85 - Batch (210/363) - Mini-batch Training loss: 0.2642 - Training Acc 1: 0.53
Epoch 85 - Batch (220/363) - Mini-batch Training loss: 0.2574 - Training Acc 1: 0.56
Epoch 85 - Batch (230/363) - Mini-batch Training loss: 0.2576 - Training Acc 1: 0.59
Epoch 85 - Batch (240/363) - Mini-batch Training loss: 0.2582 - Training Acc 1: 0.61
Epoch 85 - Batch (250/363) - Mini-batch Training loss: 0.2595 - Training Acc 1: 0.64
Epoch 85 - Batch (260/363) - Mini-batch Training loss: 0.2664 - Training Acc 1: 0.66
Epoch 85 - Batch (270/363) - Mini-batch Training loss: 0.2673 - Training Acc 1: 0.68
Epoch 85 - Batch (280/363) - Mini-batch Training loss: 0.2634 - Training Acc 1: 0.71
Epoch 85 - Batch (290/363) - Mini-batch Training loss: 0.2586 - Training Acc 1: 0.74
Epoch 85 - Batch (300/363) - Mini-batch Training loss: 0.2611 - Training Acc 1: 0.76
Epoch 85 - Batch (310/363) - Mini-batch Training loss: 0.2686 - Training Acc 1: 0.79
Epoch 85 - Batch (320/363) - Mini-batch Training loss: 0.2727 - Training Acc 1: 0.81
Epoch 85 - Batch (330/363) - Mini-batch Training loss: 0.2710 - Training Acc 1: 0.84
Epoch 85 - Batch (340/363) - Mini-batch Training loss: 0.2693 - Training Acc 1: 0.86
Epoch 85 - Batch (350/363) - Mini-batch Training loss: 0.2654 - Training Acc 1: 0.89
Epoch 85 - Batch (360/363) - Mini-batch Training loss: 0.2626 - Training Acc 1: 0.92
Epoch 85 - Full-batch Training loss: 0.2613 - Training Acc 1: 0.92
Validation set: Average loss: 0.6480, Accuracy: 302.0/363 (83%)

Epoch 86 - Batch (0/363) - Mini-batch Training loss: 0.2523 - Training Acc 1: 0.00
Epoch 86 - Batch (10/363) - Mini-batch Training loss: 0.1494 - Training Acc 1: 0.03
Epoch 86 - Batch (20/363) - Mini-batch Training loss: 0.2922 - Training Acc 1: 0.05
Epoch 86 - Batch (30/363) - Mini-batch Training loss: 0.2869 - Training Acc 1: 0.08
Epoch 86 - Batch (40/363) - Mini-batch Training loss: 0.2456 - Training Acc 1: 0.10
Epoch 86 - Batch (50/363) - Mini-batch Training loss: 0.2476 - Training Acc 1: 0.13
Epoch 86 - Batch (60/363) - Mini-batch Training loss: 0.2544 - Training Acc 1: 0.16
Epoch 86 - Batch (70/363) - Mini-batch Training loss: 0.2712 - Training Acc 1: 0.18
Epoch 86 - Batch (80/363) - Mini-batch Training loss: 0.2566 - Training Acc 1: 0.21
Epoch 86 - Batch (90/363) - Mini-batch Training loss: 0.2528 - Training Acc 1: 0.23
Epoch 86 - Batch (100/363) - Mini-batch Training loss: 0.2493 - Training Acc 1: 0.26
Epoch 86 - Batch (110/363) - Mini-batch Training loss: 0.2576 - Training Acc 1: 0.28
Epoch 86 - Batch (120/363) - Mini-batch Training loss: 0.2643 - Training Acc 1: 0.31
Epoch 86 - Batch (130/363) - Mini-batch Training loss: 0.2583 - Training Acc 1: 0.33
Epoch 86 - Batch (140/363) - Mini-batch Training loss: 0.2538 - Training Acc 1: 0.36
Epoch 86 - Batch (150/363) - Mini-batch Training loss: 0.2438 - Training Acc 1: 0.39
Epoch 86 - Batch (160/363) - Mini-batch Training loss: 0.2407 - Training Acc 1: 0.41
Epoch 86 - Batch (170/363) - Mini-batch Training loss: 0.2386 - Training Acc 1: 0.44
Epoch 86 - Batch (180/363) - Mini-batch Training loss: 0.2360 - Training Acc 1: 0.46
Epoch 86 - Batch (190/363) - Mini-batch Training loss: 0.2372 - Training Acc 1: 0.49
Epoch 86 - Batch (200/363) - Mini-batch Training loss: 0.2313 - Training Acc 1: 0.52
Epoch 86 - Batch (210/363) - Mini-batch Training loss: 0.2389 - Training Acc 1: 0.54
Epoch 86 - Batch (220/363) - Mini-batch Training loss: 0.2394 - Training Acc 1: 0.57
Epoch 86 - Batch (230/363) - Mini-batch Training loss: 0.2527 - Training Acc 1: 0.59
Epoch 86 - Batch (240/363) - Mini-batch Training loss: 0.2508 - Training Acc 1: 0.61
Epoch 86 - Batch (250/363) - Mini-batch Training loss: 0.2535 - Training Acc 1: 0.64
Epoch 86 - Batch (260/363) - Mini-batch Training loss: 0.2569 - Training Acc 1: 0.66
Epoch 86 - Batch (270/363) - Mini-batch Training loss: 0.2553 - Training Acc 1: 0.69
Epoch 86 - Batch (280/363) - Mini-batch Training loss: 0.2533 - Training Acc 1: 0.71
Epoch 86 - Batch (290/363) - Mini-batch Training loss: 0.2499 - Training Acc 1: 0.74
Epoch 86 - Batch (300/363) - Mini-batch Training loss: 0.2529 - Training Acc 1: 0.76
Epoch 86 - Batch (310/363) - Mini-batch Training loss: 0.2558 - Training Acc 1: 0.79
Epoch 86 - Batch (320/363) - Mini-batch Training loss: 0.2552 - Training Acc 1: 0.81
Epoch 86 - Batch (330/363) - Mini-batch Training loss: 0.2523 - Training Acc 1: 0.84
Epoch 86 - Batch (340/363) - Mini-batch Training loss: 0.2585 - Training Acc 1: 0.86
Epoch 86 - Batch (350/363) - Mini-batch Training loss: 0.2558 - Training Acc 1: 0.89
Epoch 86 - Batch (360/363) - Mini-batch Training loss: 0.2540 - Training Acc 1: 0.92
Epoch 86 - Full-batch Training loss: 0.2527 - Training Acc 1: 0.92
Validation set: Average loss: 0.6926, Accuracy: 299.0/363 (82%)

Epoch 87 - Batch (0/363) - Mini-batch Training loss: 0.1978 - Training Acc 1: 0.00
Epoch 87 - Batch (10/363) - Mini-batch Training loss: 0.2518 - Training Acc 1: 0.03
Epoch 87 - Batch (20/363) - Mini-batch Training loss: 0.2195 - Training Acc 1: 0.05
Epoch 87 - Batch (30/363) - Mini-batch Training loss: 0.2286 - Training Acc 1: 0.08
Epoch 87 - Batch (40/363) - Mini-batch Training loss: 0.2477 - Training Acc 1: 0.10
Epoch 87 - Batch (50/363) - Mini-batch Training loss: 0.2614 - Training Acc 1: 0.13
Epoch 87 - Batch (60/363) - Mini-batch Training loss: 0.2451 - Training Acc 1: 0.16
Epoch 87 - Batch (70/363) - Mini-batch Training loss: 0.2335 - Training Acc 1: 0.18
Epoch 87 - Batch (80/363) - Mini-batch Training loss: 0.2499 - Training Acc 1: 0.21
Epoch 87 - Batch (90/363) - Mini-batch Training loss: 0.2743 - Training Acc 1: 0.23
Epoch 87 - Batch (100/363) - Mini-batch Training loss: 0.2849 - Training Acc 1: 0.25
Epoch 87 - Batch (110/363) - Mini-batch Training loss: 0.2784 - Training Acc 1: 0.28
Epoch 87 - Batch (120/363) - Mini-batch Training loss: 0.2832 - Training Acc 1: 0.30
Epoch 87 - Batch (130/363) - Mini-batch Training loss: 0.2822 - Training Acc 1: 0.33
Epoch 87 - Batch (140/363) - Mini-batch Training loss: 0.2771 - Training Acc 1: 0.35
Epoch 87 - Batch (150/363) - Mini-batch Training loss: 0.2708 - Training Acc 1: 0.38
Epoch 87 - Batch (160/363) - Mini-batch Training loss: 0.2621 - Training Acc 1: 0.41
Epoch 87 - Batch (170/363) - Mini-batch Training loss: 0.2565 - Training Acc 1: 0.43
Epoch 87 - Batch (180/363) - Mini-batch Training loss: 0.2497 - Training Acc 1: 0.46
Epoch 87 - Batch (190/363) - Mini-batch Training loss: 0.2445 - Training Acc 1: 0.48
Epoch 87 - Batch (200/363) - Mini-batch Training loss: 0.2474 - Training Acc 1: 0.51
Epoch 87 - Batch (210/363) - Mini-batch Training loss: 0.2490 - Training Acc 1: 0.53
Epoch 87 - Batch (220/363) - Mini-batch Training loss: 0.2486 - Training Acc 1: 0.56
Epoch 87 - Batch (230/363) - Mini-batch Training loss: 0.2563 - Training Acc 1: 0.58
Epoch 87 - Batch (240/363) - Mini-batch Training loss: 0.2537 - Training Acc 1: 0.61
Epoch 87 - Batch (250/363) - Mini-batch Training loss: 0.2499 - Training Acc 1: 0.64
Epoch 87 - Batch (260/363) - Mini-batch Training loss: 0.2452 - Training Acc 1: 0.66
Epoch 87 - Batch (270/363) - Mini-batch Training loss: 0.2490 - Training Acc 1: 0.69
Epoch 87 - Batch (280/363) - Mini-batch Training loss: 0.2494 - Training Acc 1: 0.71
Epoch 87 - Batch (290/363) - Mini-batch Training loss: 0.2470 - Training Acc 1: 0.74
Epoch 87 - Batch (300/363) - Mini-batch Training loss: 0.2454 - Training Acc 1: 0.76
Epoch 87 - Batch (310/363) - Mini-batch Training loss: 0.2460 - Training Acc 1: 0.79
Epoch 87 - Batch (320/363) - Mini-batch Training loss: 0.2433 - Training Acc 1: 0.82
Epoch 87 - Batch (330/363) - Mini-batch Training loss: 0.2465 - Training Acc 1: 0.84
Epoch 87 - Batch (340/363) - Mini-batch Training loss: 0.2517 - Training Acc 1: 0.86
Epoch 87 - Batch (350/363) - Mini-batch Training loss: 0.2503 - Training Acc 1: 0.89
Epoch 87 - Batch (360/363) - Mini-batch Training loss: 0.2482 - Training Acc 1: 0.92
Epoch 87 - Full-batch Training loss: 0.2477 - Training Acc 1: 0.92
Validation set: Average loss: 0.6769, Accuracy: 301.0/363 (83%)

Epoch 88 - Batch (0/363) - Mini-batch Training loss: 0.3475 - Training Acc 1: 0.00
Epoch 88 - Batch (10/363) - Mini-batch Training loss: 0.1259 - Training Acc 1: 0.03
Epoch 88 - Batch (20/363) - Mini-batch Training loss: 0.1465 - Training Acc 1: 0.06
Epoch 88 - Batch (30/363) - Mini-batch Training loss: 0.1681 - Training Acc 1: 0.08
Epoch 88 - Batch (40/363) - Mini-batch Training loss: 0.1482 - Training Acc 1: 0.11
Epoch 88 - Batch (50/363) - Mini-batch Training loss: 0.1666 - Training Acc 1: 0.14
Epoch 88 - Batch (60/363) - Mini-batch Training loss: 0.1925 - Training Acc 1: 0.16
Epoch 88 - Batch (70/363) - Mini-batch Training loss: 0.1935 - Training Acc 1: 0.19
Epoch 88 - Batch (80/363) - Mini-batch Training loss: 0.1944 - Training Acc 1: 0.21
Epoch 88 - Batch (90/363) - Mini-batch Training loss: 0.1940 - Training Acc 1: 0.24
Epoch 88 - Batch (100/363) - Mini-batch Training loss: 0.1928 - Training Acc 1: 0.26
Epoch 88 - Batch (110/363) - Mini-batch Training loss: 0.1878 - Training Acc 1: 0.29
Epoch 88 - Batch (120/363) - Mini-batch Training loss: 0.1832 - Training Acc 1: 0.32
Epoch 88 - Batch (130/363) - Mini-batch Training loss: 0.1876 - Training Acc 1: 0.34
Epoch 88 - Batch (140/363) - Mini-batch Training loss: 0.2096 - Training Acc 1: 0.37
Epoch 88 - Batch (150/363) - Mini-batch Training loss: 0.2282 - Training Acc 1: 0.39
Epoch 88 - Batch (160/363) - Mini-batch Training loss: 0.2256 - Training Acc 1: 0.41
Epoch 88 - Batch (170/363) - Mini-batch Training loss: 0.2274 - Training Acc 1: 0.44
Epoch 88 - Batch (180/363) - Mini-batch Training loss: 0.2358 - Training Acc 1: 0.46
Epoch 88 - Batch (190/363) - Mini-batch Training loss: 0.2602 - Training Acc 1: 0.49
Epoch 88 - Batch (200/363) - Mini-batch Training loss: 0.2618 - Training Acc 1: 0.51
Epoch 88 - Batch (210/363) - Mini-batch Training loss: 0.2641 - Training Acc 1: 0.54
Epoch 88 - Batch (220/363) - Mini-batch Training loss: 0.2602 - Training Acc 1: 0.56
Epoch 88 - Batch (230/363) - Mini-batch Training loss: 0.2611 - Training Acc 1: 0.59
Epoch 88 - Batch (240/363) - Mini-batch Training loss: 0.2607 - Training Acc 1: 0.61
Epoch 88 - Batch (250/363) - Mini-batch Training loss: 0.2649 - Training Acc 1: 0.64
Epoch 88 - Batch (260/363) - Mini-batch Training loss: 0.2673 - Training Acc 1: 0.66
Epoch 88 - Batch (270/363) - Mini-batch Training loss: 0.2714 - Training Acc 1: 0.69
Epoch 88 - Batch (280/363) - Mini-batch Training loss: 0.2679 - Training Acc 1: 0.71
Epoch 88 - Batch (290/363) - Mini-batch Training loss: 0.2635 - Training Acc 1: 0.74
Epoch 88 - Batch (300/363) - Mini-batch Training loss: 0.2614 - Training Acc 1: 0.77
Epoch 88 - Batch (310/363) - Mini-batch Training loss: 0.2579 - Training Acc 1: 0.79
Epoch 88 - Batch (320/363) - Mini-batch Training loss: 0.2593 - Training Acc 1: 0.82
Epoch 88 - Batch (330/363) - Mini-batch Training loss: 0.2635 - Training Acc 1: 0.84
Epoch 88 - Batch (340/363) - Mini-batch Training loss: 0.2667 - Training Acc 1: 0.87
Epoch 88 - Batch (350/363) - Mini-batch Training loss: 0.2756 - Training Acc 1: 0.89
Epoch 88 - Batch (360/363) - Mini-batch Training loss: 0.2757 - Training Acc 1: 0.91
Epoch 88 - Full-batch Training loss: 0.2754 - Training Acc 1: 0.92
Validation set: Average loss: 0.6949, Accuracy: 296.0/363 (82%)

Epoch 89 - Batch (0/363) - Mini-batch Training loss: 0.2207 - Training Acc 1: 0.00
Epoch 89 - Batch (10/363) - Mini-batch Training loss: 0.2646 - Training Acc 1: 0.03
Epoch 89 - Batch (20/363) - Mini-batch Training loss: 0.2133 - Training Acc 1: 0.06
Epoch 89 - Batch (30/363) - Mini-batch Training loss: 0.2254 - Training Acc 1: 0.08
Epoch 89 - Batch (40/363) - Mini-batch Training loss: 0.2196 - Training Acc 1: 0.11
Epoch 89 - Batch (50/363) - Mini-batch Training loss: 0.2607 - Training Acc 1: 0.13
Epoch 89 - Batch (60/363) - Mini-batch Training loss: 0.2452 - Training Acc 1: 0.16
Epoch 89 - Batch (70/363) - Mini-batch Training loss: 0.2362 - Training Acc 1: 0.18
Epoch 89 - Batch (80/363) - Mini-batch Training loss: 0.2323 - Training Acc 1: 0.21
Epoch 89 - Batch (90/363) - Mini-batch Training loss: 0.2344 - Training Acc 1: 0.23
Epoch 89 - Batch (100/363) - Mini-batch Training loss: 0.2484 - Training Acc 1: 0.26
Epoch 89 - Batch (110/363) - Mini-batch Training loss: 0.2487 - Training Acc 1: 0.28
Epoch 89 - Batch (120/363) - Mini-batch Training loss: 0.2450 - Training Acc 1: 0.31
Epoch 89 - Batch (130/363) - Mini-batch Training loss: 0.2356 - Training Acc 1: 0.33
Epoch 89 - Batch (140/363) - Mini-batch Training loss: 0.2398 - Training Acc 1: 0.36
Epoch 89 - Batch (150/363) - Mini-batch Training loss: 0.2449 - Training Acc 1: 0.38
Epoch 89 - Batch (160/363) - Mini-batch Training loss: 0.2443 - Training Acc 1: 0.41
Epoch 89 - Batch (170/363) - Mini-batch Training loss: 0.2379 - Training Acc 1: 0.43
Epoch 89 - Batch (180/363) - Mini-batch Training loss: 0.2302 - Training Acc 1: 0.46
Epoch 89 - Batch (190/363) - Mini-batch Training loss: 0.2350 - Training Acc 1: 0.49
Epoch 89 - Batch (200/363) - Mini-batch Training loss: 0.2287 - Training Acc 1: 0.51
Epoch 89 - Batch (210/363) - Mini-batch Training loss: 0.2232 - Training Acc 1: 0.54
Epoch 89 - Batch (220/363) - Mini-batch Training loss: 0.2284 - Training Acc 1: 0.56
Epoch 89 - Batch (230/363) - Mini-batch Training loss: 0.2312 - Training Acc 1: 0.59
Epoch 89 - Batch (240/363) - Mini-batch Training loss: 0.2357 - Training Acc 1: 0.62
Epoch 89 - Batch (250/363) - Mini-batch Training loss: 0.2396 - Training Acc 1: 0.64
Epoch 89 - Batch (260/363) - Mini-batch Training loss: 0.2347 - Training Acc 1: 0.67
Epoch 89 - Batch (270/363) - Mini-batch Training loss: 0.2342 - Training Acc 1: 0.69
Epoch 89 - Batch (280/363) - Mini-batch Training loss: 0.2335 - Training Acc 1: 0.72
Epoch 89 - Batch (290/363) - Mini-batch Training loss: 0.2310 - Training Acc 1: 0.75
Epoch 89 - Batch (300/363) - Mini-batch Training loss: 0.2309 - Training Acc 1: 0.77
Epoch 89 - Batch (310/363) - Mini-batch Training loss: 0.2353 - Training Acc 1: 0.80
Epoch 89 - Batch (320/363) - Mini-batch Training loss: 0.2352 - Training Acc 1: 0.82
Epoch 89 - Batch (330/363) - Mini-batch Training loss: 0.2370 - Training Acc 1: 0.85
Epoch 89 - Batch (340/363) - Mini-batch Training loss: 0.2357 - Training Acc 1: 0.87
Epoch 89 - Batch (350/363) - Mini-batch Training loss: 0.2335 - Training Acc 1: 0.90
Epoch 89 - Batch (360/363) - Mini-batch Training loss: 0.2318 - Training Acc 1: 0.92
Epoch 89 - Full-batch Training loss: 0.2316 - Training Acc 1: 0.93
Validation set: Average loss: 0.6607, Accuracy: 299.0/363 (82%)

Epoch 90 - Batch (0/363) - Mini-batch Training loss: 0.0883 - Training Acc 1: 0.00
Epoch 90 - Batch (10/363) - Mini-batch Training loss: 0.2450 - Training Acc 1: 0.03
Epoch 90 - Batch (20/363) - Mini-batch Training loss: 0.2147 - Training Acc 1: 0.05
Epoch 90 - Batch (30/363) - Mini-batch Training loss: 0.2578 - Training Acc 1: 0.08
Epoch 90 - Batch (40/363) - Mini-batch Training loss: 0.2373 - Training Acc 1: 0.11
Epoch 90 - Batch (50/363) - Mini-batch Training loss: 0.2057 - Training Acc 1: 0.13
Epoch 90 - Batch (60/363) - Mini-batch Training loss: 0.2202 - Training Acc 1: 0.16
Epoch 90 - Batch (70/363) - Mini-batch Training loss: 0.2106 - Training Acc 1: 0.18
Epoch 90 - Batch (80/363) - Mini-batch Training loss: 0.2095 - Training Acc 1: 0.21
Epoch 90 - Batch (90/363) - Mini-batch Training loss: 0.2189 - Training Acc 1: 0.24
Epoch 90 - Batch (100/363) - Mini-batch Training loss: 0.2177 - Training Acc 1: 0.26
Epoch 90 - Batch (110/363) - Mini-batch Training loss: 0.2244 - Training Acc 1: 0.29
Epoch 90 - Batch (120/363) - Mini-batch Training loss: 0.2175 - Training Acc 1: 0.31
Epoch 90 - Batch (130/363) - Mini-batch Training loss: 0.2137 - Training Acc 1: 0.34
Epoch 90 - Batch (140/363) - Mini-batch Training loss: 0.2172 - Training Acc 1: 0.36
Epoch 90 - Batch (150/363) - Mini-batch Training loss: 0.2143 - Training Acc 1: 0.39
Epoch 90 - Batch (160/363) - Mini-batch Training loss: 0.2086 - Training Acc 1: 0.41
Epoch 90 - Batch (170/363) - Mini-batch Training loss: 0.2029 - Training Acc 1: 0.44
Epoch 90 - Batch (180/363) - Mini-batch Training loss: 0.2031 - Training Acc 1: 0.47
Epoch 90 - Batch (190/363) - Mini-batch Training loss: 0.1972 - Training Acc 1: 0.49
Epoch 90 - Batch (200/363) - Mini-batch Training loss: 0.1996 - Training Acc 1: 0.52
Epoch 90 - Batch (210/363) - Mini-batch Training loss: 0.2085 - Training Acc 1: 0.54
Epoch 90 - Batch (220/363) - Mini-batch Training loss: 0.2162 - Training Acc 1: 0.57
Epoch 90 - Batch (230/363) - Mini-batch Training loss: 0.2117 - Training Acc 1: 0.60
Epoch 90 - Batch (240/363) - Mini-batch Training loss: 0.2157 - Training Acc 1: 0.62
Epoch 90 - Batch (250/363) - Mini-batch Training loss: 0.2150 - Training Acc 1: 0.65
Epoch 90 - Batch (260/363) - Mini-batch Training loss: 0.2102 - Training Acc 1: 0.67
Epoch 90 - Batch (270/363) - Mini-batch Training loss: 0.2102 - Training Acc 1: 0.70
Epoch 90 - Batch (280/363) - Mini-batch Training loss: 0.2127 - Training Acc 1: 0.72
Epoch 90 - Batch (290/363) - Mini-batch Training loss: 0.2176 - Training Acc 1: 0.75
Epoch 90 - Batch (300/363) - Mini-batch Training loss: 0.2208 - Training Acc 1: 0.77
Epoch 90 - Batch (310/363) - Mini-batch Training loss: 0.2215 - Training Acc 1: 0.80
Epoch 90 - Batch (320/363) - Mini-batch Training loss: 0.2253 - Training Acc 1: 0.82
Epoch 90 - Batch (330/363) - Mini-batch Training loss: 0.2262 - Training Acc 1: 0.85
Epoch 90 - Batch (340/363) - Mini-batch Training loss: 0.2283 - Training Acc 1: 0.87
Epoch 90 - Batch (350/363) - Mini-batch Training loss: 0.2287 - Training Acc 1: 0.90
Epoch 90 - Batch (360/363) - Mini-batch Training loss: 0.2296 - Training Acc 1: 0.93
Epoch 90 - Full-batch Training loss: 0.2292 - Training Acc 1: 0.93
Validation set: Average loss: 0.6948, Accuracy: 309.0/363 (85%)

0.8512396694214877
Epoch 91 - Batch (0/363) - Mini-batch Training loss: 0.0351 - Training Acc 1: 0.00
Epoch 91 - Batch (10/363) - Mini-batch Training loss: 0.2038 - Training Acc 1: 0.03
Epoch 91 - Batch (20/363) - Mini-batch Training loss: 0.1566 - Training Acc 1: 0.06
Epoch 91 - Batch (30/363) - Mini-batch Training loss: 0.1635 - Training Acc 1: 0.08
Epoch 91 - Batch (40/363) - Mini-batch Training loss: 0.2204 - Training Acc 1: 0.10
Epoch 91 - Batch (50/363) - Mini-batch Training loss: 0.2073 - Training Acc 1: 0.13
Epoch 91 - Batch (60/363) - Mini-batch Training loss: 0.2075 - Training Acc 1: 0.16
Epoch 91 - Batch (70/363) - Mini-batch Training loss: 0.2064 - Training Acc 1: 0.18
Epoch 91 - Batch (80/363) - Mini-batch Training loss: 0.2017 - Training Acc 1: 0.21
Epoch 91 - Batch (90/363) - Mini-batch Training loss: 0.2070 - Training Acc 1: 0.24
Epoch 91 - Batch (100/363) - Mini-batch Training loss: 0.2077 - Training Acc 1: 0.26
Epoch 91 - Batch (110/363) - Mini-batch Training loss: 0.2230 - Training Acc 1: 0.29
Epoch 91 - Batch (120/363) - Mini-batch Training loss: 0.2194 - Training Acc 1: 0.31
Epoch 91 - Batch (130/363) - Mini-batch Training loss: 0.2150 - Training Acc 1: 0.34
Epoch 91 - Batch (140/363) - Mini-batch Training loss: 0.2133 - Training Acc 1: 0.37
Epoch 91 - Batch (150/363) - Mini-batch Training loss: 0.2120 - Training Acc 1: 0.39
Epoch 91 - Batch (160/363) - Mini-batch Training loss: 0.2096 - Training Acc 1: 0.42
Epoch 91 - Batch (170/363) - Mini-batch Training loss: 0.2013 - Training Acc 1: 0.45
Epoch 91 - Batch (180/363) - Mini-batch Training loss: 0.2000 - Training Acc 1: 0.47
Epoch 91 - Batch (190/363) - Mini-batch Training loss: 0.2114 - Training Acc 1: 0.49
Epoch 91 - Batch (200/363) - Mini-batch Training loss: 0.2121 - Training Acc 1: 0.52
Epoch 91 - Batch (210/363) - Mini-batch Training loss: 0.2144 - Training Acc 1: 0.55
Epoch 91 - Batch (220/363) - Mini-batch Training loss: 0.2151 - Training Acc 1: 0.57
Epoch 91 - Batch (230/363) - Mini-batch Training loss: 0.2188 - Training Acc 1: 0.60
Epoch 91 - Batch (240/363) - Mini-batch Training loss: 0.2191 - Training Acc 1: 0.62
Epoch 91 - Batch (250/363) - Mini-batch Training loss: 0.2191 - Training Acc 1: 0.65
Epoch 91 - Batch (260/363) - Mini-batch Training loss: 0.2279 - Training Acc 1: 0.67
Epoch 91 - Batch (270/363) - Mini-batch Training loss: 0.2368 - Training Acc 1: 0.69
Epoch 91 - Batch (280/363) - Mini-batch Training loss: 0.2374 - Training Acc 1: 0.72
Epoch 91 - Batch (290/363) - Mini-batch Training loss: 0.2342 - Training Acc 1: 0.74
Epoch 91 - Batch (300/363) - Mini-batch Training loss: 0.2354 - Training Acc 1: 0.77
Epoch 91 - Batch (310/363) - Mini-batch Training loss: 0.2419 - Training Acc 1: 0.79
Epoch 91 - Batch (320/363) - Mini-batch Training loss: 0.2436 - Training Acc 1: 0.82
Epoch 91 - Batch (330/363) - Mini-batch Training loss: 0.2420 - Training Acc 1: 0.84
Epoch 91 - Batch (340/363) - Mini-batch Training loss: 0.2393 - Training Acc 1: 0.87
Epoch 91 - Batch (350/363) - Mini-batch Training loss: 0.2384 - Training Acc 1: 0.90
Epoch 91 - Batch (360/363) - Mini-batch Training loss: 0.2385 - Training Acc 1: 0.92
Epoch 91 - Full-batch Training loss: 0.2374 - Training Acc 1: 0.92
Validation set: Average loss: 0.6940, Accuracy: 304.0/363 (84%)

Epoch 92 - Batch (0/363) - Mini-batch Training loss: 0.3780 - Training Acc 1: 0.00
Epoch 92 - Batch (10/363) - Mini-batch Training loss: 0.2697 - Training Acc 1: 0.03
Epoch 92 - Batch (20/363) - Mini-batch Training loss: 0.2503 - Training Acc 1: 0.05
Epoch 92 - Batch (30/363) - Mini-batch Training loss: 0.2068 - Training Acc 1: 0.08
Epoch 92 - Batch (40/363) - Mini-batch Training loss: 0.1852 - Training Acc 1: 0.10
Epoch 92 - Batch (50/363) - Mini-batch Training loss: 0.1812 - Training Acc 1: 0.13
Epoch 92 - Batch (60/363) - Mini-batch Training loss: 0.1883 - Training Acc 1: 0.16
Epoch 92 - Batch (70/363) - Mini-batch Training loss: 0.1858 - Training Acc 1: 0.18
Epoch 92 - Batch (80/363) - Mini-batch Training loss: 0.1980 - Training Acc 1: 0.21
Epoch 92 - Batch (90/363) - Mini-batch Training loss: 0.2054 - Training Acc 1: 0.23
Epoch 92 - Batch (100/363) - Mini-batch Training loss: 0.1955 - Training Acc 1: 0.26
Epoch 92 - Batch (110/363) - Mini-batch Training loss: 0.2221 - Training Acc 1: 0.28
Epoch 92 - Batch (120/363) - Mini-batch Training loss: 0.2179 - Training Acc 1: 0.31
Epoch 92 - Batch (130/363) - Mini-batch Training loss: 0.2438 - Training Acc 1: 0.33
Epoch 92 - Batch (140/363) - Mini-batch Training loss: 0.2440 - Training Acc 1: 0.36
Epoch 92 - Batch (150/363) - Mini-batch Training loss: 0.2516 - Training Acc 1: 0.38
Epoch 92 - Batch (160/363) - Mini-batch Training loss: 0.2452 - Training Acc 1: 0.41
Epoch 92 - Batch (170/363) - Mini-batch Training loss: 0.2538 - Training Acc 1: 0.43
Epoch 92 - Batch (180/363) - Mini-batch Training loss: 0.2532 - Training Acc 1: 0.46
Epoch 92 - Batch (190/363) - Mini-batch Training loss: 0.2534 - Training Acc 1: 0.49
Epoch 92 - Batch (200/363) - Mini-batch Training loss: 0.2664 - Training Acc 1: 0.51
Epoch 92 - Batch (210/363) - Mini-batch Training loss: 0.2679 - Training Acc 1: 0.53
Epoch 92 - Batch (220/363) - Mini-batch Training loss: 0.2653 - Training Acc 1: 0.56
Epoch 92 - Batch (230/363) - Mini-batch Training loss: 0.2606 - Training Acc 1: 0.59
Epoch 92 - Batch (240/363) - Mini-batch Training loss: 0.2737 - Training Acc 1: 0.61
Epoch 92 - Batch (250/363) - Mini-batch Training loss: 0.2807 - Training Acc 1: 0.63
Epoch 92 - Batch (260/363) - Mini-batch Training loss: 0.2848 - Training Acc 1: 0.66
Epoch 92 - Batch (270/363) - Mini-batch Training loss: 0.2867 - Training Acc 1: 0.68
Epoch 92 - Batch (280/363) - Mini-batch Training loss: 0.2829 - Training Acc 1: 0.71
Epoch 92 - Batch (290/363) - Mini-batch Training loss: 0.2756 - Training Acc 1: 0.73
Epoch 92 - Batch (300/363) - Mini-batch Training loss: 0.2726 - Training Acc 1: 0.76
Epoch 92 - Batch (310/363) - Mini-batch Training loss: 0.2745 - Training Acc 1: 0.78
Epoch 92 - Batch (320/363) - Mini-batch Training loss: 0.2765 - Training Acc 1: 0.81
Epoch 92 - Batch (330/363) - Mini-batch Training loss: 0.2775 - Training Acc 1: 0.83
Epoch 92 - Batch (340/363) - Mini-batch Training loss: 0.2730 - Training Acc 1: 0.86
Epoch 92 - Batch (350/363) - Mini-batch Training loss: 0.2720 - Training Acc 1: 0.89
Epoch 92 - Batch (360/363) - Mini-batch Training loss: 0.2706 - Training Acc 1: 0.91
Epoch 92 - Full-batch Training loss: 0.2696 - Training Acc 1: 0.92
Validation set: Average loss: 0.7040, Accuracy: 294.0/363 (81%)

Epoch 93 - Batch (0/363) - Mini-batch Training loss: 0.0142 - Training Acc 1: 0.00
Epoch 93 - Batch (10/363) - Mini-batch Training loss: 0.1426 - Training Acc 1: 0.03
Epoch 93 - Batch (20/363) - Mini-batch Training loss: 0.1018 - Training Acc 1: 0.06
Epoch 93 - Batch (30/363) - Mini-batch Training loss: 0.1074 - Training Acc 1: 0.08
Epoch 93 - Batch (40/363) - Mini-batch Training loss: 0.1511 - Training Acc 1: 0.11
Epoch 93 - Batch (50/363) - Mini-batch Training loss: 0.1694 - Training Acc 1: 0.13
Epoch 93 - Batch (60/363) - Mini-batch Training loss: 0.1598 - Training Acc 1: 0.16
Epoch 93 - Batch (70/363) - Mini-batch Training loss: 0.1586 - Training Acc 1: 0.19
Epoch 93 - Batch (80/363) - Mini-batch Training loss: 0.1545 - Training Acc 1: 0.21
Epoch 93 - Batch (90/363) - Mini-batch Training loss: 0.1535 - Training Acc 1: 0.24
Epoch 93 - Batch (100/363) - Mini-batch Training loss: 0.1594 - Training Acc 1: 0.27
Epoch 93 - Batch (110/363) - Mini-batch Training loss: 0.1761 - Training Acc 1: 0.29
Epoch 93 - Batch (120/363) - Mini-batch Training loss: 0.1736 - Training Acc 1: 0.31
Epoch 93 - Batch (130/363) - Mini-batch Training loss: 0.1846 - Training Acc 1: 0.34
Epoch 93 - Batch (140/363) - Mini-batch Training loss: 0.1901 - Training Acc 1: 0.36
Epoch 93 - Batch (150/363) - Mini-batch Training loss: 0.1900 - Training Acc 1: 0.39
Epoch 93 - Batch (160/363) - Mini-batch Training loss: 0.1874 - Training Acc 1: 0.42
Epoch 93 - Batch (170/363) - Mini-batch Training loss: 0.1896 - Training Acc 1: 0.44
Epoch 93 - Batch (180/363) - Mini-batch Training loss: 0.1845 - Training Acc 1: 0.47
Epoch 93 - Batch (190/363) - Mini-batch Training loss: 0.1893 - Training Acc 1: 0.49
Epoch 93 - Batch (200/363) - Mini-batch Training loss: 0.1901 - Training Acc 1: 0.52
Epoch 93 - Batch (210/363) - Mini-batch Training loss: 0.1842 - Training Acc 1: 0.55
Epoch 93 - Batch (220/363) - Mini-batch Training loss: 0.1825 - Training Acc 1: 0.57
Epoch 93 - Batch (230/363) - Mini-batch Training loss: 0.1863 - Training Acc 1: 0.60
Epoch 93 - Batch (240/363) - Mini-batch Training loss: 0.1868 - Training Acc 1: 0.62
Epoch 93 - Batch (250/363) - Mini-batch Training loss: 0.1864 - Training Acc 1: 0.65
Epoch 93 - Batch (260/363) - Mini-batch Training loss: 0.2017 - Training Acc 1: 0.67
Epoch 93 - Batch (270/363) - Mini-batch Training loss: 0.2083 - Training Acc 1: 0.69
Epoch 93 - Batch (280/363) - Mini-batch Training loss: 0.2089 - Training Acc 1: 0.72
Epoch 93 - Batch (290/363) - Mini-batch Training loss: 0.2170 - Training Acc 1: 0.75
Epoch 93 - Batch (300/363) - Mini-batch Training loss: 0.2211 - Training Acc 1: 0.77
Epoch 93 - Batch (310/363) - Mini-batch Training loss: 0.2264 - Training Acc 1: 0.79
Epoch 93 - Batch (320/363) - Mini-batch Training loss: 0.2287 - Training Acc 1: 0.82
Epoch 93 - Batch (330/363) - Mini-batch Training loss: 0.2293 - Training Acc 1: 0.84
Epoch 93 - Batch (340/363) - Mini-batch Training loss: 0.2339 - Training Acc 1: 0.87
Epoch 93 - Batch (350/363) - Mini-batch Training loss: 0.2327 - Training Acc 1: 0.89
Epoch 93 - Batch (360/363) - Mini-batch Training loss: 0.2320 - Training Acc 1: 0.92
Epoch 93 - Full-batch Training loss: 0.2312 - Training Acc 1: 0.92
Validation set: Average loss: 0.6863, Accuracy: 304.0/363 (84%)

Epoch 94 - Batch (0/363) - Mini-batch Training loss: 0.0164 - Training Acc 1: 0.00
Epoch 94 - Batch (10/363) - Mini-batch Training loss: 0.3250 - Training Acc 1: 0.03
Epoch 94 - Batch (20/363) - Mini-batch Training loss: 0.3122 - Training Acc 1: 0.05
Epoch 94 - Batch (30/363) - Mini-batch Training loss: 0.2794 - Training Acc 1: 0.08
Epoch 94 - Batch (40/363) - Mini-batch Training loss: 0.2363 - Training Acc 1: 0.10
Epoch 94 - Batch (50/363) - Mini-batch Training loss: 0.2144 - Training Acc 1: 0.13
Epoch 94 - Batch (60/363) - Mini-batch Training loss: 0.2590 - Training Acc 1: 0.16
